{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cdd18d",
   "metadata": {},
   "source": [
    "# IMPORTING RELEVANT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6f8175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e94b6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          70000 non-null  int64  \n",
      " 1   gender       70000 non-null  int64  \n",
      " 2   height       70000 non-null  int64  \n",
      " 3   weight       70000 non-null  float64\n",
      " 4   ap_hi        70000 non-null  int64  \n",
      " 5   ap_lo        70000 non-null  int64  \n",
      " 6   cholesterol  70000 non-null  int64  \n",
      " 7   gluc         70000 non-null  int64  \n",
      " 8   smoke        70000 non-null  int64  \n",
      " 9   alco         70000 non-null  int64  \n",
      " 10  active       70000 non-null  int64  \n",
      " 11  cardio       70000 non-null  int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 6.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "      age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       " 0  18393       2     168    62.0    110     80            1     1      0   \n",
       " 1  20228       1     156    85.0    140     90            3     1      0   \n",
       " 2  18857       1     165    64.0    130     70            3     1      0   \n",
       " 3  17623       2     169    82.0    150    100            1     1      0   \n",
       " 4  17474       1     156    56.0    100     60            1     1      0   \n",
       " \n",
       "    alco  active  cardio  \n",
       " 0     0       1       0  \n",
       " 1     0       1       1  \n",
       " 2     0       0       1  \n",
       " 3     0       1       1  \n",
       " 4     0       0       0  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the first dataset (Cardiovascular disease dataset)\n",
    "cardio_data_path = 'C:\\\\Users\\\\Ede\\\\Desktop\\\\Synthetic_Data_Using_AE_VAE_Techniques\\\\cardio.csv'\n",
    "cardio_df = pd.read_csv(cardio_data_path)\n",
    "\n",
    "# Displaying the first few rows of the dataset and summary information\n",
    "cardio_df_info = cardio_df.info()\n",
    "cardio_df_head = cardio_df.head()\n",
    "\n",
    "cardio_df_info, cardio_df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de35903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "# Drop the target variable 'cardio' and normalize the features\n",
    "# Assuming 'cardio_df' is your DataFrame and 'cardio' is the target variable\n",
    "features = cardio_df.drop('cardio', axis=1)\n",
    "labels = cardio_df['cardio'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# TRAIN THE AUTO-ENCODER\n",
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val = train_test_split(scaled_features, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d682c7",
   "metadata": {},
   "source": [
    "# 1. Define the VAE Architecture\n",
    "The VAE consists of two main components: the encoder and the decoder. The encoder will map the input data to a distribution in a latent space, and the decoder will reconstruct the data from this latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d1b73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 11)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           768         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            130         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            130         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,028\n",
      "Trainable params: 1,028\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                192       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 907\n",
      "Trainable params: 907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Network parameters\n",
    "input_shape = (features.shape[1], )\n",
    "intermediate_dim = 64\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "epochs = 50\n",
    "\n",
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = Dense(input_shape[0], activation='sigmoid')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4addc",
   "metadata": {},
   "source": [
    "# 2. VAE Loss Function\n",
    "The loss function for a VAE comprises both the reconstruction loss and the KL divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7de4f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae_mlp\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 11)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder (Functional)           [(None, 2),          1028        ['encoder_input[0][0]']          \n",
      "                                 (None, 2),                                                       \n",
      "                                 (None, 2)]                                                       \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 11)           907         ['encoder[0][2]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           768         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            130         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            130         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 2)           0           ['z_log_var[0][0]']              \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.square_2 (TFOpLambda)  (None, 2)            0           ['z_mean[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor_2 (TFOpLa  (None, 11)          0           ['decoder[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.cast_2 (TFOpLambda)         (None, 11)           0           ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.subtract_4 (TFOpLambda  (None, 2)           0           ['tf.__operators__.add_4[0][0]', \n",
      " )                                                                'tf.math.square_2[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.exp_2 (TFOpLambda)     (None, 2)            0           ['z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.squared_difference_2 (  (None, 11)          0           ['tf.convert_to_tensor_2[0][0]', \n",
      " TFOpLambda)                                                      'tf.cast_2[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.subtract_5 (TFOpLambda  (None, 2)           0           ['tf.math.subtract_4[0][0]',     \n",
      " )                                                                'tf.math.exp_2[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_4 (TFOpLam  (None,)             0           ['tf.math.squared_difference_2[0]\n",
      " bda)                                                            [0]']                            \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_2 (TFOpLamb  (None,)             0           ['tf.math.subtract_5[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None,)             0           ['tf.math.reduce_mean_4[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_2[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None,)             0           ['tf.math.multiply_4[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_5 (TFOpLam  ()                  0           ['tf.__operators__.add_5[0][0]'] \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " add_loss_2 (AddLoss)           ()                   0           ['tf.math.reduce_mean_5[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,935\n",
      "Trainable params: 1,935\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VAE loss = mse_loss or xent_loss + kl_loss\n",
    "reconstruction_loss = mse(inputs, outputs)\n",
    "reconstruction_loss *= input_shape[0]\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0bb9e8",
   "metadata": {},
   "source": [
    "# 3. Train the VAE\n",
    "Train the VAE using your preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7328b8d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "547/547 [==============================] - 2s 2ms/step - loss: 11.3347\n",
      "Epoch 2/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.6256\n",
      "Epoch 3/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.5398\n",
      "Epoch 4/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.4839\n",
      "Epoch 5/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.4456\n",
      "Epoch 6/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.4285\n",
      "Epoch 7/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.4208\n",
      "Epoch 8/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.4137\n",
      "Epoch 9/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.4119\n",
      "Epoch 10/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.4035\n",
      "Epoch 11/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3968\n",
      "Epoch 12/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3936\n",
      "Epoch 13/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3791\n",
      "Epoch 14/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3718\n",
      "Epoch 15/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3635\n",
      "Epoch 16/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3620\n",
      "Epoch 17/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3641\n",
      "Epoch 18/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3572\n",
      "Epoch 19/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3625\n",
      "Epoch 20/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3643\n",
      "Epoch 21/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3551\n",
      "Epoch 22/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3453\n",
      "Epoch 23/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3398\n",
      "Epoch 24/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3350\n",
      "Epoch 25/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3411\n",
      "Epoch 26/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3341\n",
      "Epoch 27/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3352\n",
      "Epoch 28/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3295\n",
      "Epoch 29/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3346\n",
      "Epoch 30/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3391\n",
      "Epoch 31/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3292\n",
      "Epoch 32/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3315\n",
      "Epoch 33/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3275\n",
      "Epoch 34/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3186\n",
      "Epoch 35/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3148\n",
      "Epoch 36/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3205\n",
      "Epoch 37/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3106\n",
      "Epoch 38/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3275\n",
      "Epoch 39/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3066\n",
      "Epoch 40/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3207\n",
      "Epoch 41/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3039\n",
      "Epoch 42/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3201\n",
      "Epoch 43/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3210\n",
      "Epoch 44/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3046\n",
      "Epoch 45/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3154\n",
      "Epoch 46/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3188\n",
      "Epoch 47/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3121\n",
      "Epoch 48/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3236\n",
      "Epoch 49/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3179\n",
      "Epoch 50/50\n",
      "547/547 [==============================] - 1s 2ms/step - loss: 10.3089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a527030d00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(scaled_features, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88875732",
   "metadata": {},
   "source": [
    "# Integrating VAE with GAN\n",
    "1. Develop the GAN Architecture\n",
    "The GAN comprises two main components: the generator and the discriminator. In your case, the generator will use encoded representations from the VAE to generate synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc2a7977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 128)               384       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,123\n",
      "Trainable params: 9,739\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 128)               1536      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,857\n",
      "Trainable params: 9,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A. Generator\n",
    "# The generator takes a point from the latent space and outputs synthetic data.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, LeakyReLU\n",
    "\n",
    "\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation=\"relu\", input_dim=latent_dim))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(11, activation='tanh'))  # Output size to match the 11 features\n",
    "    return model\n",
    "\n",
    "latent_dim = 2  # or choose an appropriate size for the latent dimension\n",
    "generator = build_generator(latent_dim)\n",
    "generator.summary()\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "# The discriminator should accept input data of the same shape as your dataset's features.\n",
    "# The discriminator takes real or synthetic data and tries to classify it as real or fake.\n",
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=input_shape, activation='relu'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification output\n",
    "    return model\n",
    "\n",
    "# Assuming build_discriminator is already defined\n",
    "input_shape = (11,)  # Shape of the features in your dataset\n",
    "discriminator = build_discriminator(input_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb0973",
   "metadata": {},
   "source": [
    "# Step 1: Combine Generator and Discriminator to Create GAN\n",
    "a. Combine into a GAN\n",
    "\n",
    "Create the GAN by combining the generator and discriminator. The discriminator's trainability is set to False when itâ€™s being used within the combined model. This is because we only want to train the generator when training the combined model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b62cdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 11)                10123     \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 1)                 9857      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,980\n",
      "Trainable params: 9,739\n",
      "Non-trainable params: 10,241\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False  # Important: only affects the GAN, not standalone discriminator\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e58d6d7",
   "metadata": {},
   "source": [
    "# Step 2: Train the GAN\n",
    "Training a GAN involves alternating between training the discriminator and the generator.\n",
    "\n",
    "1. Train the Discriminator:\n",
    "\n",
    "    . First, with real data (labelled as 1).\n",
    "    . Then, with fake data generated by the generator (labelled as 0).\n",
    "2. Train the Generator (via the GAN model):\n",
    "\n",
    ".Generate noise inputs.\n",
    ".Label the generated data as real (labelled as 1) to fool the discriminator.\n",
    "Here's a simplified training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb2331fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 147ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 0, D Loss: [0.69629779 0.453125  ], G Loss: 0.7184469699859619\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1, D Loss: [0.69095394 0.359375  ], G Loss: 0.7134543061256409\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 2, D Loss: [0.68595484 0.328125  ], G Loss: 0.702143669128418\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 3, D Loss: [0.67457348 0.390625  ], G Loss: 0.6987758874893188\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 4, D Loss: [0.66732019 0.484375  ], G Loss: 0.6828488111495972\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 5, D Loss: [0.654805 0.4375  ], G Loss: 0.6893022060394287\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 6, D Loss: [0.64559364 0.40625   ], G Loss: 0.6673218011856079\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 7, D Loss: [0.64201528 0.625     ], G Loss: 0.6572747230529785\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 8, D Loss: [0.64975417 0.53125   ], G Loss: 0.6386858224868774\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 9, D Loss: [0.63333163 0.578125  ], G Loss: 0.6367431879043579\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 10, D Loss: [0.64968517 0.5       ], G Loss: 0.6262125372886658\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 11, D Loss: [0.61776912 0.671875  ], G Loss: 0.6222404837608337\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 12, D Loss: [0.64113268 0.5625    ], G Loss: 0.6298767328262329\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 13, D Loss: [0.63689756 0.59375   ], G Loss: 0.6084866523742676\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 14, D Loss: [0.63995603 0.65625   ], G Loss: 0.6146121025085449\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 15, D Loss: [0.63859421 0.625     ], G Loss: 0.6033309102058411\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 16, D Loss: [0.62947407 0.546875  ], G Loss: 0.5891050100326538\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 17, D Loss: [0.63855785 0.59375   ], G Loss: 0.5932462215423584\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 18, D Loss: [0.65687168 0.546875  ], G Loss: 0.5790995359420776\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 19, D Loss: [0.62238075 0.5625    ], G Loss: 0.5706425905227661\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 20, D Loss: [0.64915758 0.59375   ], G Loss: 0.5693075656890869\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 21, D Loss: [0.65331841 0.5       ], G Loss: 0.5782602429389954\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 22, D Loss: [0.6525442 0.53125  ], G Loss: 0.5788344144821167\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 23, D Loss: [0.64990486 0.546875  ], G Loss: 0.5739246010780334\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 24, D Loss: [0.63774544 0.5625    ], G Loss: 0.5704993009567261\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 25, D Loss: [0.63294585 0.5625    ], G Loss: 0.5576274394989014\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 26, D Loss: [0.64987054 0.53125   ], G Loss: 0.5625555515289307\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 27, D Loss: [0.65581688 0.515625  ], G Loss: 0.5923826694488525\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 28, D Loss: [0.64908117 0.578125  ], G Loss: 0.5575467348098755\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 29, D Loss: [0.64828828 0.5       ], G Loss: 0.572425901889801\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 30, D Loss: [0.66875598 0.53125   ], G Loss: 0.5694336891174316\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 31, D Loss: [0.65275335 0.5625    ], G Loss: 0.5792376399040222\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 32, D Loss: [0.6857633 0.53125  ], G Loss: 0.577967643737793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 33, D Loss: [0.66458185 0.53125   ], G Loss: 0.5782415866851807\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 34, D Loss: [0.65227447 0.515625  ], G Loss: 0.553817093372345\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 35, D Loss: [0.6382916 0.609375 ], G Loss: 0.5596345663070679\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 36, D Loss: [0.65698732 0.53125   ], G Loss: 0.5737289190292358\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 37, D Loss: [0.6321958 0.5625   ], G Loss: 0.5657972097396851\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 38, D Loss: [0.68233886 0.53125   ], G Loss: 0.5515861511230469\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 39, D Loss: [0.64380255 0.546875  ], G Loss: 0.5572079420089722\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 40, D Loss: [0.64325894 0.515625  ], G Loss: 0.555919885635376\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 41, D Loss: [0.65331534 0.53125   ], G Loss: 0.5650131106376648\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 42, D Loss: [0.65143408 0.5625    ], G Loss: 0.5649166107177734\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 43, D Loss: [0.64904159 0.5625    ], G Loss: 0.5742474794387817\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 44, D Loss: [0.67303711 0.515625  ], G Loss: 0.5613493323326111\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 45, D Loss: [0.65923005 0.53125   ], G Loss: 0.5838528871536255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 46, D Loss: [0.659146 0.5625  ], G Loss: 0.5606947541236877\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 47, D Loss: [0.66721791 0.5625    ], G Loss: 0.5555775165557861\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 48, D Loss: [0.62353855 0.5625    ], G Loss: 0.5644052028656006\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 49, D Loss: [0.65469219 0.515625  ], G Loss: 0.5856770277023315\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 50, D Loss: [0.66688371 0.515625  ], G Loss: 0.5583001375198364\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 51, D Loss: [0.65205842 0.53125   ], G Loss: 0.5660971999168396\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 52, D Loss: [0.66305988 0.515625  ], G Loss: 0.5723194479942322\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 53, D Loss: [0.65133551 0.546875  ], G Loss: 0.5532026290893555\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 54, D Loss: [0.6424014 0.578125 ], G Loss: 0.5777603387832642\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 55, D Loss: [0.62545153 0.5625    ], G Loss: 0.5682215690612793\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 56, D Loss: [0.64523494 0.5625    ], G Loss: 0.5558724403381348\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 57, D Loss: [0.64540955 0.53125   ], G Loss: 0.5632306933403015\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 58, D Loss: [0.63470976 0.546875  ], G Loss: 0.5778239965438843\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 59, D Loss: [0.63516827 0.5625    ], G Loss: 0.5695270299911499\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 60, D Loss: [0.6470678 0.578125 ], G Loss: 0.5814400911331177\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 61, D Loss: [0.64847362 0.5       ], G Loss: 0.5601052045822144\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 62, D Loss: [0.63705142 0.546875  ], G Loss: 0.5608726739883423\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 63, D Loss: [0.64428908 0.53125   ], G Loss: 0.5737607479095459\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 64, D Loss: [0.63863835 0.546875  ], G Loss: 0.5765814185142517\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 65, D Loss: [0.68004546 0.515625  ], G Loss: 0.5858901739120483\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 66, D Loss: [0.65057686 0.515625  ], G Loss: 0.5826217532157898\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 67, D Loss: [0.64049123 0.53125   ], G Loss: 0.5853013396263123\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 68, D Loss: [0.66328065 0.5625    ], G Loss: 0.581315279006958\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 69, D Loss: [0.65343501 0.53125   ], G Loss: 0.5760653018951416\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 70, D Loss: [0.6780923 0.546875 ], G Loss: 0.5929121971130371\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 71, D Loss: [0.64711395 0.546875  ], G Loss: 0.5828341245651245\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 72, D Loss: [0.65479447 0.546875  ], G Loss: 0.6044669151306152\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 73, D Loss: [0.64682744 0.546875  ], G Loss: 0.5726033449172974\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 74, D Loss: [0.61492281 0.5625    ], G Loss: 0.5864878296852112\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 75, D Loss: [0.64744051 0.515625  ], G Loss: 0.590314507484436\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 76, D Loss: [0.65429325 0.546875  ], G Loss: 0.5928353071212769\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 77, D Loss: [0.65786982 0.546875  ], G Loss: 0.5860772728919983\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 78, D Loss: [0.63273269 0.53125   ], G Loss: 0.5899288058280945\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 79, D Loss: [0.6501224 0.5      ], G Loss: 0.5982177257537842\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 80, D Loss: [0.65163627 0.59375   ], G Loss: 0.5911014676094055\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 81, D Loss: [0.64540547 0.5625    ], G Loss: 0.595596194267273\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 82, D Loss: [0.62507665 0.546875  ], G Loss: 0.588114857673645\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 83, D Loss: [0.64473605 0.53125   ], G Loss: 0.6034272909164429\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 84, D Loss: [0.63297389 0.578125  ], G Loss: 0.5910321474075317\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 85, D Loss: [0.64502037 0.515625  ], G Loss: 0.601866602897644\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 86, D Loss: [0.63117152 0.546875  ], G Loss: 0.5905767679214478\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 87, D Loss: [0.64562345 0.53125   ], G Loss: 0.611821711063385\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 88, D Loss: [0.63365208 0.578125  ], G Loss: 0.5989043116569519\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 89, D Loss: [0.65949285 0.53125   ], G Loss: 0.6111961007118225\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 90, D Loss: [0.62471555 0.53125   ], G Loss: 0.6069055199623108\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 91, D Loss: [0.64449854 0.546875  ], G Loss: 0.5951344966888428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 92, D Loss: [0.63937169 0.515625  ], G Loss: 0.6161247491836548\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 93, D Loss: [0.64508142 0.546875  ], G Loss: 0.6119288802146912\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 94, D Loss: [0.62744938 0.546875  ], G Loss: 0.6074041128158569\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 95, D Loss: [0.64689733 0.53125   ], G Loss: 0.6065235137939453\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 96, D Loss: [0.63317962 0.546875  ], G Loss: 0.6164525747299194\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 97, D Loss: [0.64300877 0.484375  ], G Loss: 0.6275571584701538\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 98, D Loss: [0.63898768 0.53125   ], G Loss: 0.6111869812011719\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 99, D Loss: [0.62831578 0.59375   ], G Loss: 0.6049413084983826\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 100, D Loss: [0.63250677 0.578125  ], G Loss: 0.6107711791992188\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 101, D Loss: [0.64000228 0.5       ], G Loss: 0.6102689504623413\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 102, D Loss: [0.61225212 0.546875  ], G Loss: 0.589975893497467\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 103, D Loss: [0.64477736 0.515625  ], G Loss: 0.6086230278015137\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 104, D Loss: [0.61440444 0.546875  ], G Loss: 0.619017481803894\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 105, D Loss: [0.62559199 0.515625  ], G Loss: 0.6190741658210754\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 106, D Loss: [0.63056551 0.5625    ], G Loss: 0.6201561689376831\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 107, D Loss: [0.6293664 0.5625   ], G Loss: 0.6210618019104004\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 108, D Loss: [0.6277913 0.578125 ], G Loss: 0.6179515719413757\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 109, D Loss: [0.6177386 0.5625   ], G Loss: 0.6118446588516235\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 110, D Loss: [0.64383376 0.578125  ], G Loss: 0.6251336932182312\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 111, D Loss: [0.61507134 0.609375  ], G Loss: 0.6257297992706299\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 112, D Loss: [0.64042766 0.5       ], G Loss: 0.6090632081031799\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 113, D Loss: [0.63745703 0.609375  ], G Loss: 0.6219585537910461\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 114, D Loss: [0.63748869 0.59375   ], G Loss: 0.6109800338745117\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 115, D Loss: [0.65544873 0.546875  ], G Loss: 0.6168464422225952\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 116, D Loss: [0.63512191 0.59375   ], G Loss: 0.6140173077583313\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 117, D Loss: [0.62141463 0.640625  ], G Loss: 0.6068592071533203\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 118, D Loss: [0.63461363 0.546875  ], G Loss: 0.6166343688964844\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 119, D Loss: [0.6491279 0.515625 ], G Loss: 0.6134676933288574\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 120, D Loss: [0.64220946 0.5625    ], G Loss: 0.6125901341438293\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 121, D Loss: [0.6433942 0.5625   ], G Loss: 0.6120249629020691\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 122, D Loss: [0.6445969 0.5      ], G Loss: 0.6125011444091797\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 123, D Loss: [0.64670247 0.53125   ], G Loss: 0.6012747287750244\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 124, D Loss: [0.63978329 0.578125  ], G Loss: 0.6159228086471558\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 125, D Loss: [0.65264301 0.5625    ], G Loss: 0.6038775444030762\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 126, D Loss: [0.63762426 0.578125  ], G Loss: 0.6170505285263062\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 127, D Loss: [0.6510188 0.546875 ], G Loss: 0.6006702780723572\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 128, D Loss: [0.65754762 0.5625    ], G Loss: 0.6117818355560303\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 129, D Loss: [0.63299033 0.578125  ], G Loss: 0.5968290567398071\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 130, D Loss: [0.6163249 0.640625 ], G Loss: 0.622520387172699\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 131, D Loss: [0.64485338 0.515625  ], G Loss: 0.6156736016273499\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 132, D Loss: [0.65467149 0.546875  ], G Loss: 0.6028116941452026\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 133, D Loss: [0.63810909 0.515625  ], G Loss: 0.6137819886207581\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 134, D Loss: [0.62782627 0.53125   ], G Loss: 0.6009886860847473\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 135, D Loss: [0.62933022 0.609375  ], G Loss: 0.6146104335784912\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 136, D Loss: [0.64287907 0.53125   ], G Loss: 0.6011807918548584\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 137, D Loss: [0.64665197 0.515625  ], G Loss: 0.5952916741371155\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 138, D Loss: [0.63615704 0.609375  ], G Loss: 0.6091333627700806\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 139, D Loss: [0.63495044 0.578125  ], G Loss: 0.5936139225959778\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 140, D Loss: [0.6385911 0.53125  ], G Loss: 0.6006369590759277\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 141, D Loss: [0.63694397 0.546875  ], G Loss: 0.6163532733917236\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 142, D Loss: [0.63357455 0.546875  ], G Loss: 0.5977112054824829\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 143, D Loss: [0.64624333 0.53125   ], G Loss: 0.607029914855957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 144, D Loss: [0.6579702 0.5      ], G Loss: 0.6195536255836487\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 145, D Loss: [0.63682464 0.53125   ], G Loss: 0.6157617568969727\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 146, D Loss: [0.64307246 0.515625  ], G Loss: 0.5991338491439819\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 147, D Loss: [0.64349988 0.515625  ], G Loss: 0.6070040464401245\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 148, D Loss: [0.64657196 0.515625  ], G Loss: 0.6229588389396667\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 149, D Loss: [0.66641968 0.53125   ], G Loss: 0.6222966909408569\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 150, D Loss: [0.64830346 0.53125   ], G Loss: 0.604755163192749\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 151, D Loss: [0.63894269 0.5625    ], G Loss: 0.6155428886413574\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 152, D Loss: [0.64008994 0.578125  ], G Loss: 0.6126448512077332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 153, D Loss: [0.65157054 0.53125   ], G Loss: 0.6085742712020874\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 154, D Loss: [0.63034074 0.578125  ], G Loss: 0.6172831654548645\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 155, D Loss: [0.64737043 0.578125  ], G Loss: 0.6071655750274658\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 156, D Loss: [0.64377299 0.5625    ], G Loss: 0.6122057437896729\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 157, D Loss: [0.64376378 0.59375   ], G Loss: 0.6174875497817993\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 158, D Loss: [0.65824267 0.546875  ], G Loss: 0.6093587875366211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 159, D Loss: [0.66331393 0.59375   ], G Loss: 0.6168324947357178\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 160, D Loss: [0.65546313 0.59375   ], G Loss: 0.6097492575645447\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 161, D Loss: [0.64668974 0.5625    ], G Loss: 0.6132428050041199\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 162, D Loss: [0.65103811 0.640625  ], G Loss: 0.61024010181427\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 163, D Loss: [0.64934275 0.578125  ], G Loss: 0.6159394979476929\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 164, D Loss: [0.65689173 0.53125   ], G Loss: 0.6132669448852539\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 165, D Loss: [0.65916753 0.53125   ], G Loss: 0.6005462408065796\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 166, D Loss: [0.63824923 0.59375   ], G Loss: 0.6130353212356567\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 167, D Loss: [0.6620298 0.5625   ], G Loss: 0.5950567126274109\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 168, D Loss: [0.62361562 0.5625    ], G Loss: 0.604350209236145\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 169, D Loss: [0.65206489 0.59375   ], G Loss: 0.600648820400238\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 170, D Loss: [0.6327959 0.609375 ], G Loss: 0.6069786548614502\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 171, D Loss: [0.64806765 0.640625  ], G Loss: 0.5903216004371643\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 172, D Loss: [0.68521482 0.515625  ], G Loss: 0.6174726486206055\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 173, D Loss: [0.64369097 0.546875  ], G Loss: 0.6043440103530884\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 174, D Loss: [0.65883476 0.546875  ], G Loss: 0.6164007782936096\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 175, D Loss: [0.65753987 0.578125  ], G Loss: 0.6027202606201172\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 176, D Loss: [0.64166191 0.609375  ], G Loss: 0.6075184345245361\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 177, D Loss: [0.63957119 0.625     ], G Loss: 0.5968949794769287\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 178, D Loss: [0.66957501 0.53125   ], G Loss: 0.6101856827735901\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 179, D Loss: [0.67245534 0.578125  ], G Loss: 0.6159403324127197\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 180, D Loss: [0.67120063 0.546875  ], G Loss: 0.5912246704101562\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 181, D Loss: [0.65885147 0.546875  ], G Loss: 0.6175699234008789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 182, D Loss: [0.65915859 0.65625   ], G Loss: 0.6003433465957642\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 183, D Loss: [0.68225351 0.546875  ], G Loss: 0.6105936765670776\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 184, D Loss: [0.65918717 0.59375   ], G Loss: 0.6215112805366516\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 185, D Loss: [0.66835007 0.65625   ], G Loss: 0.6199720501899719\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 186, D Loss: [0.66763657 0.625     ], G Loss: 0.6210699081420898\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 187, D Loss: [0.66644579 0.578125  ], G Loss: 0.6128672361373901\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 188, D Loss: [0.6629456 0.625    ], G Loss: 0.610023021697998\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 189, D Loss: [0.67162257 0.5625    ], G Loss: 0.6148214340209961\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 190, D Loss: [0.66783202 0.59375   ], G Loss: 0.6262596845626831\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 191, D Loss: [0.67135906 0.578125  ], G Loss: 0.6136577129364014\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 192, D Loss: [0.64680704 0.5625    ], G Loss: 0.6162789463996887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 193, D Loss: [0.64898854 0.65625   ], G Loss: 0.6043462753295898\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 194, D Loss: [0.64352739 0.640625  ], G Loss: 0.6081678867340088\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 195, D Loss: [0.66043088 0.578125  ], G Loss: 0.6064416170120239\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 196, D Loss: [0.63462204 0.609375  ], G Loss: 0.613034725189209\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 197, D Loss: [0.64536786 0.640625  ], G Loss: 0.6171072721481323\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 198, D Loss: [0.65658575 0.59375   ], G Loss: 0.6188418865203857\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 199, D Loss: [0.64045784 0.609375  ], G Loss: 0.6190701723098755\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 200, D Loss: [0.66405508 0.53125   ], G Loss: 0.6287683248519897\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 201, D Loss: [0.66863722 0.640625  ], G Loss: 0.6163390874862671\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 202, D Loss: [0.63383669 0.625     ], G Loss: 0.6188578605651855\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 203, D Loss: [0.65793535 0.640625  ], G Loss: 0.6138882637023926\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 204, D Loss: [0.69155601 0.5       ], G Loss: 0.6055330038070679\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 205, D Loss: [0.64463151 0.609375  ], G Loss: 0.6211107969284058\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 206, D Loss: [0.64868769 0.609375  ], G Loss: 0.6310208439826965\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 207, D Loss: [0.66656297 0.5625    ], G Loss: 0.6300491094589233\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 208, D Loss: [0.66507262 0.546875  ], G Loss: 0.6147894859313965\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 209, D Loss: [0.65287867 0.609375  ], G Loss: 0.6119809150695801\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 210, D Loss: [0.64031035 0.625     ], G Loss: 0.6170068979263306\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 211, D Loss: [0.65494317 0.546875  ], G Loss: 0.6209270358085632\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 212, D Loss: [0.63224304 0.65625   ], G Loss: 0.6182808876037598\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 213, D Loss: [0.66513324 0.5625    ], G Loss: 0.613741934299469\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 214, D Loss: [0.64105448 0.59375   ], G Loss: 0.6211276650428772\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 215, D Loss: [0.66789085 0.59375   ], G Loss: 0.6279447078704834\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 216, D Loss: [0.66042128 0.5625    ], G Loss: 0.6317782998085022\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 217, D Loss: [0.62494789 0.65625   ], G Loss: 0.6191900372505188\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 218, D Loss: [0.66849715 0.59375   ], G Loss: 0.6375163793563843\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 219, D Loss: [0.65698788 0.59375   ], G Loss: 0.6348714232444763\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 220, D Loss: [0.64517495 0.609375  ], G Loss: 0.6362227201461792\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 221, D Loss: [0.64051139 0.546875  ], G Loss: 0.6259032487869263\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 222, D Loss: [0.64734703 0.515625  ], G Loss: 0.6538633108139038\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 223, D Loss: [0.65374839 0.53125   ], G Loss: 0.6441160440444946\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 224, D Loss: [0.64706346 0.625     ], G Loss: 0.6466501951217651\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 225, D Loss: [0.63625506 0.609375  ], G Loss: 0.6450561285018921\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 226, D Loss: [0.65482485 0.5625    ], G Loss: 0.6448636054992676\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 227, D Loss: [0.64810365 0.625     ], G Loss: 0.6440256834030151\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 228, D Loss: [0.64420903 0.609375  ], G Loss: 0.6415939331054688\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 229, D Loss: [0.63778034 0.640625  ], G Loss: 0.641713559627533\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 230, D Loss: [0.6378777 0.625    ], G Loss: 0.6477110385894775\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 231, D Loss: [0.65241247 0.640625  ], G Loss: 0.6615254878997803\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 232, D Loss: [0.62574649 0.609375  ], G Loss: 0.6345872282981873\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 233, D Loss: [0.64425036 0.5625    ], G Loss: 0.6515992879867554\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 234, D Loss: [0.64156848 0.5625    ], G Loss: 0.6559619903564453\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 235, D Loss: [0.64139864 0.59375   ], G Loss: 0.6504659652709961\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 236, D Loss: [0.63930044 0.546875  ], G Loss: 0.6531550884246826\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 237, D Loss: [0.61005518 0.703125  ], G Loss: 0.6390495300292969\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 238, D Loss: [0.64176238 0.5625    ], G Loss: 0.6365691423416138\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 239, D Loss: [0.63786975 0.546875  ], G Loss: 0.6402314901351929\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 240, D Loss: [0.6532416 0.640625 ], G Loss: 0.6564540863037109\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 241, D Loss: [0.64639845 0.59375   ], G Loss: 0.646094799041748\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 242, D Loss: [0.62273835 0.578125  ], G Loss: 0.6569317579269409\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 243, D Loss: [0.61609153 0.6875    ], G Loss: 0.6472402215003967\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 244, D Loss: [0.6351172 0.609375 ], G Loss: 0.6598321795463562\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 245, D Loss: [0.64240772 0.578125  ], G Loss: 0.6405484676361084\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 246, D Loss: [0.63617182 0.625     ], G Loss: 0.6418019533157349\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 247, D Loss: [0.65465561 0.609375  ], G Loss: 0.6404869556427002\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 248, D Loss: [0.63560295 0.671875  ], G Loss: 0.6306151747703552\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 249, D Loss: [0.64537686 0.640625  ], G Loss: 0.6451835632324219\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 250, D Loss: [0.6298224 0.625    ], G Loss: 0.63838791847229\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 251, D Loss: [0.63141701 0.65625   ], G Loss: 0.6356731653213501\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 252, D Loss: [0.63722599 0.671875  ], G Loss: 0.6407934427261353\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 253, D Loss: [0.6348938 0.578125 ], G Loss: 0.6477980613708496\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 254, D Loss: [0.64418596 0.59375   ], G Loss: 0.6436986923217773\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 255, D Loss: [0.64288539 0.609375  ], G Loss: 0.6572960615158081\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 256, D Loss: [0.63659316 0.640625  ], G Loss: 0.6568220853805542\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 257, D Loss: [0.64397246 0.65625   ], G Loss: 0.6470506191253662\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 258, D Loss: [0.62606677 0.640625  ], G Loss: 0.6415949463844299\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 259, D Loss: [0.65781879 0.625     ], G Loss: 0.6582461595535278\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 260, D Loss: [0.64491478 0.59375   ], G Loss: 0.6503594517707825\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 261, D Loss: [0.6376631 0.640625 ], G Loss: 0.6313974857330322\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 262, D Loss: [0.65982217 0.5625    ], G Loss: 0.6529251337051392\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 263, D Loss: [0.63024977 0.625     ], G Loss: 0.6470068097114563\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 264, D Loss: [0.64258447 0.65625   ], G Loss: 0.6358507871627808\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 265, D Loss: [0.64939216 0.578125  ], G Loss: 0.6581298112869263\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 266, D Loss: [0.63087627 0.6875    ], G Loss: 0.6508767008781433\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 267, D Loss: [0.63311723 0.625     ], G Loss: 0.6536175608634949\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 268, D Loss: [0.62802288 0.75      ], G Loss: 0.6538876891136169\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 269, D Loss: [0.62464249 0.640625  ], G Loss: 0.6348332166671753\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 270, D Loss: [0.64256579 0.5625    ], G Loss: 0.6628972291946411\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 271, D Loss: [0.63584635 0.609375  ], G Loss: 0.6446417570114136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 272, D Loss: [0.63065679 0.59375   ], G Loss: 0.6415170431137085\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 273, D Loss: [0.62945762 0.640625  ], G Loss: 0.6366157531738281\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 274, D Loss: [0.63746691 0.609375  ], G Loss: 0.6496878862380981\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 275, D Loss: [0.66401771 0.546875  ], G Loss: 0.6458261013031006\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 276, D Loss: [0.63291183 0.640625  ], G Loss: 0.6438743472099304\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 277, D Loss: [0.64927161 0.59375   ], G Loss: 0.6647628545761108\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 278, D Loss: [0.64951769 0.5625    ], G Loss: 0.6391212940216064\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 279, D Loss: [0.6427598 0.5625   ], G Loss: 0.6571673154830933\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 280, D Loss: [0.62678021 0.671875  ], G Loss: 0.6532628536224365\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 281, D Loss: [0.65091828 0.609375  ], G Loss: 0.6583143472671509\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 282, D Loss: [0.62863654 0.5625    ], G Loss: 0.6576229333877563\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 283, D Loss: [0.64911455 0.515625  ], G Loss: 0.6260585188865662\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 284, D Loss: [0.62316903 0.625     ], G Loss: 0.6450427770614624\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 285, D Loss: [0.6391243 0.640625 ], G Loss: 0.6379549503326416\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 286, D Loss: [0.63638973 0.75      ], G Loss: 0.6496521234512329\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 287, D Loss: [0.63217759 0.609375  ], G Loss: 0.6476049423217773\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 288, D Loss: [0.66821477 0.5625    ], G Loss: 0.6400320529937744\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 289, D Loss: [0.62347026 0.625     ], G Loss: 0.6630408763885498\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 290, D Loss: [0.64445451 0.625     ], G Loss: 0.6467153429985046\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 291, D Loss: [0.62215796 0.59375   ], G Loss: 0.644458532333374\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 292, D Loss: [0.62012666 0.71875   ], G Loss: 0.6476960182189941\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 293, D Loss: [0.63553244 0.609375  ], G Loss: 0.6541124582290649\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 294, D Loss: [0.63755864 0.59375   ], G Loss: 0.6679989099502563\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 295, D Loss: [0.63550675 0.71875   ], G Loss: 0.6335091590881348\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 296, D Loss: [0.63121498 0.671875  ], G Loss: 0.6456568241119385\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 297, D Loss: [0.64468479 0.609375  ], G Loss: 0.6528568863868713\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 298, D Loss: [0.61293349 0.640625  ], G Loss: 0.6617132425308228\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 299, D Loss: [0.64069289 0.671875  ], G Loss: 0.6465282440185547\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 300, D Loss: [0.65011135 0.578125  ], G Loss: 0.6333609819412231\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 301, D Loss: [0.64446953 0.578125  ], G Loss: 0.643484354019165\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 302, D Loss: [0.64682913 0.671875  ], G Loss: 0.6424812078475952\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 303, D Loss: [0.60123998 0.71875   ], G Loss: 0.6450316905975342\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 304, D Loss: [0.66827643 0.59375   ], G Loss: 0.6516214609146118\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 305, D Loss: [0.65268651 0.59375   ], G Loss: 0.6410535573959351\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 306, D Loss: [0.65551338 0.515625  ], G Loss: 0.6477691531181335\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 307, D Loss: [0.62506746 0.625     ], G Loss: 0.6463654041290283\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 308, D Loss: [0.64748949 0.59375   ], G Loss: 0.6565791964530945\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 309, D Loss: [0.64262921 0.59375   ], G Loss: 0.6579829454421997\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 310, D Loss: [0.6245527 0.6875   ], G Loss: 0.6580695509910583\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 311, D Loss: [0.63322911 0.546875  ], G Loss: 0.6446937918663025\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 312, D Loss: [0.62725794 0.65625   ], G Loss: 0.6896586418151855\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 313, D Loss: [0.61628368 0.671875  ], G Loss: 0.6629410982131958\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 314, D Loss: [0.65058336 0.5625    ], G Loss: 0.6548824310302734\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 315, D Loss: [0.63435918 0.59375   ], G Loss: 0.6542800068855286\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 316, D Loss: [0.65349066 0.578125  ], G Loss: 0.6489976644515991\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 317, D Loss: [0.65245414 0.546875  ], G Loss: 0.6604459285736084\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 318, D Loss: [0.65660205 0.65625   ], G Loss: 0.6659310460090637\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 319, D Loss: [0.64249572 0.5625    ], G Loss: 0.644556999206543\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 320, D Loss: [0.63030358 0.59375   ], G Loss: 0.6278905868530273\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 321, D Loss: [0.64545766 0.59375   ], G Loss: 0.6550191640853882\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 322, D Loss: [0.63104397 0.640625  ], G Loss: 0.648608922958374\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 323, D Loss: [0.63645843 0.609375  ], G Loss: 0.6698644161224365\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 324, D Loss: [0.6188094 0.578125 ], G Loss: 0.6401424407958984\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 325, D Loss: [0.60811377 0.671875  ], G Loss: 0.6347918510437012\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 326, D Loss: [0.63292426 0.671875  ], G Loss: 0.6612963080406189\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 327, D Loss: [0.63173574 0.625     ], G Loss: 0.6464712023735046\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 328, D Loss: [0.63372779 0.5625    ], G Loss: 0.6633850336074829\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 329, D Loss: [0.61948782 0.5625    ], G Loss: 0.6500058770179749\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 330, D Loss: [0.63132191 0.609375  ], G Loss: 0.6470763087272644\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 331, D Loss: [0.62542644 0.53125   ], G Loss: 0.6534583568572998\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 332, D Loss: [0.63718402 0.5625    ], G Loss: 0.6561634540557861\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 333, D Loss: [0.62882686 0.65625   ], G Loss: 0.663023054599762\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 334, D Loss: [0.61355083 0.6875    ], G Loss: 0.6552441716194153\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 335, D Loss: [0.63449886 0.6875    ], G Loss: 0.6645867824554443\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 336, D Loss: [0.65567499 0.53125   ], G Loss: 0.6482486724853516\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 337, D Loss: [0.61599737 0.6875    ], G Loss: 0.6421172618865967\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 338, D Loss: [0.66431358 0.53125   ], G Loss: 0.6618785858154297\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 339, D Loss: [0.63943118 0.625     ], G Loss: 0.6716670393943787\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 340, D Loss: [0.64545578 0.53125   ], G Loss: 0.6667837500572205\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 341, D Loss: [0.62217548 0.6875    ], G Loss: 0.6563779711723328\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 342, D Loss: [0.62960547 0.640625  ], G Loss: 0.6510553359985352\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 343, D Loss: [0.62403888 0.65625   ], G Loss: 0.6640326380729675\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 344, D Loss: [0.61780703 0.71875   ], G Loss: 0.6573739647865295\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 345, D Loss: [0.62017223 0.65625   ], G Loss: 0.6553043127059937\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 346, D Loss: [0.60295548 0.734375  ], G Loss: 0.6552160978317261\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 347, D Loss: [0.6197412 0.6875   ], G Loss: 0.6619834303855896\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 348, D Loss: [0.6419338 0.59375  ], G Loss: 0.659214973449707\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 349, D Loss: [0.62365839 0.703125  ], G Loss: 0.6465483903884888\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 350, D Loss: [0.64119083 0.625     ], G Loss: 0.6498461961746216\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 351, D Loss: [0.62724674 0.71875   ], G Loss: 0.6419087648391724\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 352, D Loss: [0.63506615 0.5625    ], G Loss: 0.6756424903869629\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 353, D Loss: [0.64195335 0.59375   ], G Loss: 0.6535992622375488\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 354, D Loss: [0.63334471 0.609375  ], G Loss: 0.6592720746994019\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 355, D Loss: [0.6532394 0.640625 ], G Loss: 0.6703108549118042\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 356, D Loss: [0.64184178 0.609375  ], G Loss: 0.6530307531356812\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 357, D Loss: [0.63927585 0.625     ], G Loss: 0.6481197476387024\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 358, D Loss: [0.63112584 0.5625    ], G Loss: 0.6504639387130737\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 359, D Loss: [0.62769642 0.65625   ], G Loss: 0.6346791386604309\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 360, D Loss: [0.66395527 0.578125  ], G Loss: 0.6479930281639099\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 361, D Loss: [0.6462664 0.65625  ], G Loss: 0.6436644792556763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 362, D Loss: [0.62394577 0.6875    ], G Loss: 0.6452947854995728\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 363, D Loss: [0.65727001 0.546875  ], G Loss: 0.6299070119857788\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 364, D Loss: [0.64210176 0.578125  ], G Loss: 0.6297382116317749\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 365, D Loss: [0.63722271 0.609375  ], G Loss: 0.6276394724845886\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 366, D Loss: [0.65494621 0.53125   ], G Loss: 0.6574239730834961\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 367, D Loss: [0.65797412 0.515625  ], G Loss: 0.648411214351654\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 368, D Loss: [0.65726316 0.578125  ], G Loss: 0.6429783701896667\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 369, D Loss: [0.62047639 0.5625    ], G Loss: 0.6671512722969055\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 370, D Loss: [0.62800485 0.640625  ], G Loss: 0.6490589380264282\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 371, D Loss: [0.65177882 0.546875  ], G Loss: 0.6439886093139648\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 372, D Loss: [0.65025613 0.578125  ], G Loss: 0.6396153569221497\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 373, D Loss: [0.6460529 0.609375 ], G Loss: 0.6265132427215576\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 374, D Loss: [0.63926631 0.578125  ], G Loss: 0.62846839427948\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 375, D Loss: [0.64350548 0.59375   ], G Loss: 0.6361043453216553\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 376, D Loss: [0.63841337 0.546875  ], G Loss: 0.627839982509613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 377, D Loss: [0.64885595 0.546875  ], G Loss: 0.638190746307373\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 378, D Loss: [0.63362324 0.578125  ], G Loss: 0.6272299289703369\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 379, D Loss: [0.65899378 0.5       ], G Loss: 0.6386349201202393\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 380, D Loss: [0.63659656 0.640625  ], G Loss: 0.6424863934516907\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 381, D Loss: [0.63676137 0.609375  ], G Loss: 0.6321092247962952\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 382, D Loss: [0.65296119 0.5       ], G Loss: 0.6271765232086182\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 383, D Loss: [0.62763584 0.59375   ], G Loss: 0.6313797235488892\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 384, D Loss: [0.65822074 0.578125  ], G Loss: 0.6271107196807861\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 385, D Loss: [0.65955931 0.484375  ], G Loss: 0.6276540160179138\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 386, D Loss: [0.67726251 0.484375  ], G Loss: 0.6196528077125549\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 387, D Loss: [0.6632129 0.4375   ], G Loss: 0.6187562942504883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 388, D Loss: [0.64502808 0.5625    ], G Loss: 0.6379754543304443\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 389, D Loss: [0.66045731 0.546875  ], G Loss: 0.6288508772850037\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 390, D Loss: [0.65529364 0.515625  ], G Loss: 0.636072039604187\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 391, D Loss: [0.65545869 0.5625    ], G Loss: 0.6273975372314453\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 392, D Loss: [0.62973066 0.53125   ], G Loss: 0.6359618902206421\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 393, D Loss: [0.64508188 0.546875  ], G Loss: 0.647181510925293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 394, D Loss: [0.64497072 0.5625    ], G Loss: 0.6476194858551025\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 395, D Loss: [0.64665672 0.59375   ], G Loss: 0.6248883008956909\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 396, D Loss: [0.62783632 0.625     ], G Loss: 0.643427312374115\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 397, D Loss: [0.62162957 0.5625    ], G Loss: 0.6566653251647949\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 398, D Loss: [0.64247677 0.609375  ], G Loss: 0.6655722260475159\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 399, D Loss: [0.64885426 0.640625  ], G Loss: 0.6284947395324707\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 400, D Loss: [0.62778452 0.65625   ], G Loss: 0.629267692565918\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 401, D Loss: [0.62787643 0.59375   ], G Loss: 0.6211717128753662\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 402, D Loss: [0.63227117 0.609375  ], G Loss: 0.6241478323936462\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 403, D Loss: [0.67435542 0.515625  ], G Loss: 0.6207261085510254\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 404, D Loss: [0.66529348 0.546875  ], G Loss: 0.6218528747558594\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 405, D Loss: [0.66679597 0.53125   ], G Loss: 0.6498477458953857\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 406, D Loss: [0.66623822 0.546875  ], G Loss: 0.6529498100280762\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 407, D Loss: [0.66622478 0.53125   ], G Loss: 0.6425647735595703\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 408, D Loss: [0.66898429 0.546875  ], G Loss: 0.6264281272888184\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 409, D Loss: [0.66895452 0.609375  ], G Loss: 0.6257007122039795\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 410, D Loss: [0.65681341 0.625     ], G Loss: 0.6362011432647705\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 411, D Loss: [0.65882558 0.515625  ], G Loss: 0.6129918098449707\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 412, D Loss: [0.65807426 0.53125   ], G Loss: 0.6402485370635986\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 413, D Loss: [0.65360421 0.578125  ], G Loss: 0.628724217414856\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 414, D Loss: [0.68369183 0.484375  ], G Loss: 0.6345841884613037\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 415, D Loss: [0.6847887 0.515625 ], G Loss: 0.6407465934753418\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 416, D Loss: [0.67695528 0.46875   ], G Loss: 0.6296108961105347\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 417, D Loss: [0.65322593 0.53125   ], G Loss: 0.6429647207260132\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 418, D Loss: [0.6688922 0.515625 ], G Loss: 0.633090615272522\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 419, D Loss: [0.65871447 0.53125   ], G Loss: 0.6411739587783813\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 420, D Loss: [0.65171239 0.515625  ], G Loss: 0.6438286900520325\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 421, D Loss: [0.63324851 0.515625  ], G Loss: 0.6443783044815063\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 422, D Loss: [0.65722474 0.5625    ], G Loss: 0.6385781168937683\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 423, D Loss: [0.6558066 0.53125  ], G Loss: 0.6412590742111206\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 424, D Loss: [0.65267637 0.546875  ], G Loss: 0.6386772990226746\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 425, D Loss: [0.63070032 0.609375  ], G Loss: 0.6378363966941833\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 426, D Loss: [0.65876377 0.578125  ], G Loss: 0.6175194978713989\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 427, D Loss: [0.65002942 0.546875  ], G Loss: 0.6313770413398743\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 428, D Loss: [0.64124051 0.625     ], G Loss: 0.632204532623291\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 429, D Loss: [0.63784972 0.625     ], G Loss: 0.636275589466095\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 430, D Loss: [0.64123675 0.53125   ], G Loss: 0.6459416151046753\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 431, D Loss: [0.65460047 0.578125  ], G Loss: 0.6453604102134705\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 432, D Loss: [0.66920775 0.609375  ], G Loss: 0.6125229597091675\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 433, D Loss: [0.64016274 0.59375   ], G Loss: 0.6352934837341309\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 434, D Loss: [0.68075454 0.515625  ], G Loss: 0.6344683170318604\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 435, D Loss: [0.64141598 0.640625  ], G Loss: 0.6327461004257202\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 436, D Loss: [0.64359191 0.59375   ], G Loss: 0.6380636692047119\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 437, D Loss: [0.64775485 0.59375   ], G Loss: 0.6475799083709717\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 438, D Loss: [0.6441727 0.625    ], G Loss: 0.6451151967048645\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 439, D Loss: [0.65768442 0.578125  ], G Loss: 0.6245403289794922\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 440, D Loss: [0.67194903 0.5625    ], G Loss: 0.6292169094085693\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 441, D Loss: [0.65127119 0.515625  ], G Loss: 0.6395243406295776\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 442, D Loss: [0.66647717 0.59375   ], G Loss: 0.6401312351226807\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 443, D Loss: [0.67439011 0.53125   ], G Loss: 0.6546227931976318\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 444, D Loss: [0.65610874 0.578125  ], G Loss: 0.6607300043106079\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 445, D Loss: [0.65525168 0.515625  ], G Loss: 0.656477689743042\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 446, D Loss: [0.6370199 0.59375  ], G Loss: 0.6525228023529053\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 447, D Loss: [0.65759015 0.546875  ], G Loss: 0.6480636596679688\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 448, D Loss: [0.64864025 0.609375  ], G Loss: 0.6530842781066895\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 449, D Loss: [0.62743157 0.65625   ], G Loss: 0.660444974899292\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 450, D Loss: [0.64640564 0.625     ], G Loss: 0.6407666802406311\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 451, D Loss: [0.63575557 0.59375   ], G Loss: 0.6500821113586426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 452, D Loss: [0.66350833 0.59375   ], G Loss: 0.6519198417663574\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 453, D Loss: [0.67073336 0.578125  ], G Loss: 0.6520787477493286\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 454, D Loss: [0.64927918 0.5625    ], G Loss: 0.6527178287506104\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 455, D Loss: [0.65255362 0.546875  ], G Loss: 0.6526243686676025\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 456, D Loss: [0.673825 0.546875], G Loss: 0.654550313949585\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 457, D Loss: [0.64575911 0.5625    ], G Loss: 0.6616483926773071\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 458, D Loss: [0.63828123 0.59375   ], G Loss: 0.6483160257339478\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 459, D Loss: [0.6568262 0.53125  ], G Loss: 0.6548190116882324\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 460, D Loss: [0.64224342 0.578125  ], G Loss: 0.653694748878479\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 461, D Loss: [0.64898816 0.625     ], G Loss: 0.6601409316062927\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 462, D Loss: [0.64463067 0.625     ], G Loss: 0.6431792378425598\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 463, D Loss: [0.63455921 0.53125   ], G Loss: 0.6522580981254578\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 464, D Loss: [0.64037421 0.5       ], G Loss: 0.6648924350738525\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 465, D Loss: [0.64231351 0.546875  ], G Loss: 0.6544588208198547\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 466, D Loss: [0.63577992 0.484375  ], G Loss: 0.6462733149528503\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 467, D Loss: [0.65960884 0.53125   ], G Loss: 0.6509105563163757\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 468, D Loss: [0.62355143 0.59375   ], G Loss: 0.6497910022735596\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 469, D Loss: [0.63820371 0.609375  ], G Loss: 0.6652646064758301\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 470, D Loss: [0.64906517 0.484375  ], G Loss: 0.6496748924255371\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 471, D Loss: [0.63967139 0.546875  ], G Loss: 0.6729888319969177\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 472, D Loss: [0.66075689 0.546875  ], G Loss: 0.6756531596183777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 473, D Loss: [0.67341676 0.53125   ], G Loss: 0.6568059921264648\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 474, D Loss: [0.64253518 0.65625   ], G Loss: 0.6614050269126892\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 475, D Loss: [0.64221525 0.609375  ], G Loss: 0.6681911945343018\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 476, D Loss: [0.63806993 0.65625   ], G Loss: 0.6601788997650146\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 477, D Loss: [0.65296453 0.640625  ], G Loss: 0.6613597869873047\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 478, D Loss: [0.64804813 0.609375  ], G Loss: 0.6787747144699097\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 479, D Loss: [0.66252667 0.5625    ], G Loss: 0.6603797674179077\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 480, D Loss: [0.64046222 0.625     ], G Loss: 0.6977798938751221\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 481, D Loss: [0.6511988 0.53125  ], G Loss: 0.6692200899124146\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 482, D Loss: [0.6389606 0.546875 ], G Loss: 0.6684846878051758\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 483, D Loss: [0.63868198 0.6875    ], G Loss: 0.6691478490829468\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 484, D Loss: [0.63442856 0.640625  ], G Loss: 0.684705376625061\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 485, D Loss: [0.64316237 0.625     ], G Loss: 0.6855366230010986\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 486, D Loss: [0.65598875 0.609375  ], G Loss: 0.6652558445930481\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 487, D Loss: [0.64916515 0.625     ], G Loss: 0.6925970315933228\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 488, D Loss: [0.62993047 0.625     ], G Loss: 0.6978163123130798\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 489, D Loss: [0.64945897 0.5625    ], G Loss: 0.696814775466919\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 490, D Loss: [0.65868217 0.53125   ], G Loss: 0.6804822683334351\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 491, D Loss: [0.62956828 0.625     ], G Loss: 0.7087932825088501\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 492, D Loss: [0.63354996 0.625     ], G Loss: 0.6800545454025269\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 493, D Loss: [0.65366313 0.625     ], G Loss: 0.6881392002105713\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 494, D Loss: [0.65056089 0.515625  ], G Loss: 0.6768497824668884\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 495, D Loss: [0.6644381 0.59375  ], G Loss: 0.6738433837890625\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 496, D Loss: [0.63270131 0.640625  ], G Loss: 0.6976714134216309\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 497, D Loss: [0.64485967 0.609375  ], G Loss: 0.6884799003601074\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 498, D Loss: [0.63849911 0.546875  ], G Loss: 0.6848503947257996\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 499, D Loss: [0.6337533 0.5625   ], G Loss: 0.6864032745361328\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_gan(gan, generator, discriminator, features, epochs, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        # Randomly select real data points\n",
    "        idx = np.random.randint(0, features.shape[0], batch_size)\n",
    "        real_data = features[idx]\n",
    "\n",
    "        # Generate fake data\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_data = generator.predict(noise)\n",
    "        print(\"Shape of real data:\", real_data.shape)\n",
    "        print(\"Shape of fake data:\", fake_data.shape)\n",
    "\n",
    "        # Labels for real and fake data\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(real_data, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_data, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train the generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(noise, real_labels)\n",
    "\n",
    "        # Optionally, print the progress\n",
    "        print(f\"Epoch: {epoch}, D Loss: {d_loss}, G Loss: {g_loss}\")\n",
    "\n",
    "train_gan(gan, generator, discriminator, scaled_features, epochs=500, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf766442",
   "metadata": {},
   "source": [
    "# Step 3: Evaluate and Use the Synthetic Data\n",
    "Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eaa3fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhiklEQVR4nO3de5hV1X3/8fdnLjAqeIVWERRqMQo6oIxKfpr+SIx4qcbEeCE/NZEnapqYxqRWayOP0aiJaU1s1XiNRo3GJF5KjSVtJNEEn1gVrCKXCJjQMBF1JAoCAjNzvr8/zp7xMM4NOHsOM+vzep7zzNln77P3WoPuz6y19tpbEYGZmaWrqtIFMDOzynIQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgljNJP5P0mTLt60OSXi5ZXi7po+XYd7a/hZKmlGt/1j84CKxsspPSu5LWlrxGlGGfZTvRbeGxfykpJNV0s01IWpfVdZWkX0g6o3SbiDg+Iu7pxfFC0l92t01EzImID/S+Ft0e725JV3fY//iIeLIc+7f+w0Fg5XZSRAwpeb1aycJ0dxLv4XtnAr397oSIGAJ8ALgbuEnS17bmuD2UaavqYtYTB4HlTtIuku6UtFLSHyVdLak6W7df9pf3KklvSrpf0q7Zuh8A+wA/zf7ivkTSFEmNHfbf3mqQdIWkhyTdJ2kNcE53x++qvMDXgEu2pJ4R8WZE/AD4PPCPkvbI9vekpHOz938p6VeSVmf1/XH2+a+z3byY1fWMtrpK+gdJrwHf76z+wGGSFkl6S9L3JdVl+zxH0lMd6hZZGc4HzgQuyY73005+l4Ml/YukV7PXv0ganK1rK9tFkt7IfrfTt+T3ZdsPB4H1hXuAFuAvgUOAqcC52ToB3wRGAAcCo4ArACLibOAPvNfK+KdeHu9k4CFgV+D+Ho7fmW8AtwCv9fJ4Hf07xdbE4Z2suwr4ObAbMBK4ESAi/ipbPyGr64+z5T2B3YF9gfO7ON6ZwLHAfsD+wIyeChgRt1P83fxTdryTOtnsMmAyMBGYkNWndN97ArsAewOfBb4rabeejm3bHweBldtMSW9nr5mS/hw4HvhyRKyLiDeA64FpABGxLCIej4iNEdEEfAf4v9tYhqcjYmZEFICduzt+R5IagCPJTtBbIyKagTcpnsA7aqZ4Uh8RERsi4qlOtilVAL6W/X7e7WKbmyJiRUT8CbgG+NTWlr2DM4GvR8Qb2b/NlcDZJeubs/XNETELWEuxe8z6Gfc5Wrl9PCJmty1IOhyoBVZKavu4CliRrf8z4AbgQ8DQbN1b21iGFSXv9+3u+KUkVQE3AxdGREvJ9ltEUi0wHPhTJ6svodgqeFbSW8C3I+KubnbXFBEbejhkaV3+l2LrqhxGZPvrat+rIqKlZHk9MKRMx7Y+5CCwvK0ANgLDOpw02nwTCKA+IlZJ+jhwU8n6jrfHXQfs2LaQ9fUP77BN6Xd6On6pnYEG4MdZCLSNIzRKOi0i5vTw/TYnU+yKerbjioh4DTgvK/tRwGxJv46IZV3sqze3Bx5V8n4foG2AvuPvas8t3PerFIN0YSf7tgHEXUOWq4hYSbFP/NuSdpZUlQ0Qt3X/DKXYpfC2pL2Bizvs4nXgL0qWlwB1kv46+8t7BjB4G45fajXFv3gnZq8Tss8nAc/0VFdJu2dXG30X+FZErOpkm9MkjcwW36J4Mm7toq69dYGkkZJ2B74KtI0vvAiMlzQxG0C+osP3ejreA8AMScMlDQMuB+7bivLZds5BYH3h08AgYBHFk99DwF7ZuiuBQymehP8DeKTDd79J8WT0tqS/j4jVwBeA7wF/pPhXb8eraLbk+O2i6LW2F9CUrXo9IjZ1s/8XJa0FllEchP5KRFzexbaHAc9k2z9KsRvq99m6K4B7srqe3kOdSv2QYtj9LntdndVnCfB1YDawFOg4HnEnMK5tPKeT/V4NzAXmAy8Bz7ft2wYW+cE0ZmZpc4vAzCxxDgIzs8Q5CMzMEucgMDNLXL+bRzBs2LAYPXp0pYthZtavzJs3782I6DjnBuiHQTB69Gjmzp1b6WKYmfUrkv63q3XuGjIzS5yDwMwscQ4CM7PE9bsxAjMbmJqbm2lsbGTDhp5utmrdqaurY+TIkdTW1vb6Ow4CM9suNDY2MnToUEaPHs3W3gI8dRHBqlWraGxsZMyYMb3+nruGzGy7sGHDBvbYYw+HwDaQxB577LHFrSoHgZltNxwC225rfocOAjOzxCUfBK+t3kDD1Y+z7I21lS6KmVVYY2MjJ598MmPHjmW//fbjwgsvZNOm9z+K4tVXX+XUU0/tcX8nnHACb7/99laV5YorruC6667bqu9uqeSD4I9vv8ubazex4k/rK10UM6ugiOCUU07h4x//OEuXLmXJkiWsXbuWyy67bLPtWlpaGDFiBA899FCP+5w1axa77rprTiUun+SDoO3BPAU/oMcsab/85S+pq6tj+vTpAFRXV3P99ddz1113cfPNN3Paaadx0kknMXXqVJYvX85BBx0EwPr16zn99NOpr6/njDPO4Igjjmi/Dc7o0aN58803Wb58OQceeCDnnXce48ePZ+rUqbz77rsA3HHHHRx22GFMmDCBT37yk6xf3/d/lCZ/+WghNv9pZpV35U8XsujVNWXd57gRO/O1k8Z3uX7hwoVMmjRps8923nln9tlnH1paWnj66aeZP38+u+++O8uXL2/f5uabb2a33XZj/vz5LFiwgIkTJ3a6/6VLl/LAAw9wxx13cPrpp/Pwww9z1llnccopp3DeeecBMGPGDO68807+9m//dpvruyWSbxEU3CIwM4q9A51dcdP2+THHHMPuu+/+vvVPPfUU06ZNA+Cggw6ivr6+0/2PGTOmPSQmTZrUHiYLFizgQx/6EAcffDD3338/CxcuLE+FtoBbBFkA+NnNZtuP7v5yz8v48eN5+OGHN/tszZo1rFixgurqanbaaadOv9fbc8fgwYPb31dXV7d3DZ1zzjnMnDmTCRMmcPfdd/Pkk09uXQW2QfItgnDXkJkBRx99NOvXr+fee+8FoLW1lYsuuohzzjmHHXfcscvvHXXUUfzkJz8BYNGiRbz00ktbdNx33nmHvfbai+bmZu6///6tr8A2cBC0B4GTwCxlkvi3f/s3HnzwQcaOHcv+++9PXV0d3/jGN7r93he+8AWampqor6/nW9/6FvX19eyyyy69Pu5VV13FEUccwTHHHMMBBxywrdXYKupvXSINDQ1RzgfT/HpJE5++61lu/NQhnDRhRNn2a2ZbZvHixRx44IGVLsYWa21tpbm5mbq6Ol555RWOPvpolixZwqBBgypWps5+l5LmRURDZ9t7jMCDxWa2DdavX8+HP/xhmpubiQhuueWWiobA1kg+CNrO/84BM9saQ4cO7fePz81tjEDSKElPSFosaaGkCzvZZoqk1ZJeyF6X51WerrhFYGapy7NF0AJcFBHPSxoKzJP0eEQs6rDdnIg4McdydMsTyswsdbm1CCJiZUQ8n71/B1gM7J3X8baWWwRmlro+uXxU0mjgEOCZTlZ/UNKLkn4mqdNZJJLOlzRX0tympqayli08oczMEpd7EEgaAjwMfDkiOt485Hlg34iYANwIzOxsHxFxe0Q0RETD8OHDy1o+dw2ZWalrrrmG8ePHU19fz8SJE3nmmc7+fu3ezJkzWbTovV7wKVOmbNGA8vLly/nhD3/Yvjx37ly+9KUvbXE5eivXIJBUSzEE7o+IRzquj4g1EbE2ez8LqJU0LM8yvb8MxZ/uGjKzp59+mscee4znn3+e+fPnM3v2bEaNGrXF++kYBFuqYxA0NDRwww03bPX+epLnVUMC7gQWR8R3uthmz2w7JB2elWdVXmXqzHtjBH15VDPbHq1cuZJhw4a13xdo2LBhLF68mE984hPt2zz++OOccsopAAwZMoTLLruMCRMmMHnyZF5//XV+85vf8Oijj3LxxRczceJEXnnlFQAefPBBDj/8cPbff3/mzJkDFCejXXzxxRx22GHU19dz2223AXDppZcyZ84cJk6cyPXXX8+TTz7JiScWr6lZu3Yt06dP5+CDD6a+vv5990faGnleNXQkcDbwkqQXss++CuwDEBG3AqcCn5fUArwLTIs+7qz3TefMtkM/uxRe27J79vRoz4Ph+Gu73WTq1Kl8/etfZ//99+ejH/0oZ5xxBh/5yEe44IILaGpqYvjw4Xz/+99vf2bBunXrmDx5Mtdccw2XXHIJd9xxBzNmzOBjH/sYJ5544mZPMWtpaeHZZ59l1qxZXHnllcyePZs777yTXXbZheeee46NGzdy5JFHMnXqVK699lquu+46HnvsMYDNbkR31VVXscsuu7Tf0+itt97a5l9NbkEQEU8B3T5FOSJuAm7Kqwy94QllZtZmyJAhzJs3jzlz5vDEE09wxhlncO2113L22Wdz3333MX36dJ5++un2G9MNGjSo/S/1SZMm8fjjj3e577ZWROktqH/+858zf/789qedrV69mqVLl3Y7M3n27Nn86Ec/al/ebbfdtqnO4JnFvnzUbHvUw1/ueaqurmbKlClMmTKFgw8+mHvuuYfbbruNk046ibq6Ok477TRqaoqnztra2vZnGFRXV9PS0tLlftu6m0q3iwhuvPFGjj322M227e5W1F09N2FbJH/3UV81ZGZtXn75ZZYuXdq+/MILL7DvvvsyYsQIRowYwdVXX80555zT436GDh3KO++80+N2xx57LLfccgvNzc0ALFmyhHXr1nX7/alTp3LTTe91pJSja8hB4DECM8usXbuWz3zmM4wbN476+noWLVrEFVdcAcCZZ57JqFGjGDduXI/7mTZtGv/8z//MIYcc0j5Y3Jlzzz2XcePGceihh3LQQQfxuc99jpaWFurr66mpqWHChAlcf/31m31nxowZvPXWWxx00EFMmDCBJ554YpvqDL4NNT9+7g/8w8Mv8dUTDuD8v9qvbPs1sy2zvd+G+otf/CKHHHIIn/3sZytdlB75NtRbyF1DZtaTSZMmsdNOO/Htb3+70kXJRfJB4AllZtaTefPmVboIufIYQfsYQYULYmYeqyuDrfkdJh8Ebb+0gvuGzCqqrq6OVatWOQy2QUSwatUq6urqtuh7yXcNeYzAbPswcuRIGhsbKfcdhlNTV1fHyJEjt+g7DoK2riGcBGaVVFtby5gxYypdjCQl3zXkFoGZpS75IPCDacwsdckHge81ZGapcxC4a8jMEpd8EHhCmZmlLvkg8IQyM0td8kHgCWVmlrrkg8BjBGaWOgeBrxoys8Q5CNqfWewgMLM0JR8E7RPKKlwOM7NKST4I3DVkZqlzEHiw2MwS5yDwvYbMLHHJB0Hb4EChUNlimJlVSvJB4DECM0udg8BjBGaWOAeBxwjMLHHJB4HvPmpmqUs+CN4bI6hwQczMKiS3IJA0StITkhZLWijpwk62kaQbJC2TNF/SoXmVpyseLDaz1NXkuO8W4KKIeF7SUGCepMcjYlHJNscDY7PXEcAt2c8+036vob48qJnZdiS3FkFErIyI57P37wCLgb07bHYycG8U/Tewq6S98ipTF+Xc7KeZWWr6ZIxA0mjgEOCZDqv2BlaULDfy/rBA0vmS5kqa29TUVNayhSeUmVnicg8CSUOAh4EvR8Sajqs7+cr7/jSPiNsjoiEiGoYPH17W8nmMwMxSl2sQSKqlGAL3R8QjnWzSCIwqWR4JvJpnmTryhDIzS12eVw0JuBNYHBHf6WKzR4FPZ1cPTQZWR8TKvMrUGU8oM7PU5XnV0JHA2cBLkl7IPvsqsA9ARNwKzAJOAJYB64HpOZanU55QZmapyy0IIuIpOh8DKN0mgAvyKkNveEKZmaXOM4vdIjCzxDkI2scIKlwQM7MKST4IwpePmlniHASx+U8zs9QkHwSeUGZmqXMQuEVgZolLPgg8RmBmqUs+CHz5qJmlzkHgCWVmljgHQfsYgZPAzNKUfBCEWwRmlrjkg8CXj5pZ6pIPgvfuPlrZcpiZVUryQeDnEZhZ6hwEnlBmZolLPgg8oczMUpd8EHhCmZmlzkHg5xGYWeIcBG4RmFnikg8CTygzs9QlHwSeUGZmqXMQFIo/nQNmlqrkg6Dt/O8WgZmlykHgriEzS1yvgkDSw5L+WtKACw4/j8DMUtfbE/stwP8Dlkq6VtIBOZapT/kWE2aWul4FQUTMjogzgUOB5cDjkn4jabqk2jwLmDffdM7MUtfrrh5JewDnAOcC/wP8K8VgeDyXkvWRCJioZYwqNFa6KGZmFVHTm40kPQIcAPwAOCkiVmarfixpbl6F6wuFCGYOvjy7fGh6pYtjZtbnetsi+F5EjIuIb7aFgKTBABHR0NkXJN0l6Q1JC7pYP0XSakkvZK/Lt6oG28hXC5lZ6nobBFd38tnTPXznbuC4HraZExETs9fXe1mWsmqbUGZmlqpuu4Yk7QnsDewg6RBA2aqdgR27+25E/FrS6HIU0szM8tPTGMGxFAeIRwLfKfn8HeCrZTj+ByW9CLwK/H1ELCzDPreIu4bMLHXdBkFE3APcI+mTEfFwmY/9PLBvRKyVdAIwExjb2YaSzgfOB9hnn33KWggHgZmlrqeuobMi4j5gtKS/67g+Ir7Tydd6JSLWlLyfJelmScMi4s1Otr0duB2goaGhrGduzyg2s9T11DW0U/ZzSLkPnI0/vB4RIelwigPXq8p9nJ54IpmZpa6nrqHbsp9XbumOJT0ATAGGSWoEvgbUZvu7FTgV+LykFuBdYFpU4KzsFoGZpa63E8r+ieIlpO8C/wlMAL6cdRt1KiI+1d0+I+Im4KbeFzUfHiMws9T1dh7B1KxP/0SgEdgfuDi3UvWhQkmTwN1EZpai3gZB243lTgAeiIg/5VSePld67nc3kZmlqLdB8FNJvwUagF9IGg5syK9Yfaf03O9uIjNLUW9vQ30p8EGgISKagXXAyXkWrK+UnvwdBGaWol4NFmcOpDifoPQ795a5PH2u9OTvHDCzFPX2qqEfAPsBLwCt2cfBAAsCtwjMLEW9bRE0AOMqcZ1/3qqitf29B4vNLEW9HSxeAOyZZ0EqRfHefajdIjCzFPW2RTAMWCTpWWBj24cR8bFcStWXSloE4WcTmFmCehsEV+RZiEqJCKpLgwC3CMwsPb0Kgoj4laR9gbERMVvSjkB1vkXLXwRUUdo1VMHCmJlVSK/GCCSdBzwE3JZ9tDfF5wf0a4UIakqDwM+tNLME9Xaw+ALgSGANQEQsBf4sr0L1lQCqNwuClsoVxsysQnobBBsjYlPbQjaprN93pBQiNusaitbWbrY2MxuYehsEv5L0VYoPsT8GeBD4aX7F6hsRUEPJPAK3CMwsQb0NgkuBJuAl4HPALGBGXoXqK4UIqlTSIvAYgZklqLdXDRUkzQRmRkRTvkXqO4Vg88HiVrcIzCw93bYIVHSFpDeB3wIvS2qSdHnfFC9fHccI8BiBmSWop66hL1O8WuiwiNgjInYHjgCOlPSVvAuXtyh0uGrIU4vNLEE9BcGngU9FxO/bPoiI3wFnZev6tUIEtbzXHRTuGjKzBPUUBLUR8WbHD7NxgtpOtu9XChEMKg2CcNeQmaWnpyDYtJXr+oWAzYKAgoPAzNLT01VDEySt6eRzAXU5lKdPFSL4i6pX31t2EJhZgroNgojo9zeW604EfLP2zveWPaHMzBLU2wllA1LHB9FEq68aMrP0JB4EsCZ2aF92i8DMUpR2EBSCn7ROaV/2LSbMLEVJB0FEcdS7fdktAjNLUNJB8L7bUPuqITNLkIMA333UzNKWWxBIukvSG5IWdLFekm6QtEzSfEmH5lWWrgRQVfp8Hc8sNrME5dkiuBs4rpv1xwNjs9f5wC05lqVTEbFZEET0+4eumZltsdyCICJ+Dfypm01OBu6Nov8GdpW0V17l6Uwh6PCoSg8Wm1l6KjlGsDewomS5MfvsfSSdL2mupLlNTeV7Lk7BLQIzs4oGgTr5rNMzcUTcHhENEdEwfPjwshWgUNi8ReCbzplZiioZBI3AqJLlkcCrXWybi+Izi0tbBA4CM0tPJYPgUeDT2dVDk4HVEbGyLwsQHccIfPmomSWoVw+v3xqSHgCmAMMkNQJfI3uYTUTcCswCTgCWAeuB6XmVpSvvHyNwEJhZenILgoj4VA/rA7ggr+P3xvseXu8WgZklKOmZxQEIjxGYWdrSDoIIqt0iMLPEJR0ExQllHiMws7SlHQSF4mBxoe3X4HkEZpagtIMgu3w0qrIxc7cIzCxBSQdBZFcNFVSdLTsIzCw9SQdB2xhBqNgi8IQyM0tR4kEQiCCyFgHhu4+aWXocBASFtjGCgu8+ambpSToIou3y0fYxAl81ZGbpSTsIyLqGqtq6hjxGYGbpSToICgWo0nuDxZ5ZbGYpSjsIsjEC2lsE7hoys/QkHgRkXUNtE8o8WGxm6Uk6CKLteQRtXUNuEZhZgpIOgrYWQVvXkCeUmVmKEg+CrEXgew2ZWcKSDwJRKBksdhCYWXqSDoIIEJTMI/AYgZmlJ+0gIHtmsa8aMrOEJR0EhUKxRaAqXzVkZulKOwg6Dhb7qiEzS1DSQVAcIyj4qiEzS1rSQVC8agjkq4bMLGGJB0HxmcWqqqYQchCYWZISD4LiGIEkCgh5sNjMEpR0EER291FVVdFKlS8fNbMkJR0EbfcakqoI3DVkZmlKOgjaWgSoigJVnkdgZklKOggK2TOLpbauIbcIzCw9uQaBpOMkvSxpmaRLO1k/RdJqSS9kr8vzLE9HhQiqVYAqdw2ZWbpq8tqxpGrgu8AxQCPwnKRHI2JRh03nRMSJeZWjOxEwiBZUU5ddNeQgMLP05NkiOBxYFhG/i4hNwI+Ak3M83hYrRFDHJqgZTCvVvnzUzJKUZxDsDawoWW7MPuvog5JelPQzSeM725Gk8yXNlTS3qampbAUsBAymGdXWUaDKQWBmScozCNTJZx0v1H8e2DciJgA3AjM721FE3B4RDRHRMHz48LIVsFAoMFjNUDOYFqpRoaVs+zYz6y/yDIJGYFTJ8kjg1dINImJNRKzN3s8CaiUNy7FMm6kqbCy+qdmBVqqKN6AzM0tMnkHwHDBW0hhJg4BpwKOlG0jaU5Ky94dn5VmVY5k2U9VSDALV1tEqjxGYWZpyu2ooIlokfRH4L6AauCsiFkr6m2z9rcCpwOcltQDvAtMi+u4+D1WFTQCopo5WqqkqOAjMLD25BQG0d/fM6vDZrSXvbwJuyrMM3alq3QBQMljsMQIzS0/SM4urS4KgePmoxwjMLD1JB0FVa7FriLauIY8RmFmC0g6C9quGBtOqKqrcNWRmCUo6CKrbWwQ7EJ5QZmaJSjsICsUxgrauIY8RmFmKkg6CqtbSriGPEZhZmpIOgupsHgG1O1Cgmio8RmBm6Uk8CNq6hgZTUJVbBGaWpKSDoMaXj5qZpR0E1SWXjxbkwWIzS1PSQVBTcvfR4hiBWwRmlp6kg6C6sJEWqqC6hlaqqfaEMjNLUOJBsIlNDAKgVTUOAjNLUtJBUFPYxMYsCJpVS000V7hEZmZ9L/Eg2MgmagFocRCYWaKSDoLBrWtZpx0BB4GZpSvpIKgrrGMtOwHQqlqqHQRmlqCkg2CH1rWsUzEImlVLDa1Q8FwCM0tL0kFQ17qWtXqvRVB8s7GCJTIz63tJB8EOhXdY3zEIWhwEZpaWdIOg+V2GtK5hVdXuQHGwGIBWjxOYWVrSDYJ/nQjAiuqRALRUuWvIzNKUbhCsfQ2Ap2snA9CCu4bMLE01lS5Axew4jF/VfBCqir+C1qriDGMHgZmlJt0WwYbV7QPFAO9WZ+83vlOhApmZVUaaQdDaAoVmNmowVRIAG6qGFNdtWF3BgpmZ9b1Eg6DY/dOsQVRlv4H11UOLbza8XZkymZlVSJpBkI0DNFPzXoug2i0CM0tTmkGQPat4E7XofUHwdoUKZWZWGWkGQdYi2EQtVcUcoFA1iA0Mhnffrly5zMwqINcgkHScpJclLZN0aSfrJemGbP18SYfmWZ52WYugWbXtXUOSWKMhFNav6pMimJltL3ILAknVwHeB44FxwKckjeuw2fHA2Ox1PnBLXuXZTMsGANa2VLe3CI4bvye/bx3OH3+3qE+KYGa2vchzQtnhwLKI+B2ApB8BJwOlZ9qTgXsjIoD/lrSrpL0iYmW5C/OfC1bylR+/CMAn9ATfqILnmqrZ9YDijOJPThrJ078Zx6hVj3Dx5TP4D44qdxEsR6p0Acz6wGePGsPfTf1A2fer4jm4/CSdChwXEedmy2cDR0TEF0u2eQy4NiKeypZ/AfxDRMztsK/zKbYYAD4AvJxDkYcBb+aw3+1JCnWENOqZQh3B9SynfSNieGcr8mwRdPZHWsfU6c02RMTtwO3lKFRXJM2NiIY8j1FpKdQR0qhnCnUE17Ov5DlY3AiMKlkeCby6FduYmVmO8gyC54CxksZIGgRMAx7tsM2jwKezq4cmA6vzGB8wM7Ou5dY1FBEtkr4I/BdQDdwVEQsl/U22/lZgFnACsAxYD0zPqzy9kGvX03YihTpCGvVMoY7gevaJ3AaLzcysf0hzZrGZmbVzEJiZJS75IOjpNhj9laRRkp6QtFjSQkkXZp/vLulxSUuzn7tVuqzbSlK1pP/J5qUM1DruKukhSb/N/k0/ONDqKekr2X+rCyQ9IKluINRR0l2S3pC0oOSzLusl6R+z89HLko7tizImHQS9vA1Gf9UCXBQRBwKTgQuyul0K/CIixgK/yJb7uwuBxSXLA7GO/wr8Z0QcAEygWN8BU09JewNfAhoi4iCKF5hMY2DU8W7guA6fdVqv7P/RacD47Ds3Z+epXCUdBJTcBiMiNgFtt8Ho9yJiZUQ8n71/h+KJY2+K9bsn2+we4OMVKWCZSBoJ/DXwvZKPB1oddwb+CrgTICI2RcTbDLB6UryKcQdJNcCOFOcU9fs6RsSvgT91+Lirep0M/CgiNkbE7yleUXl43mVMPQj2BlaULDdmnw0okkYDhwDPAH/eNlcj+/lnFSxaOfwLcAlQKPlsoNXxL4Am4PtZF9j3JO3EAKpnRPwRuA74A7CS4pyinzOA6thBV/WqyDkp9SDo1S0u+jNJQ4CHgS9HxJpKl6ecJJ0IvBER8ypdlpzVAIcCt0TEIcA6+mcXSZeyPvKTgTHACGAnSWdVtlQVUZFzUupBMKBvcSGplmII3B8Rj2Qfvy5pr2z9XsAblSpfGRwJfEzScordeh+RdB8Dq45Q/O+0MSKeyZYfohgMA6meHwV+HxFNEdEMPAL8HwZWHUt1Va+KnJNSD4Le3AajX5Ikin3KiyPiOyWrHgU+k73/DPDvfV22comIf4yIkRExmuK/3S8j4iwGUB0BIuI1YIWktvsPH03xdu4DqZ5/ACZL2jH7b/doiuNaA6mOpbqq16PANEmDJY2h+KyWZ3MvTUQk/aJ4i4slwCvAZZUuTxnrdRTFJuV84IXsdQKwB8WrFJZmP3evdFnLVN8pwGPZ+wFXR2AiMDf795wJ7DbQ6glcCfwWWAD8ABg8EOoIPEBx3KOZ4l/8n+2uXsBl2fnoZeD4viijbzFhZpa41LuGzMyS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHH/HwAW6skUxM1eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate Synthetic Data:\n",
    "\n",
    "# Define the number of synthetic samples to generate\n",
    "number_of_samples = scaled_features.shape[0]  # for example, the same as your original dataset size\n",
    "\n",
    "#Use the generator model to create synthetic data points.\n",
    "# Ensure the amount of synthetic data is sufficient for statistical comparison and machine learning tasks.\n",
    "\n",
    "# Generate noise input for the generator\n",
    "noise = np.random.normal(0, 1, (number_of_samples, latent_dim))\n",
    "\n",
    "# Use the generator to create synthetic data\n",
    "synthetic_data = generator.predict(noise)\n",
    "\n",
    "# Statistical Comparison:\n",
    "\n",
    "# Compare key statistical properties (mean, variance, distribution, etc.) between the synthetic data and the original data.\n",
    "# Visualization tools (like histograms, scatter plots) and statistical tests (like KS-test) can be useful here.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Example: Compare distributions\n",
    "for i in range(scaled_features.shape[1]):\n",
    "    sns.distplot(scaled_features[:, i], label='Original', hist=False)\n",
    "    sns.distplot(synthetic_data[:, i], label='Synthetic', hist=False)\n",
    "    plt.title(f'Feature {i} Distribution')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f84bdc",
   "metadata": {},
   "source": [
    "# Utility Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244bfbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'features' and 'labels' are your dataset's features and target variable\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d145e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "639cfe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 24440, number of negative: 24560\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498776 -> initscore=-0.004898\n",
      "[LightGBM] [Info] Start training from score -0.004898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75     10461\n",
      "           1       0.76      0.69      0.73     10539\n",
      "\n",
      "    accuracy                           0.74     21000\n",
      "   macro avg       0.74      0.74      0.74     21000\n",
      "weighted avg       0.74      0.74      0.74     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create and train the LightGBM model\n",
    "lgbm_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.05)\n",
    "lgbm_model.fit(X_train_real, y_train_real)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_lgbm = lgbm_model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred_lgbm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fcf838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9440404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75     10461\n",
      "           1       0.76      0.70      0.73     10539\n",
      "\n",
      "    accuracy                           0.74     21000\n",
      "   macro avg       0.74      0.74      0.74     21000\n",
      "weighted avg       0.74      0.74      0.74     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# XGBoost model\n",
    "xgb_model = XGBClassifier(n_estimators=2000, learning_rate=0.005)\n",
    "xgb_model.fit(X_train_real, y_train_real)\n",
    "y_pred_xgb = xgb_model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c6a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21b65be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75     10461\n",
      "           1       0.76      0.70      0.73     10539\n",
      "\n",
      "    accuracy                           0.74     21000\n",
      "   macro avg       0.74      0.74      0.74     21000\n",
      "weighted avg       0.74      0.74      0.74     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# CatBoost model\n",
    "cat_model = CatBoostClassifier(iterations=100, learning_rate=0.05, depth=10, verbose=False)\n",
    "cat_model.fit(X_train_real, y_train_real)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_cat = cat_model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred_cat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de874e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6bb905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bdb24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f998f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d013cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b98bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f0a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6bd38aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    35021\n",
      "1    34979\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ffc95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1e13d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\ede\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ede\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0c732e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.2.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\ede\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ede\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab80db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0f76696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 24440, number of negative: 24560\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498776 -> initscore=-0.004898\n",
      "[LightGBM] [Info] Start training from score -0.004898\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100, 'num_leaves': 31}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50, 70],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# Create the model\n",
    "lgbm = lgb.LGBMClassifier()\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(estimator=lgbm, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_real, y_train_real)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3f7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.6419 - accuracy: 0.6482 - val_loss: 0.5941 - val_accuracy: 0.6904\n",
      "Epoch 2/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5989 - accuracy: 0.6996 - val_loss: 0.5657 - val_accuracy: 0.7231\n",
      "Epoch 3/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5839 - accuracy: 0.7133 - val_loss: 0.5584 - val_accuracy: 0.7289\n",
      "Epoch 4/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5721 - accuracy: 0.7221 - val_loss: 0.5538 - val_accuracy: 0.7336\n",
      "Epoch 5/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7223 - val_loss: 0.5494 - val_accuracy: 0.7305\n",
      "Epoch 6/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5619 - accuracy: 0.7255 - val_loss: 0.5472 - val_accuracy: 0.7309\n",
      "Epoch 7/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5591 - accuracy: 0.7254 - val_loss: 0.5474 - val_accuracy: 0.7322\n",
      "Epoch 8/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5585 - accuracy: 0.7252 - val_loss: 0.5452 - val_accuracy: 0.7344\n",
      "Epoch 9/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5582 - accuracy: 0.7274 - val_loss: 0.5454 - val_accuracy: 0.7361\n",
      "Epoch 10/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5584 - accuracy: 0.7271 - val_loss: 0.5457 - val_accuracy: 0.7348\n",
      "Epoch 11/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5563 - accuracy: 0.7282 - val_loss: 0.5456 - val_accuracy: 0.7345\n",
      "Epoch 12/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5539 - accuracy: 0.7273 - val_loss: 0.5465 - val_accuracy: 0.7348\n",
      "Epoch 13/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5554 - accuracy: 0.7277 - val_loss: 0.5442 - val_accuracy: 0.7320\n",
      "Epoch 14/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5557 - accuracy: 0.7269 - val_loss: 0.5463 - val_accuracy: 0.7342\n",
      "Epoch 15/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5559 - accuracy: 0.7264 - val_loss: 0.5426 - val_accuracy: 0.7365\n",
      "Epoch 16/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5547 - accuracy: 0.7295 - val_loss: 0.5439 - val_accuracy: 0.7337\n",
      "Epoch 17/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5550 - accuracy: 0.7284 - val_loss: 0.5429 - val_accuracy: 0.7364\n",
      "Epoch 18/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5534 - accuracy: 0.7292 - val_loss: 0.5431 - val_accuracy: 0.7340\n",
      "Epoch 19/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5535 - accuracy: 0.7285 - val_loss: 0.5445 - val_accuracy: 0.7338\n",
      "Epoch 20/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5543 - accuracy: 0.7281 - val_loss: 0.5447 - val_accuracy: 0.7370\n",
      "Epoch 21/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5535 - accuracy: 0.7293 - val_loss: 0.5435 - val_accuracy: 0.7342\n",
      "Epoch 22/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5524 - accuracy: 0.7271 - val_loss: 0.5426 - val_accuracy: 0.7366\n",
      "Epoch 23/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5551 - accuracy: 0.7293 - val_loss: 0.5424 - val_accuracy: 0.7359\n",
      "Epoch 24/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5531 - accuracy: 0.7297 - val_loss: 0.5424 - val_accuracy: 0.7371\n",
      "Epoch 25/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5519 - accuracy: 0.7302 - val_loss: 0.5422 - val_accuracy: 0.7354\n",
      "Epoch 26/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5526 - accuracy: 0.7294 - val_loss: 0.5446 - val_accuracy: 0.7361\n",
      "Epoch 27/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5529 - accuracy: 0.7307 - val_loss: 0.5450 - val_accuracy: 0.7328\n",
      "Epoch 28/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5522 - accuracy: 0.7293 - val_loss: 0.5406 - val_accuracy: 0.7373\n",
      "Epoch 29/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5519 - accuracy: 0.7319 - val_loss: 0.5404 - val_accuracy: 0.7385\n",
      "Epoch 30/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5524 - accuracy: 0.7296 - val_loss: 0.5417 - val_accuracy: 0.7368\n",
      "Epoch 31/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5512 - accuracy: 0.7294 - val_loss: 0.5416 - val_accuracy: 0.7368\n",
      "Epoch 32/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5525 - accuracy: 0.7294 - val_loss: 0.5432 - val_accuracy: 0.7361\n",
      "Epoch 33/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5508 - accuracy: 0.7300 - val_loss: 0.5426 - val_accuracy: 0.7356\n",
      "Epoch 34/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5514 - accuracy: 0.7305 - val_loss: 0.5414 - val_accuracy: 0.7358\n",
      "Epoch 35/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5525 - accuracy: 0.7309 - val_loss: 0.5417 - val_accuracy: 0.7372\n",
      "Epoch 36/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5513 - accuracy: 0.7299 - val_loss: 0.5430 - val_accuracy: 0.7354\n",
      "Epoch 37/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5507 - accuracy: 0.7318 - val_loss: 0.5422 - val_accuracy: 0.7348\n",
      "Epoch 38/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5520 - accuracy: 0.7298 - val_loss: 0.5428 - val_accuracy: 0.7385\n",
      "Epoch 39/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5515 - accuracy: 0.7312 - val_loss: 0.5444 - val_accuracy: 0.7365\n",
      "Epoch 40/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5508 - accuracy: 0.7309 - val_loss: 0.5421 - val_accuracy: 0.7362\n",
      "Epoch 41/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5520 - accuracy: 0.7313 - val_loss: 0.5412 - val_accuracy: 0.7372\n",
      "Epoch 42/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5521 - accuracy: 0.7305 - val_loss: 0.5431 - val_accuracy: 0.7326\n",
      "Epoch 43/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5509 - accuracy: 0.7299 - val_loss: 0.5419 - val_accuracy: 0.7347\n",
      "Epoch 44/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5499 - accuracy: 0.7301 - val_loss: 0.5453 - val_accuracy: 0.7354\n",
      "Epoch 45/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5521 - accuracy: 0.7312 - val_loss: 0.5427 - val_accuracy: 0.7356\n",
      "Epoch 46/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5505 - accuracy: 0.7316 - val_loss: 0.5431 - val_accuracy: 0.7357\n",
      "Epoch 47/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5515 - accuracy: 0.7320 - val_loss: 0.5436 - val_accuracy: 0.7341\n",
      "Epoch 48/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5496 - accuracy: 0.7298 - val_loss: 0.5424 - val_accuracy: 0.7346\n",
      "Epoch 49/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5506 - accuracy: 0.7302 - val_loss: 0.5429 - val_accuracy: 0.7342\n",
      "Epoch 50/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5501 - accuracy: 0.7299 - val_loss: 0.5419 - val_accuracy: 0.7355\n",
      "Epoch 51/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5500 - accuracy: 0.7302 - val_loss: 0.5423 - val_accuracy: 0.7357\n",
      "Epoch 52/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5511 - accuracy: 0.7301 - val_loss: 0.5413 - val_accuracy: 0.7365\n",
      "Epoch 53/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5514 - accuracy: 0.7293 - val_loss: 0.5421 - val_accuracy: 0.7353\n",
      "Epoch 54/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5497 - accuracy: 0.7298 - val_loss: 0.5421 - val_accuracy: 0.7336\n",
      "Epoch 55/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5524 - accuracy: 0.7308 - val_loss: 0.5431 - val_accuracy: 0.7357\n",
      "Epoch 56/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5510 - accuracy: 0.7310 - val_loss: 0.5430 - val_accuracy: 0.7360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5501 - accuracy: 0.7299 - val_loss: 0.5417 - val_accuracy: 0.7341\n",
      "Epoch 58/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5530 - accuracy: 0.7299 - val_loss: 0.5433 - val_accuracy: 0.7349\n",
      "Epoch 59/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5499 - accuracy: 0.7308 - val_loss: 0.5436 - val_accuracy: 0.7377\n",
      "Epoch 60/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5500 - accuracy: 0.7310 - val_loss: 0.5421 - val_accuracy: 0.7378\n",
      "Epoch 61/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5506 - accuracy: 0.7316 - val_loss: 0.5473 - val_accuracy: 0.7336\n",
      "Epoch 62/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5496 - accuracy: 0.7297 - val_loss: 0.5449 - val_accuracy: 0.7364\n",
      "Epoch 63/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7304 - val_loss: 0.5436 - val_accuracy: 0.7387\n",
      "Epoch 64/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5499 - accuracy: 0.7307 - val_loss: 0.5427 - val_accuracy: 0.7372\n",
      "Epoch 65/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5506 - accuracy: 0.7306 - val_loss: 0.5442 - val_accuracy: 0.7380\n",
      "Epoch 66/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7305 - val_loss: 0.5430 - val_accuracy: 0.7384\n",
      "Epoch 67/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7304 - val_loss: 0.5428 - val_accuracy: 0.7380\n",
      "Epoch 68/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5503 - accuracy: 0.7305 - val_loss: 0.5433 - val_accuracy: 0.7355\n",
      "Epoch 69/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5495 - accuracy: 0.7316 - val_loss: 0.5420 - val_accuracy: 0.7348\n",
      "Epoch 70/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5514 - accuracy: 0.7309 - val_loss: 0.5418 - val_accuracy: 0.7345\n",
      "Epoch 71/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7327 - val_loss: 0.5426 - val_accuracy: 0.7349\n",
      "Epoch 72/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5493 - accuracy: 0.7302 - val_loss: 0.5424 - val_accuracy: 0.7348\n",
      "Epoch 73/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7294 - val_loss: 0.5449 - val_accuracy: 0.7365\n",
      "Epoch 74/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5502 - accuracy: 0.7305 - val_loss: 0.5437 - val_accuracy: 0.7376\n",
      "Epoch 75/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5498 - accuracy: 0.7305 - val_loss: 0.5446 - val_accuracy: 0.7351\n",
      "Epoch 76/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5506 - accuracy: 0.7306 - val_loss: 0.5421 - val_accuracy: 0.7365\n",
      "Epoch 77/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7298 - val_loss: 0.5425 - val_accuracy: 0.7368\n",
      "Epoch 78/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7301 - val_loss: 0.5418 - val_accuracy: 0.7359\n",
      "Epoch 79/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5483 - accuracy: 0.7316 - val_loss: 0.5435 - val_accuracy: 0.7384\n",
      "Epoch 80/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5533 - accuracy: 0.7299 - val_loss: 0.5419 - val_accuracy: 0.7344\n",
      "Epoch 81/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5488 - accuracy: 0.7311 - val_loss: 0.5434 - val_accuracy: 0.7369\n",
      "Epoch 82/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.7314 - val_loss: 0.5417 - val_accuracy: 0.7354\n",
      "Epoch 83/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5501 - accuracy: 0.7306 - val_loss: 0.5443 - val_accuracy: 0.7360\n",
      "Epoch 84/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5492 - accuracy: 0.7308 - val_loss: 0.5432 - val_accuracy: 0.7348\n",
      "Epoch 85/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5520 - accuracy: 0.7315 - val_loss: 0.5416 - val_accuracy: 0.7358\n",
      "Epoch 86/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7333 - val_loss: 0.5416 - val_accuracy: 0.7370\n",
      "Epoch 87/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7291 - val_loss: 0.5441 - val_accuracy: 0.7352\n",
      "Epoch 88/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.7304 - val_loss: 0.5426 - val_accuracy: 0.7362\n",
      "Epoch 89/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5486 - accuracy: 0.7318 - val_loss: 0.5415 - val_accuracy: 0.7351\n",
      "Epoch 90/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7293 - val_loss: 0.5438 - val_accuracy: 0.7348\n",
      "Epoch 91/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5492 - accuracy: 0.7322 - val_loss: 0.5419 - val_accuracy: 0.7366\n",
      "Epoch 92/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5518 - accuracy: 0.7309 - val_loss: 0.5423 - val_accuracy: 0.7357\n",
      "Epoch 93/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.7320 - val_loss: 0.5432 - val_accuracy: 0.7362\n",
      "Epoch 94/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5483 - accuracy: 0.7325 - val_loss: 0.5417 - val_accuracy: 0.7368\n",
      "Epoch 95/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7307 - val_loss: 0.5439 - val_accuracy: 0.7349\n",
      "Epoch 96/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5510 - accuracy: 0.7297 - val_loss: 0.5432 - val_accuracy: 0.7353\n",
      "Epoch 97/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.7303 - val_loss: 0.5425 - val_accuracy: 0.7356\n",
      "Epoch 98/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5491 - accuracy: 0.7321 - val_loss: 0.5436 - val_accuracy: 0.7366\n",
      "Epoch 99/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5498 - accuracy: 0.7299 - val_loss: 0.5419 - val_accuracy: 0.7374\n",
      "Epoch 100/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5500 - accuracy: 0.7316 - val_loss: 0.5429 - val_accuracy: 0.7362\n",
      "Epoch 101/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.7294 - val_loss: 0.5423 - val_accuracy: 0.7369\n",
      "Epoch 102/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.7302 - val_loss: 0.5435 - val_accuracy: 0.7363\n",
      "Epoch 103/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5500 - accuracy: 0.7322 - val_loss: 0.5429 - val_accuracy: 0.7359\n",
      "Epoch 104/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.7307 - val_loss: 0.5437 - val_accuracy: 0.7355\n",
      "Epoch 105/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5479 - accuracy: 0.7324 - val_loss: 0.5452 - val_accuracy: 0.7340\n",
      "Epoch 106/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.7314 - val_loss: 0.5426 - val_accuracy: 0.7358\n",
      "Epoch 107/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5481 - accuracy: 0.7321 - val_loss: 0.5433 - val_accuracy: 0.7395\n",
      "Epoch 108/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5486 - accuracy: 0.7319 - val_loss: 0.5426 - val_accuracy: 0.7334\n",
      "Epoch 109/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7321 - val_loss: 0.5436 - val_accuracy: 0.7368\n",
      "Epoch 110/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5486 - accuracy: 0.7314 - val_loss: 0.5428 - val_accuracy: 0.7365\n",
      "Epoch 111/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7316 - val_loss: 0.5418 - val_accuracy: 0.7369\n",
      "Epoch 112/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7319 - val_loss: 0.5443 - val_accuracy: 0.7346\n",
      "Epoch 113/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5481 - accuracy: 0.7329 - val_loss: 0.5432 - val_accuracy: 0.7360\n",
      "Epoch 114/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7320 - val_loss: 0.5419 - val_accuracy: 0.7345\n",
      "Epoch 115/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7324 - val_loss: 0.5421 - val_accuracy: 0.7352\n",
      "Epoch 116/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7321 - val_loss: 0.5428 - val_accuracy: 0.7346\n",
      "Epoch 117/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5481 - accuracy: 0.7311 - val_loss: 0.5434 - val_accuracy: 0.7345\n",
      "Epoch 118/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5479 - accuracy: 0.7313 - val_loss: 0.5431 - val_accuracy: 0.7380\n",
      "Epoch 119/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7318 - val_loss: 0.5429 - val_accuracy: 0.7362\n",
      "Epoch 120/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7316 - val_loss: 0.5422 - val_accuracy: 0.7368\n",
      "Epoch 121/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7304 - val_loss: 0.5426 - val_accuracy: 0.7351\n",
      "Epoch 122/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7321 - val_loss: 0.5437 - val_accuracy: 0.7348\n",
      "Epoch 123/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5485 - accuracy: 0.7326 - val_loss: 0.5434 - val_accuracy: 0.7360\n",
      "Epoch 124/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7325 - val_loss: 0.5422 - val_accuracy: 0.7348\n",
      "Epoch 125/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5485 - accuracy: 0.7327 - val_loss: 0.5439 - val_accuracy: 0.7373\n",
      "Epoch 126/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.7335 - val_loss: 0.5437 - val_accuracy: 0.7331\n",
      "Epoch 127/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5477 - accuracy: 0.7323 - val_loss: 0.5440 - val_accuracy: 0.7338\n",
      "Epoch 128/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5478 - accuracy: 0.7309 - val_loss: 0.5428 - val_accuracy: 0.7365\n",
      "Epoch 129/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7312 - val_loss: 0.5451 - val_accuracy: 0.7345\n",
      "Epoch 130/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5485 - accuracy: 0.7332 - val_loss: 0.5441 - val_accuracy: 0.7343\n",
      "Epoch 131/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7335 - val_loss: 0.5443 - val_accuracy: 0.7338\n",
      "Epoch 132/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7320 - val_loss: 0.5424 - val_accuracy: 0.7354\n",
      "Epoch 133/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5490 - accuracy: 0.7330 - val_loss: 0.5434 - val_accuracy: 0.7346\n",
      "Epoch 134/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7316 - val_loss: 0.5418 - val_accuracy: 0.7362\n",
      "Epoch 135/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7329 - val_loss: 0.5442 - val_accuracy: 0.7332\n",
      "Epoch 136/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5483 - accuracy: 0.7325 - val_loss: 0.5441 - val_accuracy: 0.7338\n",
      "Epoch 137/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5505 - accuracy: 0.7331 - val_loss: 0.5431 - val_accuracy: 0.7342\n",
      "Epoch 138/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7324 - val_loss: 0.5429 - val_accuracy: 0.7346\n",
      "Epoch 139/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5478 - accuracy: 0.7321 - val_loss: 0.5452 - val_accuracy: 0.7337\n",
      "Epoch 140/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7319 - val_loss: 0.5426 - val_accuracy: 0.7352\n",
      "Epoch 141/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7331 - val_loss: 0.5414 - val_accuracy: 0.7362\n",
      "Epoch 142/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5477 - accuracy: 0.7317 - val_loss: 0.5439 - val_accuracy: 0.7350\n",
      "Epoch 143/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7337 - val_loss: 0.5420 - val_accuracy: 0.7381\n",
      "Epoch 144/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7328 - val_loss: 0.5429 - val_accuracy: 0.7355\n",
      "Epoch 145/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5482 - accuracy: 0.7311 - val_loss: 0.5451 - val_accuracy: 0.7389\n",
      "Epoch 146/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7335 - val_loss: 0.5467 - val_accuracy: 0.7354\n",
      "Epoch 147/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7341 - val_loss: 0.5433 - val_accuracy: 0.7378\n",
      "Epoch 148/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7321 - val_loss: 0.5432 - val_accuracy: 0.7368\n",
      "Epoch 149/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7321 - val_loss: 0.5436 - val_accuracy: 0.7348\n",
      "Epoch 150/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5476 - accuracy: 0.7321 - val_loss: 0.5455 - val_accuracy: 0.7361\n",
      "Epoch 151/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7324 - val_loss: 0.5440 - val_accuracy: 0.7348\n",
      "Epoch 152/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5482 - accuracy: 0.7312 - val_loss: 0.5436 - val_accuracy: 0.7362\n",
      "Epoch 153/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7309 - val_loss: 0.5442 - val_accuracy: 0.7347\n",
      "Epoch 154/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5472 - accuracy: 0.7324 - val_loss: 0.5438 - val_accuracy: 0.7356\n",
      "Epoch 155/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7341 - val_loss: 0.5429 - val_accuracy: 0.7363\n",
      "Epoch 156/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7321 - val_loss: 0.5430 - val_accuracy: 0.7366\n",
      "Epoch 157/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7324 - val_loss: 0.5436 - val_accuracy: 0.7358\n",
      "Epoch 158/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5467 - accuracy: 0.7336 - val_loss: 0.5466 - val_accuracy: 0.7359\n",
      "Epoch 159/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5477 - accuracy: 0.7334 - val_loss: 0.5432 - val_accuracy: 0.7352\n",
      "Epoch 160/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5485 - accuracy: 0.7315 - val_loss: 0.5431 - val_accuracy: 0.7369\n",
      "Epoch 161/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7339 - val_loss: 0.5455 - val_accuracy: 0.7355\n",
      "Epoch 162/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7321 - val_loss: 0.5428 - val_accuracy: 0.7354\n",
      "Epoch 163/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7342 - val_loss: 0.5440 - val_accuracy: 0.7368\n",
      "Epoch 164/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7323 - val_loss: 0.5430 - val_accuracy: 0.7341\n",
      "Epoch 165/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5467 - accuracy: 0.7329 - val_loss: 0.5438 - val_accuracy: 0.7364\n",
      "Epoch 166/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7333 - val_loss: 0.5436 - val_accuracy: 0.7361\n",
      "Epoch 167/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7323 - val_loss: 0.5452 - val_accuracy: 0.7383\n",
      "Epoch 168/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7323 - val_loss: 0.5448 - val_accuracy: 0.7357\n",
      "Epoch 169/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7332 - val_loss: 0.5426 - val_accuracy: 0.7359\n",
      "Epoch 170/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7323 - val_loss: 0.5425 - val_accuracy: 0.7359\n",
      "Epoch 171/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5477 - accuracy: 0.7319 - val_loss: 0.5419 - val_accuracy: 0.7343\n",
      "Epoch 172/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7329 - val_loss: 0.5425 - val_accuracy: 0.7356\n",
      "Epoch 173/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7326 - val_loss: 0.5429 - val_accuracy: 0.7361\n",
      "Epoch 174/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5507 - accuracy: 0.7326 - val_loss: 0.5446 - val_accuracy: 0.7359\n",
      "Epoch 175/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7326 - val_loss: 0.5440 - val_accuracy: 0.7347\n",
      "Epoch 176/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7330 - val_loss: 0.5435 - val_accuracy: 0.7343\n",
      "Epoch 177/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7323 - val_loss: 0.5428 - val_accuracy: 0.7387\n",
      "Epoch 178/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5470 - accuracy: 0.7340 - val_loss: 0.5431 - val_accuracy: 0.7364\n",
      "Epoch 179/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7331 - val_loss: 0.5448 - val_accuracy: 0.7371\n",
      "Epoch 180/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7334 - val_loss: 0.5421 - val_accuracy: 0.7368\n",
      "Epoch 181/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.7328 - val_loss: 0.5434 - val_accuracy: 0.7346\n",
      "Epoch 182/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7334 - val_loss: 0.5446 - val_accuracy: 0.7357\n",
      "Epoch 183/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7329 - val_loss: 0.5438 - val_accuracy: 0.7352\n",
      "Epoch 184/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7333 - val_loss: 0.5437 - val_accuracy: 0.7335\n",
      "Epoch 185/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7336 - val_loss: 0.5430 - val_accuracy: 0.7346\n",
      "Epoch 186/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7323 - val_loss: 0.5434 - val_accuracy: 0.7358\n",
      "Epoch 187/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5469 - accuracy: 0.7323 - val_loss: 0.5451 - val_accuracy: 0.7351\n",
      "Epoch 188/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7330 - val_loss: 0.5435 - val_accuracy: 0.7336\n",
      "Epoch 189/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7326 - val_loss: 0.5436 - val_accuracy: 0.7370\n",
      "Epoch 190/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7340 - val_loss: 0.5444 - val_accuracy: 0.7343\n",
      "Epoch 191/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5467 - accuracy: 0.7326 - val_loss: 0.5432 - val_accuracy: 0.7343\n",
      "Epoch 192/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5468 - accuracy: 0.7320 - val_loss: 0.5432 - val_accuracy: 0.7356\n",
      "Epoch 193/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7306 - val_loss: 0.5451 - val_accuracy: 0.7348\n",
      "Epoch 194/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7326 - val_loss: 0.5417 - val_accuracy: 0.7364\n",
      "Epoch 195/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7345 - val_loss: 0.5461 - val_accuracy: 0.7356\n",
      "Epoch 196/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7330 - val_loss: 0.5441 - val_accuracy: 0.7370\n",
      "Epoch 197/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5520 - accuracy: 0.7332 - val_loss: 0.5434 - val_accuracy: 0.7341\n",
      "Epoch 198/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5494 - accuracy: 0.7326 - val_loss: 0.5440 - val_accuracy: 0.7365\n",
      "Epoch 199/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7338 - val_loss: 0.5448 - val_accuracy: 0.7367\n",
      "Epoch 200/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7324 - val_loss: 0.5446 - val_accuracy: 0.7346\n",
      "Epoch 201/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7318 - val_loss: 0.5431 - val_accuracy: 0.7345\n",
      "Epoch 202/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7326 - val_loss: 0.5416 - val_accuracy: 0.7359\n",
      "Epoch 203/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5468 - accuracy: 0.7336 - val_loss: 0.5465 - val_accuracy: 0.7351\n",
      "Epoch 204/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7325 - val_loss: 0.5428 - val_accuracy: 0.7359\n",
      "Epoch 205/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5461 - accuracy: 0.7337 - val_loss: 0.5423 - val_accuracy: 0.7353\n",
      "Epoch 206/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7333 - val_loss: 0.5434 - val_accuracy: 0.7362\n",
      "Epoch 207/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5483 - accuracy: 0.7332 - val_loss: 0.5441 - val_accuracy: 0.7339\n",
      "Epoch 208/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7310 - val_loss: 0.5447 - val_accuracy: 0.7323\n",
      "Epoch 209/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7343 - val_loss: 0.5435 - val_accuracy: 0.7352\n",
      "Epoch 210/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7323 - val_loss: 0.5439 - val_accuracy: 0.7347\n",
      "Epoch 211/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7329 - val_loss: 0.5424 - val_accuracy: 0.7353\n",
      "Epoch 212/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5466 - accuracy: 0.7332 - val_loss: 0.5430 - val_accuracy: 0.7353\n",
      "Epoch 213/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7332 - val_loss: 0.5445 - val_accuracy: 0.7337\n",
      "Epoch 214/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7333 - val_loss: 0.5459 - val_accuracy: 0.7351\n",
      "Epoch 215/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.7338 - val_loss: 0.5461 - val_accuracy: 0.7329\n",
      "Epoch 216/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5461 - accuracy: 0.7337 - val_loss: 0.5447 - val_accuracy: 0.7355\n",
      "Epoch 217/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5470 - accuracy: 0.7329 - val_loss: 0.5442 - val_accuracy: 0.7332\n",
      "Epoch 218/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7324 - val_loss: 0.5440 - val_accuracy: 0.7334\n",
      "Epoch 219/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7338 - val_loss: 0.5440 - val_accuracy: 0.7330\n",
      "Epoch 220/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7340 - val_loss: 0.5442 - val_accuracy: 0.7342\n",
      "Epoch 221/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7327 - val_loss: 0.5464 - val_accuracy: 0.7363\n",
      "Epoch 222/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7319 - val_loss: 0.5454 - val_accuracy: 0.7342\n",
      "Epoch 223/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7327 - val_loss: 0.5443 - val_accuracy: 0.7371\n",
      "Epoch 224/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5483 - accuracy: 0.7328 - val_loss: 0.5453 - val_accuracy: 0.7340\n",
      "Epoch 225/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5498 - accuracy: 0.7333 - val_loss: 0.5435 - val_accuracy: 0.7346\n",
      "Epoch 226/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.7342 - val_loss: 0.5426 - val_accuracy: 0.7353\n",
      "Epoch 227/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7345 - val_loss: 0.5436 - val_accuracy: 0.7343\n",
      "Epoch 228/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7315 - val_loss: 0.5437 - val_accuracy: 0.7358\n",
      "Epoch 229/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7327 - val_loss: 0.5450 - val_accuracy: 0.7355\n",
      "Epoch 230/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5465 - accuracy: 0.7331 - val_loss: 0.5455 - val_accuracy: 0.7360\n",
      "Epoch 231/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5461 - accuracy: 0.7324 - val_loss: 0.5442 - val_accuracy: 0.7337\n",
      "Epoch 232/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5457 - accuracy: 0.7335 - val_loss: 0.5433 - val_accuracy: 0.7341\n",
      "Epoch 233/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5458 - accuracy: 0.7340 - val_loss: 0.5447 - val_accuracy: 0.7348\n",
      "Epoch 234/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5463 - accuracy: 0.7326 - val_loss: 0.5434 - val_accuracy: 0.7352\n",
      "Epoch 235/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7330 - val_loss: 0.5447 - val_accuracy: 0.7344\n",
      "Epoch 236/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7339 - val_loss: 0.5451 - val_accuracy: 0.7351\n",
      "Epoch 237/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7334 - val_loss: 0.5419 - val_accuracy: 0.7384\n",
      "Epoch 238/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7344 - val_loss: 0.5429 - val_accuracy: 0.7380\n",
      "Epoch 239/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7336 - val_loss: 0.5424 - val_accuracy: 0.7347\n",
      "Epoch 240/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7346 - val_loss: 0.5424 - val_accuracy: 0.7349\n",
      "Epoch 241/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7329 - val_loss: 0.5437 - val_accuracy: 0.7365\n",
      "Epoch 242/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7328 - val_loss: 0.5419 - val_accuracy: 0.7338\n",
      "Epoch 243/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5449 - accuracy: 0.7325 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
      "Epoch 244/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5459 - accuracy: 0.7330 - val_loss: 0.5451 - val_accuracy: 0.7329\n",
      "Epoch 245/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7359 - val_loss: 0.5431 - val_accuracy: 0.7348\n",
      "Epoch 246/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7321 - val_loss: 0.5434 - val_accuracy: 0.7343\n",
      "Epoch 247/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7332 - val_loss: 0.5457 - val_accuracy: 0.7349\n",
      "Epoch 248/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7316 - val_loss: 0.5442 - val_accuracy: 0.7363\n",
      "Epoch 249/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7332 - val_loss: 0.5428 - val_accuracy: 0.7359\n",
      "Epoch 250/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5468 - accuracy: 0.7341 - val_loss: 0.5434 - val_accuracy: 0.7355\n",
      "Epoch 251/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7333 - val_loss: 0.5490 - val_accuracy: 0.7329\n",
      "Epoch 252/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.7308 - val_loss: 0.5438 - val_accuracy: 0.7351\n",
      "Epoch 253/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7327 - val_loss: 0.5432 - val_accuracy: 0.7336\n",
      "Epoch 254/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7342 - val_loss: 0.5446 - val_accuracy: 0.7363\n",
      "Epoch 255/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7326 - val_loss: 0.5432 - val_accuracy: 0.7361\n",
      "Epoch 256/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5451 - accuracy: 0.7345 - val_loss: 0.5445 - val_accuracy: 0.7371\n",
      "Epoch 257/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5465 - accuracy: 0.7333 - val_loss: 0.5429 - val_accuracy: 0.7373\n",
      "Epoch 258/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7335 - val_loss: 0.5461 - val_accuracy: 0.7337\n",
      "Epoch 259/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5464 - accuracy: 0.7339 - val_loss: 0.5452 - val_accuracy: 0.7367\n",
      "Epoch 260/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.7335 - val_loss: 0.5465 - val_accuracy: 0.7357\n",
      "Epoch 261/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7350 - val_loss: 0.5449 - val_accuracy: 0.7357\n",
      "Epoch 262/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7343 - val_loss: 0.5446 - val_accuracy: 0.7354\n",
      "Epoch 263/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5462 - accuracy: 0.7324 - val_loss: 0.5496 - val_accuracy: 0.7363\n",
      "Epoch 264/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7351 - val_loss: 0.5441 - val_accuracy: 0.7370\n",
      "Epoch 265/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7326 - val_loss: 0.5432 - val_accuracy: 0.7368\n",
      "Epoch 266/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5471 - accuracy: 0.7349 - val_loss: 0.5446 - val_accuracy: 0.7364\n",
      "Epoch 267/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5455 - accuracy: 0.7333 - val_loss: 0.5429 - val_accuracy: 0.7357\n",
      "Epoch 268/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5479 - accuracy: 0.7329 - val_loss: 0.5432 - val_accuracy: 0.7357\n",
      "Epoch 269/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5449 - accuracy: 0.7340 - val_loss: 0.5435 - val_accuracy: 0.7348\n",
      "Epoch 270/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7326 - val_loss: 0.5451 - val_accuracy: 0.7363\n",
      "Epoch 271/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7332 - val_loss: 0.5478 - val_accuracy: 0.7354\n",
      "Epoch 272/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7340 - val_loss: 0.5449 - val_accuracy: 0.7349\n",
      "Epoch 273/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7328 - val_loss: 0.5435 - val_accuracy: 0.7361\n",
      "Epoch 274/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5476 - accuracy: 0.7334 - val_loss: 0.5458 - val_accuracy: 0.7343\n",
      "Epoch 275/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7324 - val_loss: 0.5449 - val_accuracy: 0.7367\n",
      "Epoch 276/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5449 - accuracy: 0.7337 - val_loss: 0.5450 - val_accuracy: 0.7355\n",
      "Epoch 277/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7336 - val_loss: 0.5438 - val_accuracy: 0.7322\n",
      "Epoch 278/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7322 - val_loss: 0.5447 - val_accuracy: 0.7354\n",
      "Epoch 279/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7330 - val_loss: 0.5448 - val_accuracy: 0.7363\n",
      "Epoch 280/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7332 - val_loss: 0.5466 - val_accuracy: 0.7348\n",
      "Epoch 281/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7333 - val_loss: 0.5464 - val_accuracy: 0.7333\n",
      "Epoch 282/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7342 - val_loss: 0.5462 - val_accuracy: 0.7352\n",
      "Epoch 283/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7336 - val_loss: 0.5441 - val_accuracy: 0.7340\n",
      "Epoch 284/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7327 - val_loss: 0.5457 - val_accuracy: 0.7342\n",
      "Epoch 285/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7327 - val_loss: 0.5441 - val_accuracy: 0.7319\n",
      "Epoch 286/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5437 - accuracy: 0.7345 - val_loss: 0.5440 - val_accuracy: 0.7343\n",
      "Epoch 287/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5450 - accuracy: 0.7363 - val_loss: 0.5418 - val_accuracy: 0.7351\n",
      "Epoch 288/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7334 - val_loss: 0.5444 - val_accuracy: 0.7362\n",
      "Epoch 289/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5460 - accuracy: 0.7314 - val_loss: 0.5453 - val_accuracy: 0.7331\n",
      "Epoch 290/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.7345 - val_loss: 0.5436 - val_accuracy: 0.7347\n",
      "Epoch 291/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7339 - val_loss: 0.5458 - val_accuracy: 0.7337\n",
      "Epoch 292/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7335 - val_loss: 0.5456 - val_accuracy: 0.7342\n",
      "Epoch 293/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7349 - val_loss: 0.5453 - val_accuracy: 0.7368\n",
      "Epoch 294/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7337 - val_loss: 0.5435 - val_accuracy: 0.7371\n",
      "Epoch 295/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5441 - accuracy: 0.7329 - val_loss: 0.5446 - val_accuracy: 0.7333\n",
      "Epoch 296/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7345 - val_loss: 0.5433 - val_accuracy: 0.7345\n",
      "Epoch 297/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7345 - val_loss: 0.5436 - val_accuracy: 0.7350\n",
      "Epoch 298/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7357 - val_loss: 0.5449 - val_accuracy: 0.7347\n",
      "Epoch 299/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7329 - val_loss: 0.5441 - val_accuracy: 0.7339\n",
      "Epoch 300/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7323 - val_loss: 0.5455 - val_accuracy: 0.7360\n",
      "Epoch 301/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7348 - val_loss: 0.5444 - val_accuracy: 0.7350\n",
      "Epoch 302/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5456 - accuracy: 0.7338 - val_loss: 0.5457 - val_accuracy: 0.7358\n",
      "Epoch 303/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7334 - val_loss: 0.5441 - val_accuracy: 0.7350\n",
      "Epoch 304/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7325 - val_loss: 0.5440 - val_accuracy: 0.7329\n",
      "Epoch 305/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7324 - val_loss: 0.5435 - val_accuracy: 0.7324\n",
      "Epoch 306/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7330 - val_loss: 0.5443 - val_accuracy: 0.7369\n",
      "Epoch 307/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7331 - val_loss: 0.5439 - val_accuracy: 0.7351\n",
      "Epoch 308/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7340 - val_loss: 0.5446 - val_accuracy: 0.7333\n",
      "Epoch 309/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7334 - val_loss: 0.5436 - val_accuracy: 0.7352\n",
      "Epoch 310/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7342 - val_loss: 0.5442 - val_accuracy: 0.7338\n",
      "Epoch 311/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7346 - val_loss: 0.5434 - val_accuracy: 0.7322\n",
      "Epoch 312/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5454 - accuracy: 0.7350 - val_loss: 0.5442 - val_accuracy: 0.7341\n",
      "Epoch 313/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5442 - accuracy: 0.7353 - val_loss: 0.5463 - val_accuracy: 0.7316\n",
      "Epoch 314/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7331 - val_loss: 0.5437 - val_accuracy: 0.7337\n",
      "Epoch 315/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5463 - accuracy: 0.7341 - val_loss: 0.5449 - val_accuracy: 0.7336\n",
      "Epoch 316/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7337 - val_loss: 0.5462 - val_accuracy: 0.7340\n",
      "Epoch 317/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7334 - val_loss: 0.5438 - val_accuracy: 0.7332\n",
      "Epoch 318/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7320 - val_loss: 0.5453 - val_accuracy: 0.7360\n",
      "Epoch 319/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7328 - val_loss: 0.5432 - val_accuracy: 0.7360\n",
      "Epoch 320/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7335 - val_loss: 0.5438 - val_accuracy: 0.7346\n",
      "Epoch 321/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5446 - accuracy: 0.7338 - val_loss: 0.5445 - val_accuracy: 0.7349\n",
      "Epoch 322/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5445 - accuracy: 0.7339 - val_loss: 0.5456 - val_accuracy: 0.7335\n",
      "Epoch 323/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7335 - val_loss: 0.5458 - val_accuracy: 0.7356\n",
      "Epoch 324/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7333 - val_loss: 0.5445 - val_accuracy: 0.7355\n",
      "Epoch 325/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7331 - val_loss: 0.5438 - val_accuracy: 0.7369\n",
      "Epoch 326/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7338 - val_loss: 0.5472 - val_accuracy: 0.7329\n",
      "Epoch 327/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7331 - val_loss: 0.5450 - val_accuracy: 0.7363\n",
      "Epoch 328/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5453 - accuracy: 0.7340 - val_loss: 0.5455 - val_accuracy: 0.7371\n",
      "Epoch 329/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7335 - val_loss: 0.5448 - val_accuracy: 0.7361\n",
      "Epoch 330/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7340 - val_loss: 0.5445 - val_accuracy: 0.7346\n",
      "Epoch 331/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5440 - accuracy: 0.7349 - val_loss: 0.5436 - val_accuracy: 0.7357\n",
      "Epoch 332/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7350 - val_loss: 0.5445 - val_accuracy: 0.7356\n",
      "Epoch 333/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7349 - val_loss: 0.5448 - val_accuracy: 0.7352\n",
      "Epoch 334/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7333 - val_loss: 0.5439 - val_accuracy: 0.7347\n",
      "Epoch 335/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7326 - val_loss: 0.5428 - val_accuracy: 0.7346\n",
      "Epoch 336/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7353 - val_loss: 0.5438 - val_accuracy: 0.7348\n",
      "Epoch 337/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5451 - accuracy: 0.7343 - val_loss: 0.5476 - val_accuracy: 0.7329\n",
      "Epoch 338/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7335 - val_loss: 0.5463 - val_accuracy: 0.7358\n",
      "Epoch 339/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7349 - val_loss: 0.5432 - val_accuracy: 0.7371\n",
      "Epoch 340/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7327 - val_loss: 0.5431 - val_accuracy: 0.7347\n",
      "Epoch 341/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5442 - accuracy: 0.7328 - val_loss: 0.5430 - val_accuracy: 0.7341\n",
      "Epoch 342/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5496 - accuracy: 0.7335 - val_loss: 0.5442 - val_accuracy: 0.7352\n",
      "Epoch 343/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7335 - val_loss: 0.5434 - val_accuracy: 0.7365\n",
      "Epoch 344/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7336 - val_loss: 0.5442 - val_accuracy: 0.7357\n",
      "Epoch 345/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7343 - val_loss: 0.5441 - val_accuracy: 0.7362\n",
      "Epoch 346/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7327 - val_loss: 0.5440 - val_accuracy: 0.7367\n",
      "Epoch 347/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7342 - val_loss: 0.5441 - val_accuracy: 0.7365\n",
      "Epoch 348/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5433 - accuracy: 0.7343 - val_loss: 0.5447 - val_accuracy: 0.7335\n",
      "Epoch 349/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5524 - accuracy: 0.7332 - val_loss: 0.5458 - val_accuracy: 0.7343\n",
      "Epoch 350/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7345 - val_loss: 0.5456 - val_accuracy: 0.7363\n",
      "Epoch 351/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7327 - val_loss: 0.5441 - val_accuracy: 0.7348\n",
      "Epoch 352/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5442 - accuracy: 0.7337 - val_loss: 0.5451 - val_accuracy: 0.7371\n",
      "Epoch 353/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7337 - val_loss: 0.5458 - val_accuracy: 0.7345\n",
      "Epoch 354/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5456 - accuracy: 0.7334 - val_loss: 0.5434 - val_accuracy: 0.7359\n",
      "Epoch 355/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7331 - val_loss: 0.5462 - val_accuracy: 0.7350\n",
      "Epoch 356/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7339 - val_loss: 0.5445 - val_accuracy: 0.7334\n",
      "Epoch 357/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7338 - val_loss: 0.5443 - val_accuracy: 0.7347\n",
      "Epoch 358/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7340 - val_loss: 0.5455 - val_accuracy: 0.7309\n",
      "Epoch 359/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7329 - val_loss: 0.5475 - val_accuracy: 0.7345\n",
      "Epoch 360/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7339 - val_loss: 0.5441 - val_accuracy: 0.7332\n",
      "Epoch 361/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7332 - val_loss: 0.5464 - val_accuracy: 0.7316\n",
      "Epoch 362/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7340 - val_loss: 0.5441 - val_accuracy: 0.7333\n",
      "Epoch 363/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5449 - accuracy: 0.7336 - val_loss: 0.5456 - val_accuracy: 0.7334\n",
      "Epoch 364/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7331 - val_loss: 0.5460 - val_accuracy: 0.7352\n",
      "Epoch 365/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7340 - val_loss: 0.5461 - val_accuracy: 0.7356\n",
      "Epoch 366/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7332 - val_loss: 0.5444 - val_accuracy: 0.7362\n",
      "Epoch 367/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5460 - accuracy: 0.7329 - val_loss: 0.5469 - val_accuracy: 0.7362\n",
      "Epoch 368/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7344 - val_loss: 0.5452 - val_accuracy: 0.7358\n",
      "Epoch 369/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7335 - val_loss: 0.5459 - val_accuracy: 0.7352\n",
      "Epoch 370/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5448 - accuracy: 0.7344 - val_loss: 0.5439 - val_accuracy: 0.7342\n",
      "Epoch 371/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7349 - val_loss: 0.5452 - val_accuracy: 0.7353\n",
      "Epoch 372/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7337 - val_loss: 0.5483 - val_accuracy: 0.7348\n",
      "Epoch 373/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7331 - val_loss: 0.5443 - val_accuracy: 0.7351\n",
      "Epoch 374/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7319 - val_loss: 0.5455 - val_accuracy: 0.7343\n",
      "Epoch 375/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5513 - accuracy: 0.7329 - val_loss: 0.5463 - val_accuracy: 0.7346\n",
      "Epoch 376/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7336 - val_loss: 0.5451 - val_accuracy: 0.7348\n",
      "Epoch 377/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5438 - accuracy: 0.7331 - val_loss: 0.5444 - val_accuracy: 0.7360\n",
      "Epoch 378/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5456 - accuracy: 0.7332 - val_loss: 0.5476 - val_accuracy: 0.7346\n",
      "Epoch 379/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5442 - accuracy: 0.7347 - val_loss: 0.5455 - val_accuracy: 0.7337\n",
      "Epoch 380/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5468 - accuracy: 0.7333 - val_loss: 0.5468 - val_accuracy: 0.7361\n",
      "Epoch 381/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7338 - val_loss: 0.5451 - val_accuracy: 0.7346\n",
      "Epoch 382/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5447 - accuracy: 0.7340 - val_loss: 0.5440 - val_accuracy: 0.7362\n",
      "Epoch 383/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7340 - val_loss: 0.5461 - val_accuracy: 0.7365\n",
      "Epoch 384/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7343 - val_loss: 0.5458 - val_accuracy: 0.7373\n",
      "Epoch 385/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7347 - val_loss: 0.5448 - val_accuracy: 0.7337\n",
      "Epoch 386/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5438 - accuracy: 0.7342 - val_loss: 0.5460 - val_accuracy: 0.7347\n",
      "Epoch 387/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7319 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
      "Epoch 388/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5494 - accuracy: 0.7347 - val_loss: 0.5455 - val_accuracy: 0.7343\n",
      "Epoch 389/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7324 - val_loss: 0.5455 - val_accuracy: 0.7346\n",
      "Epoch 390/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5430 - accuracy: 0.7337 - val_loss: 0.5440 - val_accuracy: 0.7342\n",
      "Epoch 391/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5452 - accuracy: 0.7331 - val_loss: 0.5446 - val_accuracy: 0.7365\n",
      "Epoch 392/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7333 - val_loss: 0.5455 - val_accuracy: 0.7353\n",
      "Epoch 393/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7332 - val_loss: 0.5433 - val_accuracy: 0.7357\n",
      "Epoch 394/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7331 - val_loss: 0.5471 - val_accuracy: 0.7356\n",
      "Epoch 395/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7347 - val_loss: 0.5438 - val_accuracy: 0.7354\n",
      "Epoch 396/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7336 - val_loss: 0.5465 - val_accuracy: 0.7346\n",
      "Epoch 397/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7339 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 398/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7338 - val_loss: 0.5440 - val_accuracy: 0.7350\n",
      "Epoch 399/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7332 - val_loss: 0.5456 - val_accuracy: 0.7373\n",
      "Epoch 400/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7328 - val_loss: 0.5453 - val_accuracy: 0.7364\n",
      "Epoch 401/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7342 - val_loss: 0.5435 - val_accuracy: 0.7354\n",
      "Epoch 402/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7343 - val_loss: 0.5453 - val_accuracy: 0.7354\n",
      "Epoch 403/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7342 - val_loss: 0.5450 - val_accuracy: 0.7339\n",
      "Epoch 404/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7357 - val_loss: 0.5457 - val_accuracy: 0.7355\n",
      "Epoch 405/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7354 - val_loss: 0.5447 - val_accuracy: 0.7345\n",
      "Epoch 406/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5446 - accuracy: 0.7314 - val_loss: 0.5432 - val_accuracy: 0.7352\n",
      "Epoch 407/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7338 - val_loss: 0.5436 - val_accuracy: 0.7335\n",
      "Epoch 408/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5461 - accuracy: 0.7343 - val_loss: 0.5468 - val_accuracy: 0.7355\n",
      "Epoch 409/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7330 - val_loss: 0.5450 - val_accuracy: 0.7344\n",
      "Epoch 410/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7343 - val_loss: 0.5461 - val_accuracy: 0.7354\n",
      "Epoch 411/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7324 - val_loss: 0.5443 - val_accuracy: 0.7372\n",
      "Epoch 412/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5441 - accuracy: 0.7344 - val_loss: 0.5456 - val_accuracy: 0.7373\n",
      "Epoch 413/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7352 - val_loss: 0.5450 - val_accuracy: 0.7362\n",
      "Epoch 414/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7332 - val_loss: 0.5445 - val_accuracy: 0.7354\n",
      "Epoch 415/1500\n",
      "1225/1225 [==============================] - 3s 3ms/step - loss: 0.5444 - accuracy: 0.7343 - val_loss: 0.5442 - val_accuracy: 0.7339\n",
      "Epoch 416/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5532 - accuracy: 0.7337 - val_loss: 0.5436 - val_accuracy: 0.7353\n",
      "Epoch 417/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7318 - val_loss: 0.5452 - val_accuracy: 0.7321\n",
      "Epoch 418/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7317 - val_loss: 0.5442 - val_accuracy: 0.7351\n",
      "Epoch 419/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5433 - accuracy: 0.7347 - val_loss: 0.5439 - val_accuracy: 0.7355\n",
      "Epoch 420/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5451 - accuracy: 0.7342 - val_loss: 0.5456 - val_accuracy: 0.7340\n",
      "Epoch 421/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5457 - accuracy: 0.7314 - val_loss: 0.5449 - val_accuracy: 0.7348\n",
      "Epoch 422/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7343 - val_loss: 0.5448 - val_accuracy: 0.7363\n",
      "Epoch 423/1500\n",
      "1225/1225 [==============================] - 2s 1ms/step - loss: 0.5454 - accuracy: 0.7328 - val_loss: 0.5450 - val_accuracy: 0.7356\n",
      "Epoch 424/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7318 - val_loss: 0.5461 - val_accuracy: 0.7343\n",
      "Epoch 425/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7336 - val_loss: 0.5456 - val_accuracy: 0.7346\n",
      "Epoch 426/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7344 - val_loss: 0.5455 - val_accuracy: 0.7356\n",
      "Epoch 427/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7327 - val_loss: 0.5471 - val_accuracy: 0.7340\n",
      "Epoch 428/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7355 - val_loss: 0.5452 - val_accuracy: 0.7349\n",
      "Epoch 429/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7322 - val_loss: 0.5462 - val_accuracy: 0.7352\n",
      "Epoch 430/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5442 - accuracy: 0.7357 - val_loss: 0.5453 - val_accuracy: 0.7357\n",
      "Epoch 431/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5441 - accuracy: 0.7344 - val_loss: 0.5451 - val_accuracy: 0.7337\n",
      "Epoch 432/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5440 - accuracy: 0.7347 - val_loss: 0.5464 - val_accuracy: 0.7347\n",
      "Epoch 433/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7341 - val_loss: 0.5468 - val_accuracy: 0.7347\n",
      "Epoch 434/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5445 - accuracy: 0.7342 - val_loss: 0.5488 - val_accuracy: 0.7328\n",
      "Epoch 435/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7331 - val_loss: 0.5456 - val_accuracy: 0.7338\n",
      "Epoch 436/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5454 - accuracy: 0.7336 - val_loss: 0.5483 - val_accuracy: 0.7332\n",
      "Epoch 437/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5444 - accuracy: 0.7330 - val_loss: 0.5473 - val_accuracy: 0.7345\n",
      "Epoch 438/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7344 - val_loss: 0.5466 - val_accuracy: 0.7357\n",
      "Epoch 439/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5456 - accuracy: 0.7326 - val_loss: 0.5451 - val_accuracy: 0.7352\n",
      "Epoch 440/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7340 - val_loss: 0.5480 - val_accuracy: 0.7346\n",
      "Epoch 441/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7325 - val_loss: 0.5445 - val_accuracy: 0.7355\n",
      "Epoch 442/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5492 - accuracy: 0.7348 - val_loss: 0.5450 - val_accuracy: 0.7333\n",
      "Epoch 443/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7360 - val_loss: 0.5455 - val_accuracy: 0.7348\n",
      "Epoch 444/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7336 - val_loss: 0.5458 - val_accuracy: 0.7342\n",
      "Epoch 445/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7343 - val_loss: 0.5444 - val_accuracy: 0.7346\n",
      "Epoch 446/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5442 - accuracy: 0.7338 - val_loss: 0.5456 - val_accuracy: 0.7359\n",
      "Epoch 447/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7346 - val_loss: 0.5452 - val_accuracy: 0.7346\n",
      "Epoch 448/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7327 - val_loss: 0.5455 - val_accuracy: 0.7339\n",
      "Epoch 449/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7345 - val_loss: 0.5463 - val_accuracy: 0.7364\n",
      "Epoch 450/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7347 - val_loss: 0.5445 - val_accuracy: 0.7354\n",
      "Epoch 451/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7338 - val_loss: 0.5501 - val_accuracy: 0.7329\n",
      "Epoch 452/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5453 - accuracy: 0.7328 - val_loss: 0.5450 - val_accuracy: 0.7364\n",
      "Epoch 453/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7332 - val_loss: 0.5456 - val_accuracy: 0.7367\n",
      "Epoch 454/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7333 - val_loss: 0.5452 - val_accuracy: 0.7359\n",
      "Epoch 455/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7331 - val_loss: 0.5450 - val_accuracy: 0.7339\n",
      "Epoch 456/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7330 - val_loss: 0.5466 - val_accuracy: 0.7337\n",
      "Epoch 457/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.7319 - val_loss: 0.5454 - val_accuracy: 0.7347\n",
      "Epoch 458/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5475 - accuracy: 0.7331 - val_loss: 0.5461 - val_accuracy: 0.7348\n",
      "Epoch 459/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5439 - accuracy: 0.7325 - val_loss: 0.5453 - val_accuracy: 0.7339\n",
      "Epoch 460/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7346 - val_loss: 0.5455 - val_accuracy: 0.7336\n",
      "Epoch 461/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7318 - val_loss: 0.5469 - val_accuracy: 0.7323\n",
      "Epoch 462/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7340 - val_loss: 0.5467 - val_accuracy: 0.7326\n",
      "Epoch 463/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7337 - val_loss: 0.5467 - val_accuracy: 0.7357\n",
      "Epoch 464/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7303 - val_loss: 0.5456 - val_accuracy: 0.7342\n",
      "Epoch 465/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5452 - accuracy: 0.7340 - val_loss: 0.5482 - val_accuracy: 0.7306\n",
      "Epoch 466/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5440 - accuracy: 0.7341 - val_loss: 0.5464 - val_accuracy: 0.7349\n",
      "Epoch 467/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7336 - val_loss: 0.5465 - val_accuracy: 0.7352\n",
      "Epoch 468/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7349 - val_loss: 0.5451 - val_accuracy: 0.7338\n",
      "Epoch 469/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7326 - val_loss: 0.5446 - val_accuracy: 0.7401\n",
      "Epoch 470/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7323 - val_loss: 0.5439 - val_accuracy: 0.7372\n",
      "Epoch 471/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5436 - accuracy: 0.7346 - val_loss: 0.5465 - val_accuracy: 0.7353\n",
      "Epoch 472/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7355 - val_loss: 0.5451 - val_accuracy: 0.7355\n",
      "Epoch 473/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7341 - val_loss: 0.5450 - val_accuracy: 0.7359\n",
      "Epoch 474/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7324 - val_loss: 0.5451 - val_accuracy: 0.7362\n",
      "Epoch 475/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7332 - val_loss: 0.5436 - val_accuracy: 0.7370\n",
      "Epoch 476/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7346 - val_loss: 0.5462 - val_accuracy: 0.7358\n",
      "Epoch 477/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7347 - val_loss: 0.5455 - val_accuracy: 0.7367\n",
      "Epoch 478/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5461 - accuracy: 0.7335 - val_loss: 0.5456 - val_accuracy: 0.7345\n",
      "Epoch 479/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7328 - val_loss: 0.5463 - val_accuracy: 0.7317\n",
      "Epoch 480/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7318 - val_loss: 0.5455 - val_accuracy: 0.7350\n",
      "Epoch 481/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7331 - val_loss: 0.5464 - val_accuracy: 0.7319\n",
      "Epoch 482/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7340 - val_loss: 0.5466 - val_accuracy: 0.7312\n",
      "Epoch 483/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7336 - val_loss: 0.5471 - val_accuracy: 0.7330\n",
      "Epoch 484/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7333 - val_loss: 0.5466 - val_accuracy: 0.7335\n",
      "Epoch 485/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5453 - accuracy: 0.7330 - val_loss: 0.5468 - val_accuracy: 0.7313\n",
      "Epoch 486/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7340 - val_loss: 0.5463 - val_accuracy: 0.7335\n",
      "Epoch 487/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7336 - val_loss: 0.5463 - val_accuracy: 0.7321\n",
      "Epoch 488/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5427 - accuracy: 0.7327 - val_loss: 0.5456 - val_accuracy: 0.7353\n",
      "Epoch 489/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7328 - val_loss: 0.5457 - val_accuracy: 0.7340\n",
      "Epoch 490/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7326 - val_loss: 0.5478 - val_accuracy: 0.7332\n",
      "Epoch 491/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7333 - val_loss: 0.5467 - val_accuracy: 0.7331\n",
      "Epoch 492/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7344 - val_loss: 0.5458 - val_accuracy: 0.7341\n",
      "Epoch 493/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7346 - val_loss: 0.5479 - val_accuracy: 0.7347\n",
      "Epoch 494/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7338 - val_loss: 0.5473 - val_accuracy: 0.7376\n",
      "Epoch 495/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7336 - val_loss: 0.5469 - val_accuracy: 0.7356\n",
      "Epoch 496/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7350 - val_loss: 0.5462 - val_accuracy: 0.7354\n",
      "Epoch 497/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7348 - val_loss: 0.5501 - val_accuracy: 0.7348\n",
      "Epoch 498/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5439 - accuracy: 0.7327 - val_loss: 0.5472 - val_accuracy: 0.7348\n",
      "Epoch 499/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7334 - val_loss: 0.5452 - val_accuracy: 0.7348\n",
      "Epoch 500/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7324 - val_loss: 0.5449 - val_accuracy: 0.7345\n",
      "Epoch 501/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7339 - val_loss: 0.5473 - val_accuracy: 0.7339\n",
      "Epoch 502/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7320 - val_loss: 0.5450 - val_accuracy: 0.7357\n",
      "Epoch 503/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7344 - val_loss: 0.5459 - val_accuracy: 0.7346\n",
      "Epoch 504/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5437 - accuracy: 0.7337 - val_loss: 0.5451 - val_accuracy: 0.7338\n",
      "Epoch 505/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7332 - val_loss: 0.5489 - val_accuracy: 0.7330\n",
      "Epoch 506/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7346 - val_loss: 0.5456 - val_accuracy: 0.7328\n",
      "Epoch 507/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7326 - val_loss: 0.5471 - val_accuracy: 0.7346\n",
      "Epoch 508/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7352 - val_loss: 0.5450 - val_accuracy: 0.7364\n",
      "Epoch 509/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7335 - val_loss: 0.5484 - val_accuracy: 0.7358\n",
      "Epoch 510/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7349 - val_loss: 0.5463 - val_accuracy: 0.7359\n",
      "Epoch 511/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5440 - accuracy: 0.7348 - val_loss: 0.5460 - val_accuracy: 0.7338\n",
      "Epoch 512/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5513 - accuracy: 0.7343 - val_loss: 0.5468 - val_accuracy: 0.7355\n",
      "Epoch 513/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7347 - val_loss: 0.5457 - val_accuracy: 0.7348\n",
      "Epoch 514/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7334 - val_loss: 0.5458 - val_accuracy: 0.7363\n",
      "Epoch 515/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7330 - val_loss: 0.5470 - val_accuracy: 0.7352\n",
      "Epoch 516/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7340 - val_loss: 0.5467 - val_accuracy: 0.7368\n",
      "Epoch 517/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5429 - accuracy: 0.7356 - val_loss: 0.5462 - val_accuracy: 0.7351\n",
      "Epoch 518/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7354 - val_loss: 0.5460 - val_accuracy: 0.7324\n",
      "Epoch 519/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7330 - val_loss: 0.5469 - val_accuracy: 0.7331\n",
      "Epoch 520/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5449 - accuracy: 0.7327 - val_loss: 0.5484 - val_accuracy: 0.7351\n",
      "Epoch 521/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7330 - val_loss: 0.5476 - val_accuracy: 0.7319\n",
      "Epoch 522/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7324 - val_loss: 0.5467 - val_accuracy: 0.7361\n",
      "Epoch 523/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7356 - val_loss: 0.5452 - val_accuracy: 0.7356\n",
      "Epoch 524/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7345 - val_loss: 0.5463 - val_accuracy: 0.7331\n",
      "Epoch 525/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7340 - val_loss: 0.5482 - val_accuracy: 0.7354\n",
      "Epoch 526/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5434 - accuracy: 0.7332 - val_loss: 0.5476 - val_accuracy: 0.7345\n",
      "Epoch 527/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7351 - val_loss: 0.5488 - val_accuracy: 0.7377\n",
      "Epoch 528/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7347 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
      "Epoch 529/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7356 - val_loss: 0.5455 - val_accuracy: 0.7342\n",
      "Epoch 530/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5440 - accuracy: 0.7355 - val_loss: 0.5470 - val_accuracy: 0.7352\n",
      "Epoch 531/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5455 - accuracy: 0.7342 - val_loss: 0.5475 - val_accuracy: 0.7356\n",
      "Epoch 532/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7324 - val_loss: 0.5477 - val_accuracy: 0.7347\n",
      "Epoch 533/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7320 - val_loss: 0.5467 - val_accuracy: 0.7333\n",
      "Epoch 534/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7331 - val_loss: 0.5464 - val_accuracy: 0.7352\n",
      "Epoch 535/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7334 - val_loss: 0.5472 - val_accuracy: 0.7356\n",
      "Epoch 536/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7327 - val_loss: 0.5459 - val_accuracy: 0.7353\n",
      "Epoch 537/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5438 - accuracy: 0.7350 - val_loss: 0.5460 - val_accuracy: 0.7332\n",
      "Epoch 538/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7341 - val_loss: 0.5481 - val_accuracy: 0.7324\n",
      "Epoch 539/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7341 - val_loss: 0.5474 - val_accuracy: 0.7320\n",
      "Epoch 540/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7344 - val_loss: 0.5478 - val_accuracy: 0.7362\n",
      "Epoch 541/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7344 - val_loss: 0.5482 - val_accuracy: 0.7330\n",
      "Epoch 542/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7348 - val_loss: 0.5477 - val_accuracy: 0.7323\n",
      "Epoch 543/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5445 - accuracy: 0.7333 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
      "Epoch 544/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5439 - accuracy: 0.7338 - val_loss: 0.5469 - val_accuracy: 0.7352\n",
      "Epoch 545/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7343 - val_loss: 0.5461 - val_accuracy: 0.7355\n",
      "Epoch 546/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7344 - val_loss: 0.5472 - val_accuracy: 0.7341\n",
      "Epoch 547/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7344 - val_loss: 0.5478 - val_accuracy: 0.7340\n",
      "Epoch 548/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7320 - val_loss: 0.5516 - val_accuracy: 0.7293\n",
      "Epoch 549/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7345 - val_loss: 0.5483 - val_accuracy: 0.7365\n",
      "Epoch 550/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5447 - accuracy: 0.7330 - val_loss: 0.5473 - val_accuracy: 0.7355\n",
      "Epoch 551/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7345 - val_loss: 0.5463 - val_accuracy: 0.7340\n",
      "Epoch 552/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7335 - val_loss: 0.5474 - val_accuracy: 0.7343\n",
      "Epoch 553/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7334 - val_loss: 0.5460 - val_accuracy: 0.7345\n",
      "Epoch 554/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7338 - val_loss: 0.5466 - val_accuracy: 0.7324\n",
      "Epoch 555/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7337 - val_loss: 0.5474 - val_accuracy: 0.7329\n",
      "Epoch 556/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5459 - accuracy: 0.7348 - val_loss: 0.5499 - val_accuracy: 0.7344\n",
      "Epoch 557/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5457 - accuracy: 0.7341 - val_loss: 0.5470 - val_accuracy: 0.7349\n",
      "Epoch 558/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7356 - val_loss: 0.5475 - val_accuracy: 0.7331\n",
      "Epoch 559/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7337 - val_loss: 0.5480 - val_accuracy: 0.7337\n",
      "Epoch 560/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7336 - val_loss: 0.5469 - val_accuracy: 0.7327\n",
      "Epoch 561/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7334 - val_loss: 0.5475 - val_accuracy: 0.7322\n",
      "Epoch 562/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7346 - val_loss: 0.5486 - val_accuracy: 0.7333\n",
      "Epoch 563/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5437 - accuracy: 0.7346 - val_loss: 0.5460 - val_accuracy: 0.7349\n",
      "Epoch 564/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7351 - val_loss: 0.5450 - val_accuracy: 0.7339\n",
      "Epoch 565/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7339 - val_loss: 0.5471 - val_accuracy: 0.7327\n",
      "Epoch 566/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7333 - val_loss: 0.5469 - val_accuracy: 0.7331\n",
      "Epoch 567/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7331 - val_loss: 0.5486 - val_accuracy: 0.7341\n",
      "Epoch 568/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7338 - val_loss: 0.5489 - val_accuracy: 0.7357\n",
      "Epoch 569/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7346 - val_loss: 0.5473 - val_accuracy: 0.7326\n",
      "Epoch 570/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5438 - accuracy: 0.7337 - val_loss: 0.5461 - val_accuracy: 0.7345\n",
      "Epoch 571/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7326 - val_loss: 0.5484 - val_accuracy: 0.7338\n",
      "Epoch 572/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7332 - val_loss: 0.5465 - val_accuracy: 0.7324\n",
      "Epoch 573/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7354 - val_loss: 0.5483 - val_accuracy: 0.7330\n",
      "Epoch 574/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7325 - val_loss: 0.5465 - val_accuracy: 0.7335\n",
      "Epoch 575/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7346 - val_loss: 0.5486 - val_accuracy: 0.7328\n",
      "Epoch 576/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7344 - val_loss: 0.5475 - val_accuracy: 0.7342\n",
      "Epoch 577/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7330 - val_loss: 0.5472 - val_accuracy: 0.7320\n",
      "Epoch 578/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7344 - val_loss: 0.5475 - val_accuracy: 0.7327\n",
      "Epoch 579/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7337 - val_loss: 0.5465 - val_accuracy: 0.7348\n",
      "Epoch 580/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7352 - val_loss: 0.5466 - val_accuracy: 0.7346\n",
      "Epoch 581/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7322 - val_loss: 0.5472 - val_accuracy: 0.7322\n",
      "Epoch 582/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7327 - val_loss: 0.5474 - val_accuracy: 0.7341\n",
      "Epoch 583/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5444 - accuracy: 0.7345 - val_loss: 0.5473 - val_accuracy: 0.7336\n",
      "Epoch 584/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7335 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 585/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5475 - accuracy: 0.7348 - val_loss: 0.5465 - val_accuracy: 0.7335\n",
      "Epoch 586/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7335 - val_loss: 0.5475 - val_accuracy: 0.7339\n",
      "Epoch 587/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7328 - val_loss: 0.5468 - val_accuracy: 0.7337\n",
      "Epoch 588/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7331 - val_loss: 0.5467 - val_accuracy: 0.7350\n",
      "Epoch 589/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7339 - val_loss: 0.5455 - val_accuracy: 0.7336\n",
      "Epoch 590/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7342 - val_loss: 0.5481 - val_accuracy: 0.7348\n",
      "Epoch 591/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7343 - val_loss: 0.5449 - val_accuracy: 0.7320\n",
      "Epoch 592/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7337 - val_loss: 0.5475 - val_accuracy: 0.7339\n",
      "Epoch 593/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7326 - val_loss: 0.5463 - val_accuracy: 0.7310\n",
      "Epoch 594/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7325 - val_loss: 0.5451 - val_accuracy: 0.7353\n",
      "Epoch 595/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7349 - val_loss: 0.5462 - val_accuracy: 0.7338\n",
      "Epoch 596/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5445 - accuracy: 0.7336 - val_loss: 0.5476 - val_accuracy: 0.7342\n",
      "Epoch 597/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7338 - val_loss: 0.5463 - val_accuracy: 0.7334\n",
      "Epoch 598/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5449 - accuracy: 0.7341 - val_loss: 0.5464 - val_accuracy: 0.7338\n",
      "Epoch 599/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7347 - val_loss: 0.5459 - val_accuracy: 0.7339\n",
      "Epoch 600/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5476 - accuracy: 0.7352 - val_loss: 0.5468 - val_accuracy: 0.7335\n",
      "Epoch 601/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7326 - val_loss: 0.5481 - val_accuracy: 0.7320\n",
      "Epoch 602/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7345 - val_loss: 0.5477 - val_accuracy: 0.7352\n",
      "Epoch 603/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7338 - val_loss: 0.5473 - val_accuracy: 0.7342\n",
      "Epoch 604/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7347 - val_loss: 0.5496 - val_accuracy: 0.7341\n",
      "Epoch 605/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7346 - val_loss: 0.5461 - val_accuracy: 0.7336\n",
      "Epoch 606/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5456 - accuracy: 0.7334 - val_loss: 0.5474 - val_accuracy: 0.7328\n",
      "Epoch 607/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5450 - accuracy: 0.7335 - val_loss: 0.5460 - val_accuracy: 0.7338\n",
      "Epoch 608/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7324 - val_loss: 0.5479 - val_accuracy: 0.7330\n",
      "Epoch 609/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5449 - accuracy: 0.7338 - val_loss: 0.5485 - val_accuracy: 0.7328\n",
      "Epoch 610/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7336 - val_loss: 0.5455 - val_accuracy: 0.7310\n",
      "Epoch 611/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7346 - val_loss: 0.5463 - val_accuracy: 0.7317\n",
      "Epoch 612/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7347 - val_loss: 0.5469 - val_accuracy: 0.7356\n",
      "Epoch 613/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5470 - accuracy: 0.7346 - val_loss: 0.5475 - val_accuracy: 0.7360\n",
      "Epoch 614/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5431 - accuracy: 0.7350 - val_loss: 0.5468 - val_accuracy: 0.7326\n",
      "Epoch 615/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7318 - val_loss: 0.5476 - val_accuracy: 0.7327\n",
      "Epoch 616/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7335 - val_loss: 0.5464 - val_accuracy: 0.7336\n",
      "Epoch 617/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7326 - val_loss: 0.5458 - val_accuracy: 0.7332\n",
      "Epoch 618/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7343 - val_loss: 0.5457 - val_accuracy: 0.7338\n",
      "Epoch 619/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7343 - val_loss: 0.5452 - val_accuracy: 0.7335\n",
      "Epoch 620/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5440 - accuracy: 0.7338 - val_loss: 0.5502 - val_accuracy: 0.7332\n",
      "Epoch 621/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7344 - val_loss: 0.5473 - val_accuracy: 0.7345\n",
      "Epoch 622/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5446 - accuracy: 0.7346 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
      "Epoch 623/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7332 - val_loss: 0.5459 - val_accuracy: 0.7333\n",
      "Epoch 624/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7334 - val_loss: 0.5460 - val_accuracy: 0.7331\n",
      "Epoch 625/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5505 - accuracy: 0.7338 - val_loss: 0.5466 - val_accuracy: 0.7321\n",
      "Epoch 626/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7327 - val_loss: 0.5465 - val_accuracy: 0.7362\n",
      "Epoch 627/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7344 - val_loss: 0.5462 - val_accuracy: 0.7328\n",
      "Epoch 628/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5434 - accuracy: 0.7341 - val_loss: 0.5469 - val_accuracy: 0.7356\n",
      "Epoch 629/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7343 - val_loss: 0.5460 - val_accuracy: 0.7347\n",
      "Epoch 630/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7336 - val_loss: 0.5461 - val_accuracy: 0.7345\n",
      "Epoch 631/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7344 - val_loss: 0.5475 - val_accuracy: 0.7360\n",
      "Epoch 632/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7342 - val_loss: 0.5468 - val_accuracy: 0.7321\n",
      "Epoch 633/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7335 - val_loss: 0.5499 - val_accuracy: 0.7346\n",
      "Epoch 634/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7346 - val_loss: 0.5489 - val_accuracy: 0.7328\n",
      "Epoch 635/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5419 - accuracy: 0.7338 - val_loss: 0.5465 - val_accuracy: 0.7315\n",
      "Epoch 636/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7343 - val_loss: 0.5499 - val_accuracy: 0.7333\n",
      "Epoch 637/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5436 - accuracy: 0.7336 - val_loss: 0.5470 - val_accuracy: 0.7318\n",
      "Epoch 638/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5425 - accuracy: 0.7346 - val_loss: 0.5474 - val_accuracy: 0.7330\n",
      "Epoch 639/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5445 - accuracy: 0.7334 - val_loss: 0.5488 - val_accuracy: 0.7324\n",
      "Epoch 640/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7339 - val_loss: 0.5463 - val_accuracy: 0.7348\n",
      "Epoch 641/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5436 - accuracy: 0.7342 - val_loss: 0.5470 - val_accuracy: 0.7337\n",
      "Epoch 642/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7347 - val_loss: 0.5496 - val_accuracy: 0.7335\n",
      "Epoch 643/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7345 - val_loss: 0.5472 - val_accuracy: 0.7331\n",
      "Epoch 644/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5443 - accuracy: 0.7338 - val_loss: 0.5473 - val_accuracy: 0.7345\n",
      "Epoch 645/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7341 - val_loss: 0.5464 - val_accuracy: 0.7349\n",
      "Epoch 646/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7344 - val_loss: 0.5464 - val_accuracy: 0.7338\n",
      "Epoch 647/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7343 - val_loss: 0.5494 - val_accuracy: 0.7339\n",
      "Epoch 648/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5422 - accuracy: 0.7334 - val_loss: 0.5473 - val_accuracy: 0.7330\n",
      "Epoch 649/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5531 - accuracy: 0.7333 - val_loss: 0.5500 - val_accuracy: 0.7302\n",
      "Epoch 650/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5485 - accuracy: 0.7340 - val_loss: 0.5485 - val_accuracy: 0.7314\n",
      "Epoch 651/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.7339 - val_loss: 0.5486 - val_accuracy: 0.7331\n",
      "Epoch 652/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7329 - val_loss: 0.5467 - val_accuracy: 0.7335\n",
      "Epoch 653/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5441 - accuracy: 0.7333 - val_loss: 0.5467 - val_accuracy: 0.7335\n",
      "Epoch 654/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5449 - accuracy: 0.7342 - val_loss: 0.5480 - val_accuracy: 0.7345\n",
      "Epoch 655/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7329 - val_loss: 0.5477 - val_accuracy: 0.7335\n",
      "Epoch 656/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7338 - val_loss: 0.5482 - val_accuracy: 0.7343\n",
      "Epoch 657/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5440 - accuracy: 0.7329 - val_loss: 0.5467 - val_accuracy: 0.7350\n",
      "Epoch 658/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5465 - accuracy: 0.7324 - val_loss: 0.5467 - val_accuracy: 0.7338\n",
      "Epoch 659/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5438 - accuracy: 0.7338 - val_loss: 0.5490 - val_accuracy: 0.7320\n",
      "Epoch 660/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5429 - accuracy: 0.7342 - val_loss: 0.5497 - val_accuracy: 0.7341\n",
      "Epoch 661/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7337 - val_loss: 0.5474 - val_accuracy: 0.7347\n",
      "Epoch 662/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5436 - accuracy: 0.7333 - val_loss: 0.5479 - val_accuracy: 0.7333\n",
      "Epoch 663/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5434 - accuracy: 0.7338 - val_loss: 0.5469 - val_accuracy: 0.7331\n",
      "Epoch 664/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7325 - val_loss: 0.5485 - val_accuracy: 0.7338\n",
      "Epoch 665/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7347 - val_loss: 0.5480 - val_accuracy: 0.7359\n",
      "Epoch 666/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5442 - accuracy: 0.7332 - val_loss: 0.5463 - val_accuracy: 0.7335\n",
      "Epoch 667/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5439 - accuracy: 0.7342 - val_loss: 0.5467 - val_accuracy: 0.7347\n",
      "Epoch 668/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7336 - val_loss: 0.5482 - val_accuracy: 0.7339\n",
      "Epoch 669/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7324 - val_loss: 0.5504 - val_accuracy: 0.7354\n",
      "Epoch 670/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7332 - val_loss: 0.5489 - val_accuracy: 0.7357\n",
      "Epoch 671/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7338 - val_loss: 0.5490 - val_accuracy: 0.7347\n",
      "Epoch 672/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7341 - val_loss: 0.5476 - val_accuracy: 0.7330\n",
      "Epoch 673/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5475 - accuracy: 0.7349 - val_loss: 0.5482 - val_accuracy: 0.7323\n",
      "Epoch 674/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7339 - val_loss: 0.5453 - val_accuracy: 0.7336\n",
      "Epoch 675/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7322 - val_loss: 0.5496 - val_accuracy: 0.7338\n",
      "Epoch 676/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7335 - val_loss: 0.5455 - val_accuracy: 0.7353\n",
      "Epoch 677/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5558 - accuracy: 0.7339 - val_loss: 0.5468 - val_accuracy: 0.7330\n",
      "Epoch 678/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7335 - val_loss: 0.5469 - val_accuracy: 0.7354\n",
      "Epoch 679/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5438 - accuracy: 0.7344 - val_loss: 0.5481 - val_accuracy: 0.7326\n",
      "Epoch 680/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7329 - val_loss: 0.5484 - val_accuracy: 0.7342\n",
      "Epoch 681/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7344 - val_loss: 0.5477 - val_accuracy: 0.7334\n",
      "Epoch 682/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7315 - val_loss: 0.5474 - val_accuracy: 0.7334\n",
      "Epoch 683/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7334 - val_loss: 0.5494 - val_accuracy: 0.7334\n",
      "Epoch 684/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7332 - val_loss: 0.5483 - val_accuracy: 0.7332\n",
      "Epoch 685/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7329 - val_loss: 0.5478 - val_accuracy: 0.7320\n",
      "Epoch 686/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7334 - val_loss: 0.5474 - val_accuracy: 0.7315\n",
      "Epoch 687/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7343 - val_loss: 0.5481 - val_accuracy: 0.7332\n",
      "Epoch 688/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7337 - val_loss: 0.5478 - val_accuracy: 0.7318\n",
      "Epoch 689/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7312 - val_loss: 0.5498 - val_accuracy: 0.7287\n",
      "Epoch 690/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7331 - val_loss: 0.5481 - val_accuracy: 0.7336\n",
      "Epoch 691/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7331 - val_loss: 0.5472 - val_accuracy: 0.7338\n",
      "Epoch 692/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5422 - accuracy: 0.7327 - val_loss: 0.5513 - val_accuracy: 0.7331\n",
      "Epoch 693/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5439 - accuracy: 0.7346 - val_loss: 0.5457 - val_accuracy: 0.7335\n",
      "Epoch 694/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7342 - val_loss: 0.5492 - val_accuracy: 0.7335\n",
      "Epoch 695/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7328 - val_loss: 0.5465 - val_accuracy: 0.7326\n",
      "Epoch 696/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7340 - val_loss: 0.5467 - val_accuracy: 0.7321\n",
      "Epoch 697/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7343 - val_loss: 0.5502 - val_accuracy: 0.7315\n",
      "Epoch 698/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7354 - val_loss: 0.5496 - val_accuracy: 0.7312\n",
      "Epoch 699/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5436 - accuracy: 0.7336 - val_loss: 0.5484 - val_accuracy: 0.7310\n",
      "Epoch 700/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7338 - val_loss: 0.5484 - val_accuracy: 0.7337\n",
      "Epoch 701/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7342 - val_loss: 0.5470 - val_accuracy: 0.7317\n",
      "Epoch 702/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7344 - val_loss: 0.5472 - val_accuracy: 0.7319\n",
      "Epoch 703/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5485 - accuracy: 0.7329 - val_loss: 0.5481 - val_accuracy: 0.7300\n",
      "Epoch 704/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7311 - val_loss: 0.5469 - val_accuracy: 0.7322\n",
      "Epoch 705/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7332 - val_loss: 0.5484 - val_accuracy: 0.7339\n",
      "Epoch 706/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5465 - accuracy: 0.7342 - val_loss: 0.5494 - val_accuracy: 0.7298\n",
      "Epoch 707/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7329 - val_loss: 0.5477 - val_accuracy: 0.7320\n",
      "Epoch 708/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7342 - val_loss: 0.5479 - val_accuracy: 0.7331\n",
      "Epoch 709/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7327 - val_loss: 0.5476 - val_accuracy: 0.7335\n",
      "Epoch 710/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7358 - val_loss: 0.5490 - val_accuracy: 0.7335\n",
      "Epoch 711/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7349 - val_loss: 0.5485 - val_accuracy: 0.7343\n",
      "Epoch 712/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5446 - accuracy: 0.7351 - val_loss: 0.5476 - val_accuracy: 0.7317\n",
      "Epoch 713/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7339 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
      "Epoch 714/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7324 - val_loss: 0.5465 - val_accuracy: 0.7322\n",
      "Epoch 715/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5436 - accuracy: 0.7329 - val_loss: 0.5459 - val_accuracy: 0.7348\n",
      "Epoch 716/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7344 - val_loss: 0.5481 - val_accuracy: 0.7331\n",
      "Epoch 717/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7335 - val_loss: 0.5453 - val_accuracy: 0.7343\n",
      "Epoch 718/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7331 - val_loss: 0.5472 - val_accuracy: 0.7333\n",
      "Epoch 719/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5433 - accuracy: 0.7337 - val_loss: 0.5463 - val_accuracy: 0.7321\n",
      "Epoch 720/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5446 - accuracy: 0.7345 - val_loss: 0.5457 - val_accuracy: 0.7339\n",
      "Epoch 721/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7336 - val_loss: 0.5487 - val_accuracy: 0.7309\n",
      "Epoch 722/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7325 - val_loss: 0.5471 - val_accuracy: 0.7315\n",
      "Epoch 723/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7355 - val_loss: 0.5474 - val_accuracy: 0.7330\n",
      "Epoch 724/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7331 - val_loss: 0.5472 - val_accuracy: 0.7324\n",
      "Epoch 725/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5454 - accuracy: 0.7341 - val_loss: 0.5536 - val_accuracy: 0.7305\n",
      "Epoch 726/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7338 - val_loss: 0.5466 - val_accuracy: 0.7316\n",
      "Epoch 727/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7338 - val_loss: 0.5485 - val_accuracy: 0.7314\n",
      "Epoch 728/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5411 - accuracy: 0.7339 - val_loss: 0.5510 - val_accuracy: 0.7337\n",
      "Epoch 729/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7340 - val_loss: 0.5496 - val_accuracy: 0.7345\n",
      "Epoch 730/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7329 - val_loss: 0.5467 - val_accuracy: 0.7320\n",
      "Epoch 731/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7345 - val_loss: 0.5476 - val_accuracy: 0.7331\n",
      "Epoch 732/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5427 - accuracy: 0.7336 - val_loss: 0.5472 - val_accuracy: 0.7334\n",
      "Epoch 733/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5429 - accuracy: 0.7334 - val_loss: 0.5495 - val_accuracy: 0.7336\n",
      "Epoch 734/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7351 - val_loss: 0.5480 - val_accuracy: 0.7347\n",
      "Epoch 735/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7341 - val_loss: 0.5485 - val_accuracy: 0.7343\n",
      "Epoch 736/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7347 - val_loss: 0.5469 - val_accuracy: 0.7330\n",
      "Epoch 737/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7332 - val_loss: 0.5494 - val_accuracy: 0.7342\n",
      "Epoch 738/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5446 - accuracy: 0.7347 - val_loss: 0.5459 - val_accuracy: 0.7359\n",
      "Epoch 739/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7355 - val_loss: 0.5503 - val_accuracy: 0.7338\n",
      "Epoch 740/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5431 - accuracy: 0.7320 - val_loss: 0.5484 - val_accuracy: 0.7323\n",
      "Epoch 741/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7322 - val_loss: 0.5498 - val_accuracy: 0.7328\n",
      "Epoch 742/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7334 - val_loss: 0.5484 - val_accuracy: 0.7311\n",
      "Epoch 743/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7336 - val_loss: 0.5482 - val_accuracy: 0.7337\n",
      "Epoch 744/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5429 - accuracy: 0.7348 - val_loss: 0.5469 - val_accuracy: 0.7339\n",
      "Epoch 745/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5429 - accuracy: 0.7345 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
      "Epoch 746/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7342 - val_loss: 0.5488 - val_accuracy: 0.7344\n",
      "Epoch 747/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7338 - val_loss: 0.5473 - val_accuracy: 0.7356\n",
      "Epoch 748/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5449 - accuracy: 0.7322 - val_loss: 0.5500 - val_accuracy: 0.7311\n",
      "Epoch 749/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7332 - val_loss: 0.5478 - val_accuracy: 0.7322\n",
      "Epoch 750/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7340 - val_loss: 0.5509 - val_accuracy: 0.7358\n",
      "Epoch 751/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5486 - accuracy: 0.7352 - val_loss: 0.5471 - val_accuracy: 0.7355\n",
      "Epoch 752/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7351 - val_loss: 0.5472 - val_accuracy: 0.7303\n",
      "Epoch 753/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7358 - val_loss: 0.5480 - val_accuracy: 0.7326\n",
      "Epoch 754/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7335 - val_loss: 0.5489 - val_accuracy: 0.7311\n",
      "Epoch 755/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7335 - val_loss: 0.5473 - val_accuracy: 0.7326\n",
      "Epoch 756/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7348 - val_loss: 0.5480 - val_accuracy: 0.7320\n",
      "Epoch 757/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7340 - val_loss: 0.5468 - val_accuracy: 0.7330\n",
      "Epoch 758/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5422 - accuracy: 0.7347 - val_loss: 0.5500 - val_accuracy: 0.7314\n",
      "Epoch 759/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7333 - val_loss: 0.5504 - val_accuracy: 0.7306\n",
      "Epoch 760/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5456 - accuracy: 0.7342 - val_loss: 0.5504 - val_accuracy: 0.7302\n",
      "Epoch 761/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7334 - val_loss: 0.5498 - val_accuracy: 0.7326\n",
      "Epoch 762/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7326 - val_loss: 0.5502 - val_accuracy: 0.7338\n",
      "Epoch 763/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7353 - val_loss: 0.5486 - val_accuracy: 0.7332\n",
      "Epoch 764/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5424 - accuracy: 0.7340 - val_loss: 0.5478 - val_accuracy: 0.7327\n",
      "Epoch 765/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7337 - val_loss: 0.5483 - val_accuracy: 0.7347\n",
      "Epoch 766/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7336 - val_loss: 0.5474 - val_accuracy: 0.7335\n",
      "Epoch 767/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7347 - val_loss: 0.5480 - val_accuracy: 0.7328\n",
      "Epoch 768/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5410 - accuracy: 0.7330 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
      "Epoch 769/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7333 - val_loss: 0.5483 - val_accuracy: 0.7346\n",
      "Epoch 770/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5427 - accuracy: 0.7336 - val_loss: 0.5489 - val_accuracy: 0.7346\n",
      "Epoch 771/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7321 - val_loss: 0.5485 - val_accuracy: 0.7345\n",
      "Epoch 772/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7347 - val_loss: 0.5497 - val_accuracy: 0.7323\n",
      "Epoch 773/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7347 - val_loss: 0.5495 - val_accuracy: 0.7327\n",
      "Epoch 774/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7340 - val_loss: 0.5490 - val_accuracy: 0.7336\n",
      "Epoch 775/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7327 - val_loss: 0.5491 - val_accuracy: 0.7329\n",
      "Epoch 776/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7351 - val_loss: 0.5489 - val_accuracy: 0.7315\n",
      "Epoch 777/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7323 - val_loss: 0.5499 - val_accuracy: 0.7338\n",
      "Epoch 778/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7345 - val_loss: 0.5500 - val_accuracy: 0.7344\n",
      "Epoch 779/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7342 - val_loss: 0.5519 - val_accuracy: 0.7335\n",
      "Epoch 780/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7331 - val_loss: 0.5502 - val_accuracy: 0.7316\n",
      "Epoch 781/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7339 - val_loss: 0.5511 - val_accuracy: 0.7296\n",
      "Epoch 782/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7343 - val_loss: 0.5477 - val_accuracy: 0.7357\n",
      "Epoch 783/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7347 - val_loss: 0.5473 - val_accuracy: 0.7353\n",
      "Epoch 784/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5445 - accuracy: 0.7334 - val_loss: 0.5484 - val_accuracy: 0.7352\n",
      "Epoch 785/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7346 - val_loss: 0.5507 - val_accuracy: 0.7335\n",
      "Epoch 786/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7350 - val_loss: 0.5495 - val_accuracy: 0.7328\n",
      "Epoch 787/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7338 - val_loss: 0.5484 - val_accuracy: 0.7335\n",
      "Epoch 788/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7321 - val_loss: 0.5484 - val_accuracy: 0.7341\n",
      "Epoch 789/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7335 - val_loss: 0.5490 - val_accuracy: 0.7323\n",
      "Epoch 790/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7344 - val_loss: 0.5489 - val_accuracy: 0.7297\n",
      "Epoch 791/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5421 - accuracy: 0.7347 - val_loss: 0.5483 - val_accuracy: 0.7337\n",
      "Epoch 792/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5496 - accuracy: 0.7348 - val_loss: 0.5498 - val_accuracy: 0.7314\n",
      "Epoch 793/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7336 - val_loss: 0.5489 - val_accuracy: 0.7304\n",
      "Epoch 794/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7340 - val_loss: 0.5488 - val_accuracy: 0.7322\n",
      "Epoch 795/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7335 - val_loss: 0.5502 - val_accuracy: 0.7355\n",
      "Epoch 796/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7349 - val_loss: 0.5494 - val_accuracy: 0.7344\n",
      "Epoch 797/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5454 - accuracy: 0.7338 - val_loss: 0.5493 - val_accuracy: 0.7338\n",
      "Epoch 798/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7338 - val_loss: 0.5491 - val_accuracy: 0.7349\n",
      "Epoch 799/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7337 - val_loss: 0.5510 - val_accuracy: 0.7309\n",
      "Epoch 800/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7330 - val_loss: 0.5474 - val_accuracy: 0.7308\n",
      "Epoch 801/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7352 - val_loss: 0.5503 - val_accuracy: 0.7284\n",
      "Epoch 802/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5425 - accuracy: 0.7339 - val_loss: 0.5503 - val_accuracy: 0.7310\n",
      "Epoch 803/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7337 - val_loss: 0.5485 - val_accuracy: 0.7326\n",
      "Epoch 804/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5439 - accuracy: 0.7331 - val_loss: 0.5490 - val_accuracy: 0.7327\n",
      "Epoch 805/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5889 - accuracy: 0.7323 - val_loss: 0.5519 - val_accuracy: 0.7302\n",
      "Epoch 806/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5445 - accuracy: 0.7320 - val_loss: 0.5479 - val_accuracy: 0.7308\n",
      "Epoch 807/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5438 - accuracy: 0.7348 - val_loss: 0.5477 - val_accuracy: 0.7323\n",
      "Epoch 808/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7337 - val_loss: 0.5475 - val_accuracy: 0.7329\n",
      "Epoch 809/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7351 - val_loss: 0.5484 - val_accuracy: 0.7332\n",
      "Epoch 810/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5437 - accuracy: 0.7348 - val_loss: 0.5486 - val_accuracy: 0.7330\n",
      "Epoch 811/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5427 - accuracy: 0.7325 - val_loss: 0.5491 - val_accuracy: 0.7328\n",
      "Epoch 812/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5433 - accuracy: 0.7356 - val_loss: 0.5478 - val_accuracy: 0.7342\n",
      "Epoch 813/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5436 - accuracy: 0.7337 - val_loss: 0.5496 - val_accuracy: 0.7301\n",
      "Epoch 814/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7342 - val_loss: 0.5467 - val_accuracy: 0.7334\n",
      "Epoch 815/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7347 - val_loss: 0.5500 - val_accuracy: 0.7312\n",
      "Epoch 816/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7352 - val_loss: 0.5487 - val_accuracy: 0.7315\n",
      "Epoch 817/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7335 - val_loss: 0.5481 - val_accuracy: 0.7327\n",
      "Epoch 818/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7317 - val_loss: 0.5489 - val_accuracy: 0.7314\n",
      "Epoch 819/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7333 - val_loss: 0.5487 - val_accuracy: 0.7301\n",
      "Epoch 820/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7352 - val_loss: 0.5488 - val_accuracy: 0.7359\n",
      "Epoch 821/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5431 - accuracy: 0.7331 - val_loss: 0.5488 - val_accuracy: 0.7338\n",
      "Epoch 822/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7346 - val_loss: 0.5490 - val_accuracy: 0.7348\n",
      "Epoch 823/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5440 - accuracy: 0.7317 - val_loss: 0.5486 - val_accuracy: 0.7337\n",
      "Epoch 824/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7350 - val_loss: 0.5477 - val_accuracy: 0.7349\n",
      "Epoch 825/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5434 - accuracy: 0.7347 - val_loss: 0.5491 - val_accuracy: 0.7342\n",
      "Epoch 826/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5431 - accuracy: 0.7332 - val_loss: 0.5483 - val_accuracy: 0.7342\n",
      "Epoch 827/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7333 - val_loss: 0.5483 - val_accuracy: 0.7311\n",
      "Epoch 828/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7355 - val_loss: 0.5483 - val_accuracy: 0.7335\n",
      "Epoch 829/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7349 - val_loss: 0.5501 - val_accuracy: 0.7330\n",
      "Epoch 830/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7320 - val_loss: 0.5501 - val_accuracy: 0.7316\n",
      "Epoch 831/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7332 - val_loss: 0.5481 - val_accuracy: 0.7336\n",
      "Epoch 832/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7340 - val_loss: 0.5491 - val_accuracy: 0.7318\n",
      "Epoch 833/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7333 - val_loss: 0.5495 - val_accuracy: 0.7338\n",
      "Epoch 834/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7344 - val_loss: 0.5495 - val_accuracy: 0.7335\n",
      "Epoch 835/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5423 - accuracy: 0.7349 - val_loss: 0.5512 - val_accuracy: 0.7324\n",
      "Epoch 836/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5588 - accuracy: 0.7326 - val_loss: 0.5480 - val_accuracy: 0.7342\n",
      "Epoch 837/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7328 - val_loss: 0.5472 - val_accuracy: 0.7332\n",
      "Epoch 838/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7344 - val_loss: 0.5485 - val_accuracy: 0.7321\n",
      "Epoch 839/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7333 - val_loss: 0.5484 - val_accuracy: 0.7304\n",
      "Epoch 840/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5422 - accuracy: 0.7327 - val_loss: 0.5482 - val_accuracy: 0.7333\n",
      "Epoch 841/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7325 - val_loss: 0.5490 - val_accuracy: 0.7342\n",
      "Epoch 842/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7326 - val_loss: 0.5494 - val_accuracy: 0.7322\n",
      "Epoch 843/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7310 - val_loss: 0.5499 - val_accuracy: 0.7349\n",
      "Epoch 844/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7347 - val_loss: 0.5492 - val_accuracy: 0.7336\n",
      "Epoch 845/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7327 - val_loss: 0.5490 - val_accuracy: 0.7335\n",
      "Epoch 846/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7334 - val_loss: 0.5471 - val_accuracy: 0.7335\n",
      "Epoch 847/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7346 - val_loss: 0.5489 - val_accuracy: 0.7330\n",
      "Epoch 848/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5422 - accuracy: 0.7329 - val_loss: 0.5492 - val_accuracy: 0.7338\n",
      "Epoch 849/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7357 - val_loss: 0.5487 - val_accuracy: 0.7331\n",
      "Epoch 850/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7337 - val_loss: 0.5500 - val_accuracy: 0.7326\n",
      "Epoch 851/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7330 - val_loss: 0.5485 - val_accuracy: 0.7328\n",
      "Epoch 852/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7333 - val_loss: 0.5504 - val_accuracy: 0.7308\n",
      "Epoch 853/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7343 - val_loss: 0.5509 - val_accuracy: 0.7310\n",
      "Epoch 854/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7343 - val_loss: 0.5517 - val_accuracy: 0.7309\n",
      "Epoch 855/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5438 - accuracy: 0.7351 - val_loss: 0.5512 - val_accuracy: 0.7324\n",
      "Epoch 856/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7321 - val_loss: 0.5495 - val_accuracy: 0.7338\n",
      "Epoch 857/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7345 - val_loss: 0.5507 - val_accuracy: 0.7331\n",
      "Epoch 858/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7349 - val_loss: 0.5501 - val_accuracy: 0.7329\n",
      "Epoch 859/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7335 - val_loss: 0.5482 - val_accuracy: 0.7332\n",
      "Epoch 860/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.7331 - val_loss: 0.5507 - val_accuracy: 0.7329\n",
      "Epoch 861/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5461 - accuracy: 0.7341 - val_loss: 0.5506 - val_accuracy: 0.7305\n",
      "Epoch 862/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7340 - val_loss: 0.5505 - val_accuracy: 0.7314\n",
      "Epoch 863/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7344 - val_loss: 0.5507 - val_accuracy: 0.7335\n",
      "Epoch 864/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7342 - val_loss: 0.5514 - val_accuracy: 0.7308\n",
      "Epoch 865/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7335 - val_loss: 0.5514 - val_accuracy: 0.7302\n",
      "Epoch 866/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5424 - accuracy: 0.7346 - val_loss: 0.5503 - val_accuracy: 0.7310\n",
      "Epoch 867/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5444 - accuracy: 0.7330 - val_loss: 0.5495 - val_accuracy: 0.7309\n",
      "Epoch 868/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5448 - accuracy: 0.7342 - val_loss: 0.5483 - val_accuracy: 0.7311\n",
      "Epoch 869/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7334 - val_loss: 0.5483 - val_accuracy: 0.7329\n",
      "Epoch 870/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7347 - val_loss: 0.5482 - val_accuracy: 0.7319\n",
      "Epoch 871/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5448 - accuracy: 0.7329 - val_loss: 0.5494 - val_accuracy: 0.7308\n",
      "Epoch 872/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5439 - accuracy: 0.7345 - val_loss: 0.5494 - val_accuracy: 0.7345\n",
      "Epoch 873/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7347 - val_loss: 0.5498 - val_accuracy: 0.7297\n",
      "Epoch 874/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5440 - accuracy: 0.7328 - val_loss: 0.5478 - val_accuracy: 0.7330\n",
      "Epoch 875/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5421 - accuracy: 0.7341 - val_loss: 0.5489 - val_accuracy: 0.7305\n",
      "Epoch 876/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5411 - accuracy: 0.7329 - val_loss: 0.5498 - val_accuracy: 0.7331\n",
      "Epoch 877/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5456 - accuracy: 0.7329 - val_loss: 0.5491 - val_accuracy: 0.7339\n",
      "Epoch 878/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5434 - accuracy: 0.7338 - val_loss: 0.5502 - val_accuracy: 0.7329\n",
      "Epoch 879/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7347 - val_loss: 0.5500 - val_accuracy: 0.7304\n",
      "Epoch 880/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5536 - accuracy: 0.7332 - val_loss: 0.5507 - val_accuracy: 0.7305\n",
      "Epoch 881/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5418 - accuracy: 0.7352 - val_loss: 0.5489 - val_accuracy: 0.7317\n",
      "Epoch 882/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5421 - accuracy: 0.7339 - val_loss: 0.5488 - val_accuracy: 0.7307\n",
      "Epoch 883/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7325 - val_loss: 0.5524 - val_accuracy: 0.7303\n",
      "Epoch 884/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7347 - val_loss: 0.5502 - val_accuracy: 0.7316\n",
      "Epoch 885/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7343 - val_loss: 0.5515 - val_accuracy: 0.7328\n",
      "Epoch 886/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5553 - accuracy: 0.7342 - val_loss: 0.5497 - val_accuracy: 0.7326\n",
      "Epoch 887/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5447 - accuracy: 0.7339 - val_loss: 0.5527 - val_accuracy: 0.7300\n",
      "Epoch 888/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7325 - val_loss: 0.5496 - val_accuracy: 0.7305\n",
      "Epoch 889/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5415 - accuracy: 0.7351 - val_loss: 0.5509 - val_accuracy: 0.7302\n",
      "Epoch 890/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5503 - accuracy: 0.7329 - val_loss: 0.5533 - val_accuracy: 0.7306\n",
      "Epoch 891/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5421 - accuracy: 0.7340 - val_loss: 0.5497 - val_accuracy: 0.7327\n",
      "Epoch 892/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.7350 - val_loss: 0.5498 - val_accuracy: 0.7340\n",
      "Epoch 893/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5426 - accuracy: 0.7332 - val_loss: 0.5508 - val_accuracy: 0.7330\n",
      "Epoch 894/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7335 - val_loss: 0.5526 - val_accuracy: 0.7317\n",
      "Epoch 895/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7346 - val_loss: 0.5492 - val_accuracy: 0.7340\n",
      "Epoch 896/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7352 - val_loss: 0.5501 - val_accuracy: 0.7313\n",
      "Epoch 897/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7337 - val_loss: 0.5484 - val_accuracy: 0.7308\n",
      "Epoch 898/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7352 - val_loss: 0.5466 - val_accuracy: 0.7333\n",
      "Epoch 899/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7332 - val_loss: 0.5492 - val_accuracy: 0.7330\n",
      "Epoch 900/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5437 - accuracy: 0.7364 - val_loss: 0.5487 - val_accuracy: 0.7331\n",
      "Epoch 901/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7337 - val_loss: 0.5485 - val_accuracy: 0.7341\n",
      "Epoch 902/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7333 - val_loss: 0.5506 - val_accuracy: 0.7308\n",
      "Epoch 903/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5515 - accuracy: 0.7346 - val_loss: 0.5499 - val_accuracy: 0.7341\n",
      "Epoch 904/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5427 - accuracy: 0.7333 - val_loss: 0.5523 - val_accuracy: 0.7287\n",
      "Epoch 905/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7328 - val_loss: 0.5522 - val_accuracy: 0.7310\n",
      "Epoch 906/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.7320 - val_loss: 0.5488 - val_accuracy: 0.7341\n",
      "Epoch 907/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7323 - val_loss: 0.5476 - val_accuracy: 0.7327\n",
      "Epoch 908/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7337 - val_loss: 0.5500 - val_accuracy: 0.7307\n",
      "Epoch 909/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5510 - accuracy: 0.7327 - val_loss: 0.5505 - val_accuracy: 0.7321\n",
      "Epoch 910/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7331 - val_loss: 0.5502 - val_accuracy: 0.7316\n",
      "Epoch 911/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7342 - val_loss: 0.5523 - val_accuracy: 0.7322\n",
      "Epoch 912/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7312 - val_loss: 0.5506 - val_accuracy: 0.7326\n",
      "Epoch 913/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7340 - val_loss: 0.5507 - val_accuracy: 0.7332\n",
      "Epoch 914/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7347 - val_loss: 0.5514 - val_accuracy: 0.7302\n",
      "Epoch 915/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7334 - val_loss: 0.5522 - val_accuracy: 0.7322\n",
      "Epoch 916/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5422 - accuracy: 0.7359 - val_loss: 0.5530 - val_accuracy: 0.7321\n",
      "Epoch 917/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7327 - val_loss: 0.5506 - val_accuracy: 0.7298\n",
      "Epoch 918/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7356 - val_loss: 0.5519 - val_accuracy: 0.7308\n",
      "Epoch 919/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5434 - accuracy: 0.7344 - val_loss: 0.5514 - val_accuracy: 0.7297\n",
      "Epoch 920/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7345 - val_loss: 0.5509 - val_accuracy: 0.7311\n",
      "Epoch 921/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7332 - val_loss: 0.5529 - val_accuracy: 0.7332\n",
      "Epoch 922/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7333 - val_loss: 0.5507 - val_accuracy: 0.7311\n",
      "Epoch 923/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7345 - val_loss: 0.5571 - val_accuracy: 0.7321\n",
      "Epoch 924/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7341 - val_loss: 0.5509 - val_accuracy: 0.7308\n",
      "Epoch 925/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7343 - val_loss: 0.5510 - val_accuracy: 0.7315\n",
      "Epoch 926/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5412 - accuracy: 0.7338 - val_loss: 0.5533 - val_accuracy: 0.7300\n",
      "Epoch 927/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5415 - accuracy: 0.7339 - val_loss: 0.5528 - val_accuracy: 0.7305\n",
      "Epoch 928/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7351 - val_loss: 0.5531 - val_accuracy: 0.7324\n",
      "Epoch 929/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7349 - val_loss: 0.5513 - val_accuracy: 0.7298\n",
      "Epoch 930/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7342 - val_loss: 0.5527 - val_accuracy: 0.7313\n",
      "Epoch 931/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5434 - accuracy: 0.7332 - val_loss: 0.5506 - val_accuracy: 0.7306\n",
      "Epoch 932/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.7352 - val_loss: 0.5509 - val_accuracy: 0.7314\n",
      "Epoch 933/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7347 - val_loss: 0.5484 - val_accuracy: 0.7330\n",
      "Epoch 934/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.7323 - val_loss: 0.5496 - val_accuracy: 0.7336\n",
      "Epoch 935/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5416 - accuracy: 0.7345 - val_loss: 0.5501 - val_accuracy: 0.7316\n",
      "Epoch 936/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7336 - val_loss: 0.5506 - val_accuracy: 0.7331\n",
      "Epoch 937/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7346 - val_loss: 0.5501 - val_accuracy: 0.7308\n",
      "Epoch 938/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7354 - val_loss: 0.5511 - val_accuracy: 0.7324\n",
      "Epoch 939/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5433 - accuracy: 0.7323 - val_loss: 0.5532 - val_accuracy: 0.7342\n",
      "Epoch 940/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7346 - val_loss: 0.5528 - val_accuracy: 0.7315\n",
      "Epoch 941/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5506 - accuracy: 0.7345 - val_loss: 0.5543 - val_accuracy: 0.7311\n",
      "Epoch 942/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7327 - val_loss: 0.5541 - val_accuracy: 0.7329\n",
      "Epoch 943/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5598 - accuracy: 0.7329 - val_loss: 0.5517 - val_accuracy: 0.7318\n",
      "Epoch 944/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7329 - val_loss: 0.5511 - val_accuracy: 0.7322\n",
      "Epoch 945/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5433 - accuracy: 0.7320 - val_loss: 0.5515 - val_accuracy: 0.7307\n",
      "Epoch 946/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7329 - val_loss: 0.5531 - val_accuracy: 0.7298\n",
      "Epoch 947/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7346 - val_loss: 0.5508 - val_accuracy: 0.7300\n",
      "Epoch 948/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7346 - val_loss: 0.5508 - val_accuracy: 0.7331\n",
      "Epoch 949/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7327 - val_loss: 0.5507 - val_accuracy: 0.7310\n",
      "Epoch 950/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7343 - val_loss: 0.5502 - val_accuracy: 0.7282\n",
      "Epoch 951/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7344 - val_loss: 0.5513 - val_accuracy: 0.7310\n",
      "Epoch 952/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5429 - accuracy: 0.7340 - val_loss: 0.5515 - val_accuracy: 0.7301\n",
      "Epoch 953/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7337 - val_loss: 0.5540 - val_accuracy: 0.7301\n",
      "Epoch 954/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7308 - val_loss: 0.5508 - val_accuracy: 0.7293\n",
      "Epoch 955/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7339 - val_loss: 0.5504 - val_accuracy: 0.7319\n",
      "Epoch 956/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7351 - val_loss: 0.5512 - val_accuracy: 0.7291\n",
      "Epoch 957/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7339 - val_loss: 0.5508 - val_accuracy: 0.7312\n",
      "Epoch 958/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7351 - val_loss: 0.5517 - val_accuracy: 0.7294\n",
      "Epoch 959/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.7337 - val_loss: 0.5499 - val_accuracy: 0.7306\n",
      "Epoch 960/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.7346 - val_loss: 0.5518 - val_accuracy: 0.7284\n",
      "Epoch 961/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.7335 - val_loss: 0.5522 - val_accuracy: 0.7318\n",
      "Epoch 962/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7349 - val_loss: 0.5508 - val_accuracy: 0.7312\n",
      "Epoch 963/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7331 - val_loss: 0.5524 - val_accuracy: 0.7335\n",
      "Epoch 964/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.7350 - val_loss: 0.5521 - val_accuracy: 0.7302\n",
      "Epoch 965/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5462 - accuracy: 0.7347 - val_loss: 0.5502 - val_accuracy: 0.7303\n",
      "Epoch 966/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7344 - val_loss: 0.5530 - val_accuracy: 0.7314\n",
      "Epoch 967/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5427 - accuracy: 0.7326 - val_loss: 0.5519 - val_accuracy: 0.7305\n",
      "Epoch 968/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5501 - accuracy: 0.7338 - val_loss: 0.5529 - val_accuracy: 0.7288\n",
      "Epoch 969/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7337 - val_loss: 0.5535 - val_accuracy: 0.7301\n",
      "Epoch 970/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7340 - val_loss: 0.5504 - val_accuracy: 0.7298\n",
      "Epoch 971/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5450 - accuracy: 0.7346 - val_loss: 0.5513 - val_accuracy: 0.7323\n",
      "Epoch 972/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5431 - accuracy: 0.7350 - val_loss: 0.5494 - val_accuracy: 0.7310\n",
      "Epoch 973/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7340 - val_loss: 0.5507 - val_accuracy: 0.7321\n",
      "Epoch 974/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7343 - val_loss: 0.5549 - val_accuracy: 0.7294\n",
      "Epoch 975/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7343 - val_loss: 0.5523 - val_accuracy: 0.7313\n",
      "Epoch 976/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7336 - val_loss: 0.5534 - val_accuracy: 0.7293\n",
      "Epoch 977/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7331 - val_loss: 0.5517 - val_accuracy: 0.7332\n",
      "Epoch 978/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5429 - accuracy: 0.7329 - val_loss: 0.5501 - val_accuracy: 0.7318\n",
      "Epoch 979/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7338 - val_loss: 0.5505 - val_accuracy: 0.7321\n",
      "Epoch 980/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7347 - val_loss: 0.5517 - val_accuracy: 0.7312\n",
      "Epoch 981/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5454 - accuracy: 0.7320 - val_loss: 0.5503 - val_accuracy: 0.7322\n",
      "Epoch 982/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5444 - accuracy: 0.7338 - val_loss: 0.5508 - val_accuracy: 0.7297\n",
      "Epoch 983/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5415 - accuracy: 0.7335 - val_loss: 0.5517 - val_accuracy: 0.7305\n",
      "Epoch 984/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7337 - val_loss: 0.5514 - val_accuracy: 0.7293\n",
      "Epoch 985/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7340 - val_loss: 0.5508 - val_accuracy: 0.7307\n",
      "Epoch 986/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5437 - accuracy: 0.7328 - val_loss: 0.5516 - val_accuracy: 0.7298\n",
      "Epoch 987/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7328 - val_loss: 0.5507 - val_accuracy: 0.7309\n",
      "Epoch 988/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7324 - val_loss: 0.5533 - val_accuracy: 0.7298\n",
      "Epoch 989/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.7323 - val_loss: 0.5504 - val_accuracy: 0.7318\n",
      "Epoch 990/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7333 - val_loss: 0.5511 - val_accuracy: 0.7328\n",
      "Epoch 991/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7349 - val_loss: 0.5519 - val_accuracy: 0.7335\n",
      "Epoch 992/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7335 - val_loss: 0.5539 - val_accuracy: 0.7347\n",
      "Epoch 993/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7339 - val_loss: 0.5508 - val_accuracy: 0.7331\n",
      "Epoch 994/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7342 - val_loss: 0.5501 - val_accuracy: 0.7315\n",
      "Epoch 995/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7335 - val_loss: 0.5505 - val_accuracy: 0.7328\n",
      "Epoch 996/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5418 - accuracy: 0.7352 - val_loss: 0.5536 - val_accuracy: 0.7294\n",
      "Epoch 997/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5445 - accuracy: 0.7332 - val_loss: 0.5528 - val_accuracy: 0.7298\n",
      "Epoch 998/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5412 - accuracy: 0.7324 - val_loss: 0.5503 - val_accuracy: 0.7332\n",
      "Epoch 999/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7329 - val_loss: 0.5510 - val_accuracy: 0.7304\n",
      "Epoch 1000/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7331 - val_loss: 0.5521 - val_accuracy: 0.7316\n",
      "Epoch 1001/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7344 - val_loss: 0.5514 - val_accuracy: 0.7347\n",
      "Epoch 1002/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7333 - val_loss: 0.5510 - val_accuracy: 0.7317\n",
      "Epoch 1003/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7338 - val_loss: 0.5529 - val_accuracy: 0.7339\n",
      "Epoch 1004/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7342 - val_loss: 0.5498 - val_accuracy: 0.7305\n",
      "Epoch 1005/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5422 - accuracy: 0.7349 - val_loss: 0.5501 - val_accuracy: 0.7322\n",
      "Epoch 1006/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7321 - val_loss: 0.5498 - val_accuracy: 0.7296\n",
      "Epoch 1007/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7334 - val_loss: 0.5512 - val_accuracy: 0.7296\n",
      "Epoch 1008/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5434 - accuracy: 0.7341 - val_loss: 0.5519 - val_accuracy: 0.7289\n",
      "Epoch 1009/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7333 - val_loss: 0.5527 - val_accuracy: 0.7287\n",
      "Epoch 1010/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5434 - accuracy: 0.7332 - val_loss: 0.5514 - val_accuracy: 0.7319\n",
      "Epoch 1011/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7342 - val_loss: 0.5528 - val_accuracy: 0.7291\n",
      "Epoch 1012/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7343 - val_loss: 0.5502 - val_accuracy: 0.7340\n",
      "Epoch 1013/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5411 - accuracy: 0.7344 - val_loss: 0.5528 - val_accuracy: 0.7322\n",
      "Epoch 1014/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7343 - val_loss: 0.5528 - val_accuracy: 0.7303\n",
      "Epoch 1015/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7338 - val_loss: 0.5525 - val_accuracy: 0.7332\n",
      "Epoch 1016/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.7340 - val_loss: 0.5502 - val_accuracy: 0.7313\n",
      "Epoch 1017/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7337 - val_loss: 0.5507 - val_accuracy: 0.7338\n",
      "Epoch 1018/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7341 - val_loss: 0.5536 - val_accuracy: 0.7293\n",
      "Epoch 1019/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7353 - val_loss: 0.5506 - val_accuracy: 0.7321\n",
      "Epoch 1020/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7336 - val_loss: 0.5512 - val_accuracy: 0.7318\n",
      "Epoch 1021/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7340 - val_loss: 0.5505 - val_accuracy: 0.7320\n",
      "Epoch 1022/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7342 - val_loss: 0.5514 - val_accuracy: 0.7294\n",
      "Epoch 1023/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7329 - val_loss: 0.5500 - val_accuracy: 0.7294\n",
      "Epoch 1024/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5433 - accuracy: 0.7327 - val_loss: 0.5516 - val_accuracy: 0.7298\n",
      "Epoch 1025/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5427 - accuracy: 0.7340 - val_loss: 0.5517 - val_accuracy: 0.7301\n",
      "Epoch 1026/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7346 - val_loss: 0.5508 - val_accuracy: 0.7317\n",
      "Epoch 1027/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7335 - val_loss: 0.5514 - val_accuracy: 0.7345\n",
      "Epoch 1028/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7339 - val_loss: 0.5516 - val_accuracy: 0.7320\n",
      "Epoch 1029/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7350 - val_loss: 0.5521 - val_accuracy: 0.7323\n",
      "Epoch 1030/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7327 - val_loss: 0.5514 - val_accuracy: 0.7296\n",
      "Epoch 1031/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7349 - val_loss: 0.5522 - val_accuracy: 0.7318\n",
      "Epoch 1032/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5515 - accuracy: 0.7344 - val_loss: 0.5500 - val_accuracy: 0.7318\n",
      "Epoch 1033/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7351 - val_loss: 0.5502 - val_accuracy: 0.7329\n",
      "Epoch 1034/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7341 - val_loss: 0.5503 - val_accuracy: 0.7313\n",
      "Epoch 1035/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5411 - accuracy: 0.7355 - val_loss: 0.5517 - val_accuracy: 0.7305\n",
      "Epoch 1036/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7326 - val_loss: 0.5512 - val_accuracy: 0.7323\n",
      "Epoch 1037/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7339 - val_loss: 0.5516 - val_accuracy: 0.7318\n",
      "Epoch 1038/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5423 - accuracy: 0.7337 - val_loss: 0.5513 - val_accuracy: 0.7337\n",
      "Epoch 1039/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7341 - val_loss: 0.5522 - val_accuracy: 0.7317\n",
      "Epoch 1040/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5427 - accuracy: 0.7353 - val_loss: 0.5538 - val_accuracy: 0.7303\n",
      "Epoch 1041/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7329 - val_loss: 0.5533 - val_accuracy: 0.7313\n",
      "Epoch 1042/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7334 - val_loss: 0.5608 - val_accuracy: 0.7317\n",
      "Epoch 1043/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5437 - accuracy: 0.7344 - val_loss: 0.5530 - val_accuracy: 0.7318\n",
      "Epoch 1044/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7336 - val_loss: 0.5512 - val_accuracy: 0.7299\n",
      "Epoch 1045/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7334 - val_loss: 0.5512 - val_accuracy: 0.7297\n",
      "Epoch 1046/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7322 - val_loss: 0.5523 - val_accuracy: 0.7274\n",
      "Epoch 1047/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7336 - val_loss: 0.5523 - val_accuracy: 0.7314\n",
      "Epoch 1048/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7330 - val_loss: 0.5534 - val_accuracy: 0.7331\n",
      "Epoch 1049/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5447 - accuracy: 0.7346 - val_loss: 0.5510 - val_accuracy: 0.7320\n",
      "Epoch 1050/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7351 - val_loss: 0.5519 - val_accuracy: 0.7328\n",
      "Epoch 1051/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7352 - val_loss: 0.5511 - val_accuracy: 0.7322\n",
      "Epoch 1052/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5412 - accuracy: 0.7330 - val_loss: 0.5521 - val_accuracy: 0.7309\n",
      "Epoch 1053/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5651 - accuracy: 0.7333 - val_loss: 0.5500 - val_accuracy: 0.7314\n",
      "Epoch 1054/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7348 - val_loss: 0.5512 - val_accuracy: 0.7311\n",
      "Epoch 1055/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7356 - val_loss: 0.5508 - val_accuracy: 0.7319\n",
      "Epoch 1056/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7330 - val_loss: 0.5529 - val_accuracy: 0.7291\n",
      "Epoch 1057/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5410 - accuracy: 0.7349 - val_loss: 0.5496 - val_accuracy: 0.7312\n",
      "Epoch 1058/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7348 - val_loss: 0.5496 - val_accuracy: 0.7302\n",
      "Epoch 1059/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5418 - accuracy: 0.7355 - val_loss: 0.5515 - val_accuracy: 0.7317\n",
      "Epoch 1060/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5442 - accuracy: 0.7334 - val_loss: 0.5529 - val_accuracy: 0.7298\n",
      "Epoch 1061/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7339 - val_loss: 0.5517 - val_accuracy: 0.7298\n",
      "Epoch 1062/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5450 - accuracy: 0.7326 - val_loss: 0.5535 - val_accuracy: 0.7297\n",
      "Epoch 1063/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7326 - val_loss: 0.5502 - val_accuracy: 0.7286\n",
      "Epoch 1064/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7327 - val_loss: 0.5524 - val_accuracy: 0.7315\n",
      "Epoch 1065/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7318 - val_loss: 0.5511 - val_accuracy: 0.7327\n",
      "Epoch 1066/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7348 - val_loss: 0.5510 - val_accuracy: 0.7303\n",
      "Epoch 1067/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7346 - val_loss: 0.5513 - val_accuracy: 0.7323\n",
      "Epoch 1068/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7353 - val_loss: 0.5496 - val_accuracy: 0.7309\n",
      "Epoch 1069/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5422 - accuracy: 0.7327 - val_loss: 0.5534 - val_accuracy: 0.7313\n",
      "Epoch 1070/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7331 - val_loss: 0.5516 - val_accuracy: 0.7314\n",
      "Epoch 1071/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7339 - val_loss: 0.5499 - val_accuracy: 0.7314\n",
      "Epoch 1072/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7347 - val_loss: 0.5515 - val_accuracy: 0.7314\n",
      "Epoch 1073/1500\n",
      "1225/1225 [==============================] - 6066s 5s/step - loss: 0.5439 - accuracy: 0.7340 - val_loss: 0.5519 - val_accuracy: 0.7307\n",
      "Epoch 1074/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5446 - accuracy: 0.7357 - val_loss: 0.5513 - val_accuracy: 0.7312\n",
      "Epoch 1075/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7340 - val_loss: 0.5523 - val_accuracy: 0.7298\n",
      "Epoch 1076/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7344 - val_loss: 0.5535 - val_accuracy: 0.7302\n",
      "Epoch 1077/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7325 - val_loss: 0.5540 - val_accuracy: 0.7288\n",
      "Epoch 1078/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7343 - val_loss: 0.5527 - val_accuracy: 0.7321\n",
      "Epoch 1079/1500\n",
      "1225/1225 [==============================] - 4s 3ms/step - loss: 0.5428 - accuracy: 0.7351 - val_loss: 0.5551 - val_accuracy: 0.7334\n",
      "Epoch 1080/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5433 - accuracy: 0.7319 - val_loss: 0.5538 - val_accuracy: 0.7316\n",
      "Epoch 1081/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7319 - val_loss: 0.5522 - val_accuracy: 0.7307\n",
      "Epoch 1082/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5416 - accuracy: 0.7327 - val_loss: 0.5510 - val_accuracy: 0.7316\n",
      "Epoch 1083/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5457 - accuracy: 0.7341 - val_loss: 0.5530 - val_accuracy: 0.7308\n",
      "Epoch 1084/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.7359 - val_loss: 0.5521 - val_accuracy: 0.7305\n",
      "Epoch 1085/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5453 - accuracy: 0.7366 - val_loss: 0.5525 - val_accuracy: 0.7312\n",
      "Epoch 1086/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7347 - val_loss: 0.5525 - val_accuracy: 0.7315\n",
      "Epoch 1087/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7324 - val_loss: 0.5527 - val_accuracy: 0.7312\n",
      "Epoch 1088/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5430 - accuracy: 0.7352 - val_loss: 0.5517 - val_accuracy: 0.7320\n",
      "Epoch 1089/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7329 - val_loss: 0.5529 - val_accuracy: 0.7307\n",
      "Epoch 1090/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5417 - accuracy: 0.7335 - val_loss: 0.5541 - val_accuracy: 0.7291\n",
      "Epoch 1091/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7332 - val_loss: 0.5531 - val_accuracy: 0.7308\n",
      "Epoch 1092/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7348 - val_loss: 0.5512 - val_accuracy: 0.7315\n",
      "Epoch 1093/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5418 - accuracy: 0.7339 - val_loss: 0.5513 - val_accuracy: 0.7316\n",
      "Epoch 1094/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7335 - val_loss: 0.5531 - val_accuracy: 0.7301\n",
      "Epoch 1095/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7349 - val_loss: 0.5527 - val_accuracy: 0.7321\n",
      "Epoch 1096/1500\n",
      "1225/1225 [==============================] - 3s 3ms/step - loss: 0.5431 - accuracy: 0.7325 - val_loss: 0.5543 - val_accuracy: 0.7312\n",
      "Epoch 1097/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5420 - accuracy: 0.7323 - val_loss: 0.5507 - val_accuracy: 0.7332\n",
      "Epoch 1098/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5431 - accuracy: 0.7345 - val_loss: 0.5520 - val_accuracy: 0.7322\n",
      "Epoch 1099/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5429 - accuracy: 0.7330 - val_loss: 0.5515 - val_accuracy: 0.7308\n",
      "Epoch 1100/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5424 - accuracy: 0.7334 - val_loss: 0.5549 - val_accuracy: 0.7285\n",
      "Epoch 1101/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5430 - accuracy: 0.7368 - val_loss: 0.5528 - val_accuracy: 0.7298\n",
      "Epoch 1102/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 3s 3ms/step - loss: 0.5453 - accuracy: 0.7346 - val_loss: 0.5520 - val_accuracy: 0.7315\n",
      "Epoch 1103/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7323 - val_loss: 0.5522 - val_accuracy: 0.7299\n",
      "Epoch 1104/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7333 - val_loss: 0.5532 - val_accuracy: 0.7298\n",
      "Epoch 1105/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7355 - val_loss: 0.5529 - val_accuracy: 0.7302\n",
      "Epoch 1106/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5482 - accuracy: 0.7324 - val_loss: 0.5528 - val_accuracy: 0.7297\n",
      "Epoch 1107/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5421 - accuracy: 0.7348 - val_loss: 0.5533 - val_accuracy: 0.7300\n",
      "Epoch 1108/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7344 - val_loss: 0.5544 - val_accuracy: 0.7306\n",
      "Epoch 1109/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5461 - accuracy: 0.7327 - val_loss: 0.5519 - val_accuracy: 0.7314\n",
      "Epoch 1110/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7340 - val_loss: 0.5504 - val_accuracy: 0.7312\n",
      "Epoch 1111/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5444 - accuracy: 0.7332 - val_loss: 0.5546 - val_accuracy: 0.7320\n",
      "Epoch 1112/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5423 - accuracy: 0.7334 - val_loss: 0.5544 - val_accuracy: 0.7314\n",
      "Epoch 1113/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5426 - accuracy: 0.7330 - val_loss: 0.5517 - val_accuracy: 0.7334\n",
      "Epoch 1114/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5434 - accuracy: 0.7333 - val_loss: 0.5512 - val_accuracy: 0.7341\n",
      "Epoch 1115/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5420 - accuracy: 0.7354 - val_loss: 0.5533 - val_accuracy: 0.7316\n",
      "Epoch 1116/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7335 - val_loss: 0.5530 - val_accuracy: 0.7321\n",
      "Epoch 1117/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7358 - val_loss: 0.5519 - val_accuracy: 0.7319\n",
      "Epoch 1118/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5438 - accuracy: 0.7332 - val_loss: 0.5505 - val_accuracy: 0.7324\n",
      "Epoch 1119/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7372 - val_loss: 0.5526 - val_accuracy: 0.7330\n",
      "Epoch 1120/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7334 - val_loss: 0.5521 - val_accuracy: 0.7302\n",
      "Epoch 1121/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7343 - val_loss: 0.5533 - val_accuracy: 0.7332\n",
      "Epoch 1122/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7348 - val_loss: 0.5534 - val_accuracy: 0.7336\n",
      "Epoch 1123/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5421 - accuracy: 0.7350 - val_loss: 0.5523 - val_accuracy: 0.7329\n",
      "Epoch 1124/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7359 - val_loss: 0.5518 - val_accuracy: 0.7302\n",
      "Epoch 1125/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5442 - accuracy: 0.7332 - val_loss: 0.5557 - val_accuracy: 0.7292\n",
      "Epoch 1126/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5479 - accuracy: 0.7347 - val_loss: 0.5517 - val_accuracy: 0.7298\n",
      "Epoch 1127/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5413 - accuracy: 0.7342 - val_loss: 0.5529 - val_accuracy: 0.7294\n",
      "Epoch 1128/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.7346 - val_loss: 0.5543 - val_accuracy: 0.7304\n",
      "Epoch 1129/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7331 - val_loss: 0.5528 - val_accuracy: 0.7298\n",
      "Epoch 1130/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7367 - val_loss: 0.5524 - val_accuracy: 0.7327\n",
      "Epoch 1131/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7352 - val_loss: 0.5513 - val_accuracy: 0.7323\n",
      "Epoch 1132/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5441 - accuracy: 0.7344 - val_loss: 0.5531 - val_accuracy: 0.7295\n",
      "Epoch 1133/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5429 - accuracy: 0.7352 - val_loss: 0.5529 - val_accuracy: 0.7329\n",
      "Epoch 1134/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5430 - accuracy: 0.7342 - val_loss: 0.5536 - val_accuracy: 0.7316\n",
      "Epoch 1135/1500\n",
      "1225/1225 [==============================] - 3s 3ms/step - loss: 0.5433 - accuracy: 0.7335 - val_loss: 0.5542 - val_accuracy: 0.7309\n",
      "Epoch 1136/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5468 - accuracy: 0.7357 - val_loss: 0.5535 - val_accuracy: 0.7328\n",
      "Epoch 1137/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5425 - accuracy: 0.7356 - val_loss: 0.5529 - val_accuracy: 0.7338\n",
      "Epoch 1138/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5420 - accuracy: 0.7335 - val_loss: 0.5535 - val_accuracy: 0.7327\n",
      "Epoch 1139/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7345 - val_loss: 0.5534 - val_accuracy: 0.7347\n",
      "Epoch 1140/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5416 - accuracy: 0.7349 - val_loss: 0.5518 - val_accuracy: 0.7349\n",
      "Epoch 1141/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5424 - accuracy: 0.7339 - val_loss: 0.5522 - val_accuracy: 0.7341\n",
      "Epoch 1142/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5423 - accuracy: 0.7335 - val_loss: 0.5529 - val_accuracy: 0.7305\n",
      "Epoch 1143/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5408 - accuracy: 0.7356 - val_loss: 0.5507 - val_accuracy: 0.7318\n",
      "Epoch 1144/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5441 - accuracy: 0.7374 - val_loss: 0.5526 - val_accuracy: 0.7305\n",
      "Epoch 1145/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5436 - accuracy: 0.7332 - val_loss: 0.5531 - val_accuracy: 0.7300\n",
      "Epoch 1146/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5412 - accuracy: 0.7352 - val_loss: 0.5538 - val_accuracy: 0.7308\n",
      "Epoch 1147/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5561 - accuracy: 0.7337 - val_loss: 0.5535 - val_accuracy: 0.7280\n",
      "Epoch 1148/1500\n",
      "1225/1225 [==============================] - 3s 3ms/step - loss: 0.5458 - accuracy: 0.7347 - val_loss: 0.5545 - val_accuracy: 0.7301\n",
      "Epoch 1149/1500\n",
      "1225/1225 [==============================] - 3s 3ms/step - loss: 0.5436 - accuracy: 0.7323 - val_loss: 0.5521 - val_accuracy: 0.7311\n",
      "Epoch 1150/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5487 - accuracy: 0.7335 - val_loss: 0.5510 - val_accuracy: 0.7319\n",
      "Epoch 1151/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5433 - accuracy: 0.7359 - val_loss: 0.5521 - val_accuracy: 0.7305\n",
      "Epoch 1152/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5552 - accuracy: 0.7327 - val_loss: 0.5541 - val_accuracy: 0.7289\n",
      "Epoch 1153/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5427 - accuracy: 0.7323 - val_loss: 0.5530 - val_accuracy: 0.7316\n",
      "Epoch 1154/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5424 - accuracy: 0.7346 - val_loss: 0.5494 - val_accuracy: 0.7316\n",
      "Epoch 1155/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5430 - accuracy: 0.7335 - val_loss: 0.5508 - val_accuracy: 0.7328\n",
      "Epoch 1156/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5412 - accuracy: 0.7348 - val_loss: 0.5525 - val_accuracy: 0.7315\n",
      "Epoch 1157/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5424 - accuracy: 0.7353 - val_loss: 0.5534 - val_accuracy: 0.7301\n",
      "Epoch 1158/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7341 - val_loss: 0.5522 - val_accuracy: 0.7313\n",
      "Epoch 1159/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7337 - val_loss: 0.5522 - val_accuracy: 0.7314\n",
      "Epoch 1160/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7336 - val_loss: 0.5509 - val_accuracy: 0.7300\n",
      "Epoch 1161/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5598 - accuracy: 0.7356 - val_loss: 0.5534 - val_accuracy: 0.7303\n",
      "Epoch 1162/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5517 - accuracy: 0.7339 - val_loss: 0.5554 - val_accuracy: 0.7292\n",
      "Epoch 1163/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7344 - val_loss: 0.5523 - val_accuracy: 0.7307\n",
      "Epoch 1164/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5425 - accuracy: 0.7339 - val_loss: 0.5511 - val_accuracy: 0.7308\n",
      "Epoch 1165/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5464 - accuracy: 0.7354 - val_loss: 0.5492 - val_accuracy: 0.7328\n",
      "Epoch 1166/1500\n",
      "1225/1225 [==============================] - 3s 3ms/step - loss: 0.5420 - accuracy: 0.7347 - val_loss: 0.5513 - val_accuracy: 0.7314\n",
      "Epoch 1167/1500\n",
      "1225/1225 [==============================] - 3s 3ms/step - loss: 0.5419 - accuracy: 0.7347 - val_loss: 0.5549 - val_accuracy: 0.7321\n",
      "Epoch 1168/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5495 - accuracy: 0.7322 - val_loss: 0.5535 - val_accuracy: 0.7306\n",
      "Epoch 1169/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5433 - accuracy: 0.7339 - val_loss: 0.5517 - val_accuracy: 0.7295\n",
      "Epoch 1170/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5420 - accuracy: 0.7345 - val_loss: 0.5547 - val_accuracy: 0.7289\n",
      "Epoch 1171/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5436 - accuracy: 0.7340 - val_loss: 0.5535 - val_accuracy: 0.7310\n",
      "Epoch 1172/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5430 - accuracy: 0.7339 - val_loss: 0.5536 - val_accuracy: 0.7297\n",
      "Epoch 1173/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7324 - val_loss: 0.5535 - val_accuracy: 0.7280\n",
      "Epoch 1174/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7344 - val_loss: 0.5530 - val_accuracy: 0.7300\n",
      "Epoch 1175/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7336 - val_loss: 0.5512 - val_accuracy: 0.7314\n",
      "Epoch 1176/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7349 - val_loss: 0.5526 - val_accuracy: 0.7284\n",
      "Epoch 1177/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7337 - val_loss: 0.5557 - val_accuracy: 0.7301\n",
      "Epoch 1178/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7324 - val_loss: 0.5551 - val_accuracy: 0.7297\n",
      "Epoch 1179/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7334 - val_loss: 0.5535 - val_accuracy: 0.7305\n",
      "Epoch 1180/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5456 - accuracy: 0.7346 - val_loss: 0.5552 - val_accuracy: 0.7289\n",
      "Epoch 1181/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.7342 - val_loss: 0.5562 - val_accuracy: 0.7296\n",
      "Epoch 1182/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7364 - val_loss: 0.5545 - val_accuracy: 0.7319\n",
      "Epoch 1183/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5432 - accuracy: 0.7335 - val_loss: 0.5555 - val_accuracy: 0.7297\n",
      "Epoch 1184/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5417 - accuracy: 0.7361 - val_loss: 0.5598 - val_accuracy: 0.7298\n",
      "Epoch 1185/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.7346 - val_loss: 0.5538 - val_accuracy: 0.7301\n",
      "Epoch 1186/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7349 - val_loss: 0.5524 - val_accuracy: 0.7310\n",
      "Epoch 1187/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7326 - val_loss: 0.5498 - val_accuracy: 0.7287\n",
      "Epoch 1188/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7333 - val_loss: 0.5508 - val_accuracy: 0.7310\n",
      "Epoch 1189/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7344 - val_loss: 0.5524 - val_accuracy: 0.7321\n",
      "Epoch 1190/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7341 - val_loss: 0.5554 - val_accuracy: 0.7291\n",
      "Epoch 1191/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7345 - val_loss: 0.5543 - val_accuracy: 0.7294\n",
      "Epoch 1192/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5502 - accuracy: 0.7338 - val_loss: 0.5534 - val_accuracy: 0.7306\n",
      "Epoch 1193/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5528 - accuracy: 0.7333 - val_loss: 0.5554 - val_accuracy: 0.7290\n",
      "Epoch 1194/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7327 - val_loss: 0.5542 - val_accuracy: 0.7316\n",
      "Epoch 1195/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7351 - val_loss: 0.5563 - val_accuracy: 0.7319\n",
      "Epoch 1196/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5477 - accuracy: 0.7320 - val_loss: 0.5546 - val_accuracy: 0.7287\n",
      "Epoch 1197/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7351 - val_loss: 0.5537 - val_accuracy: 0.7317\n",
      "Epoch 1198/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5486 - accuracy: 0.7340 - val_loss: 0.5521 - val_accuracy: 0.7316\n",
      "Epoch 1199/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7339 - val_loss: 0.5533 - val_accuracy: 0.7303\n",
      "Epoch 1200/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7331 - val_loss: 0.5528 - val_accuracy: 0.7309\n",
      "Epoch 1201/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7357 - val_loss: 0.5564 - val_accuracy: 0.7331\n",
      "Epoch 1202/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7325 - val_loss: 0.5542 - val_accuracy: 0.7292\n",
      "Epoch 1203/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5401 - accuracy: 0.7343 - val_loss: 0.5526 - val_accuracy: 0.7311\n",
      "Epoch 1204/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5440 - accuracy: 0.7323 - val_loss: 0.5515 - val_accuracy: 0.7319\n",
      "Epoch 1205/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5439 - accuracy: 0.7321 - val_loss: 0.5529 - val_accuracy: 0.7315\n",
      "Epoch 1206/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5452 - accuracy: 0.7356 - val_loss: 0.5536 - val_accuracy: 0.7321\n",
      "Epoch 1207/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7329 - val_loss: 0.5526 - val_accuracy: 0.7316\n",
      "Epoch 1208/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7333 - val_loss: 0.5535 - val_accuracy: 0.7292\n",
      "Epoch 1209/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5411 - accuracy: 0.7340 - val_loss: 0.5547 - val_accuracy: 0.7313\n",
      "Epoch 1210/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5426 - accuracy: 0.7339 - val_loss: 0.5558 - val_accuracy: 0.7291\n",
      "Epoch 1211/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7336 - val_loss: 0.5538 - val_accuracy: 0.7294\n",
      "Epoch 1212/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5414 - accuracy: 0.7339 - val_loss: 0.5575 - val_accuracy: 0.7283\n",
      "Epoch 1213/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5423 - accuracy: 0.7362 - val_loss: 0.5527 - val_accuracy: 0.7316\n",
      "Epoch 1214/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5439 - accuracy: 0.7340 - val_loss: 0.5538 - val_accuracy: 0.7310\n",
      "Epoch 1215/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5427 - accuracy: 0.7324 - val_loss: 0.5556 - val_accuracy: 0.7293\n",
      "Epoch 1216/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5425 - accuracy: 0.7337 - val_loss: 0.5527 - val_accuracy: 0.7327\n",
      "Epoch 1217/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5418 - accuracy: 0.7352 - val_loss: 0.5557 - val_accuracy: 0.7290\n",
      "Epoch 1218/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5494 - accuracy: 0.7333 - val_loss: 0.5537 - val_accuracy: 0.7317\n",
      "Epoch 1219/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5435 - accuracy: 0.7336 - val_loss: 0.5545 - val_accuracy: 0.7279\n",
      "Epoch 1220/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.7341 - val_loss: 0.5526 - val_accuracy: 0.7313\n",
      "Epoch 1221/1500\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7343 - val_loss: 0.5537 - val_accuracy: 0.7316\n",
      "Epoch 1222/1500\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.5446 - accuracy: 0.7328 - val_loss: 0.5529 - val_accuracy: 0.7323\n",
      "Epoch 1223/1500\n",
      " 370/1225 [========>.....................] - ETA: 1s - loss: 0.5380 - accuracy: 0.7361"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_real)\n",
    "X_test_scaled = scaler.transform(X_test_real)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_cat = to_categorical(y_train_real)\n",
    "y_test_cat = to_categorical(y_test_real)\n",
    "\n",
    "# Create the Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))  # Use softmax for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_cat, epochs=1500, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test_cat)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691c473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9290f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413493f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56a860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ccfe1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4e1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df029874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming 'features' and 'labels' are your dataset's features and target variable\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train_real)\n",
    "X_test_poly = poly.transform(X_test_real)\n",
    "\n",
    "# Feature selection with RFE\n",
    "selector = RFE(RandomForestClassifier(), n_features_to_select=10, step=1)\n",
    "X_train_selected = selector.fit_transform(X_train_poly, y_train_real)\n",
    "X_test_selected = selector.transform(X_test_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885895b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "445689d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74     10461\n",
      "           1       0.75      0.71      0.73     10539\n",
      "\n",
      "    accuracy                           0.73     21000\n",
      "   macro avg       0.73      0.73      0.73     21000\n",
      "weighted avg       0.73      0.73      0.73     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# Create base classifiers with updated parameters\n",
    "clf1 = LogisticRegression(max_iter=1000, solver='saga')\n",
    "clf2 = RandomForestClassifier()  # Consider tuning hyperparameters\n",
    "clf3 = SVC(probability=True)     # Consider tuning hyperparameters\n",
    "\n",
    "# Voting classifier\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('svc', clf3)], voting='soft')\n",
    "eclf.fit(X_train_scaled, y_train_real)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test_real, eclf.predict(X_test_scaled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47859816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1df9e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74     10461\n",
      "           1       0.75      0.69      0.72     10539\n",
      "\n",
      "    accuracy                           0.73     21000\n",
      "   macro avg       0.73      0.73      0.73     21000\n",
      "weighted avg       0.73      0.73      0.73     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create base classifiers\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = SVC(probability=True)\n",
    "\n",
    "# Voting classifier\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('svc', clf3)], voting='soft')\n",
    "eclf.fit(X_train_selected, y_train_real)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test_real, eclf.predict(X_test_selected)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52996b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75     10461\n",
      "           1       0.76      0.70      0.73     10539\n",
      "\n",
      "    accuracy                           0.74     21000\n",
      "   macro avg       0.74      0.74      0.74     21000\n",
      "weighted avg       0.74      0.74      0.74     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# XGBoost with GridSearchCV\n",
    "model = XGBClassifier()\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train_selected, y_train_real)\n",
    "\n",
    "# Best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_xgb.predict(X_test_selected)\n",
    "print(classification_report(y_test_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b217dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce5d609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: 73.06% (0.58%)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74     10461\n",
      "           1       0.76      0.69      0.72     10539\n",
      "\n",
      "    accuracy                           0.73     21000\n",
      "   macro avg       0.74      0.73      0.73     21000\n",
      "weighted avg       0.74      0.73      0.73     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Implementing XGBoost with Cross-Validation\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# XGBoost model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "results = cross_val_score(model, X_train_real, y_train_real, cv=kfold)\n",
    "\n",
    "print(\"Cross-Validation Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "# Fit and evaluate model\n",
    "model.fit(X_train_real, y_train_real)\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f7eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f784471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "caf218b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'features' and 'labels' are your dataset's features and target variable\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a model to get feature importances\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_real, y_train_real)\n",
    "\n",
    "# Get feature importances and select top features\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Select top N features\n",
    "N = 5  # for example, top 5 features\n",
    "X_train_real_selected = X_train_real.iloc[:, indices[:N]]\n",
    "X_test_real_selected = X_test_real.iloc[:, indices[:N]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b16c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_real, y_train_real)  # Use the training data here\n",
    "\n",
    "# Use the best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f91aa268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75     10461\n",
      "           1       0.77      0.69      0.73     10539\n",
      "\n",
      "    accuracy                           0.74     21000\n",
      "   macro avg       0.74      0.74      0.74     21000\n",
      "weighted avg       0.74      0.74      0.74     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test_real)  # Use the test data here\n",
    "print(classification_report(y_test_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d6e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c68d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae4b2c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     10461\n",
      "           1       0.50      1.00      0.67     10539\n",
      "\n",
      "    accuracy                           0.50     21000\n",
      "   macro avg       0.25      0.50      0.33     21000\n",
      "weighted avg       0.25      0.50      0.34     21000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split real data for evaluation\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Assuming the last column was dropped from synthetic data\n",
    "# Drop the same column from X_test_real to match the feature count\n",
    "X_test_real_modified = X_test_real.drop(X_test_real.columns[-1], axis=1)\n",
    "\n",
    "# Train RandomForestClassifier on synthetic data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(synthetic_data_features, y_train_synthetic_binary)  # Using binary labels\n",
    "\n",
    "# Evaluate the model on modified real test data\n",
    "y_pred = model.predict(X_test_real_modified)\n",
    "print(classification_report(y_test_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b38b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff61bb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e9921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada82d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c342b492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 11 features, but RandomForestClassifier is expecting 10 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(synthetic_data_features, y_train_synthetic_binary)  \u001b[38;5;66;03m# Using binary labels\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Evaluate the model on real test data\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test_real, y_pred))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 11 features, but RandomForestClassifier is expecting 10 features as input."
     ]
    }
   ],
   "source": [
    "# Split real data\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming synthetic_data is your generated synthetic dataset\n",
    "# Convert the continuous labels into binary format\n",
    "y_train_synthetic_binary = (synthetic_data[:, -1] > 0.5).astype(int)\n",
    "\n",
    "# Drop the last column from synthetic data to match the feature count\n",
    "synthetic_data_features = synthetic_data[:, :-1]\n",
    "\n",
    "# Split real data for evaluation\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train RandomForestClassifier on synthetic data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(synthetic_data_features, y_train_synthetic_binary)  # Using binary labels\n",
    "\n",
    "# Evaluate the model on real test data\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7399a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccd89500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 11 features, but RandomForestClassifier is expecting 10 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(synthetic_data[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], y_train_synthetic_binary)  \u001b[38;5;66;03m# Using binary labels\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Evaluate the model on real test data\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test_real, y_pred))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 11 features, but RandomForestClassifier is expecting 10 features as input."
     ]
    }
   ],
   "source": [
    "# Step 4: Utility Assessment\n",
    "# Split real data\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming synthetic_data is your generated synthetic dataset\n",
    "# Convert the continuous labels into binary format\n",
    "y_train_synthetic_binary = (synthetic_data[:, -1] > 0.5).astype(int)\n",
    "\n",
    "# Split real data for evaluation\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train RandomForestClassifier on synthetic data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(synthetic_data[:, :-1], y_train_synthetic_binary)  # Using binary labels\n",
    "\n",
    "# Evaluate the model on real test data\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234d301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e6d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c87ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4231fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data shape: (70000, 11)\n",
      "Original data shape: (70000, 11)\n",
      "X_train_synthetic shape: (70000, 10)\n",
      "y_train_synthetic shape: (70000,)\n",
      "X_test_real shape: (21000, 11)\n",
      "y_test_real shape: (21000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature count mismatch between synthetic training and real test data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Ensure feature count matches\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_train_synthetic\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m X_test_real\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature count mismatch between synthetic training and real test data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Feature count mismatch between synthetic training and real test data."
     ]
    }
   ],
   "source": [
    "# NEW\n",
    "# After generating synthetic data\n",
    "print(\"Synthetic data shape:\", synthetic_data.shape)\n",
    "print(\"Original data shape:\", features.shape)\n",
    "\n",
    "# Split synthetic data\n",
    "X_train_synthetic = synthetic_data[:, :-1]  # Features\n",
    "y_train_synthetic = synthetic_data[:, -1]   # Labels\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(\"X_train_synthetic shape:\", X_train_synthetic.shape)\n",
    "print(\"y_train_synthetic shape:\", y_train_synthetic.shape)\n",
    "print(\"X_test_real shape:\", X_test_real.shape)\n",
    "print(\"y_test_real shape:\", y_test_real.shape)\n",
    "\n",
    "# Ensure feature count matches\n",
    "if X_train_synthetic.shape[1] != X_test_real.shape[1]:\n",
    "    raise ValueError(\"Feature count mismatch between synthetic training and real test data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dc25e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bc6e3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_real shape: (49000, 11)\n",
      "X_test_real shape: (21000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'cardio' is the label column in your original dataset\n",
    "X = cardio_df.drop('cardio', axis=1)  # Features\n",
    "y = cardio_df['cardio']  # Labels\n",
    "\n",
    "# Split original data\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Now check the shapes again\n",
    "print(\"X_train_real shape:\", X_train_real.shape)\n",
    "print(\"X_test_real shape:\", X_test_real.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee1ebc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data shape: (70000, 11)\n",
      "X_train_synthetic shape: (70000, 10)\n",
      "y_train_synthetic shape: (70000,)\n"
     ]
    }
   ],
   "source": [
    "# Verify shape of synthetic_data\n",
    "print(\"Synthetic data shape:\", synthetic_data.shape)\n",
    "\n",
    "# Correctly split synthetic data\n",
    "X_train_synthetic = synthetic_data[:, :-1]  # All columns except the last one for features\n",
    "y_train_synthetic = synthetic_data[:, -1]   # Last column for labels\n",
    "\n",
    "# Check the shapes of the split synthetic data\n",
    "print(\"X_train_synthetic shape:\", X_train_synthetic.shape)\n",
    "print(\"y_train_synthetic shape:\", y_train_synthetic.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a340f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "744f6aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 [==============================] - 2s 902us/step\n",
      "Shape of real data: (70000, 11)\n",
      "Shape of synthetic data: (70000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Generate Synthetic Data\n",
    "noise = np.random.normal(0, 1, (number_of_samples, latent_dim))\n",
    "synthetic_data = generator.predict(noise)\n",
    "\n",
    "# Ensure synthetic data has the same shape as real data\n",
    "print(\"Shape of real data:\", scaled_features.shape)\n",
    "print(\"Shape of synthetic data:\", synthetic_data.shape)\n",
    "\n",
    "if synthetic_data.shape[1] != scaled_features.shape[1]:\n",
    "    raise ValueError(\"Mismatch in feature count between synthetic and real data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a223cc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 0, D Loss: [0.65470332 0.6875    ], G Loss: 0.7423372268676758\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1, D Loss: [0.68686295 0.5625    ], G Loss: 0.7420216798782349\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 2, D Loss: [0.67187795 0.578125  ], G Loss: 0.7524374723434448\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 3, D Loss: [0.67628852 0.609375  ], G Loss: 0.7560558319091797\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 4, D Loss: [0.69505656 0.53125   ], G Loss: 0.7467207908630371\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 5, D Loss: [0.65434626 0.765625  ], G Loss: 0.7458609342575073\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 6, D Loss: [0.6834144 0.640625 ], G Loss: 0.7354834079742432\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 7, D Loss: [0.65240264 0.6875    ], G Loss: 0.7467637062072754\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 8, D Loss: [0.68621296 0.59375   ], G Loss: 0.7277160882949829\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 9, D Loss: [0.65122595 0.734375  ], G Loss: 0.7639073133468628\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 10, D Loss: [0.68135339 0.53125   ], G Loss: 0.7536752223968506\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 11, D Loss: [0.68285787 0.65625   ], G Loss: 0.735787034034729\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 12, D Loss: [0.66235676 0.703125  ], G Loss: 0.737351655960083\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 13, D Loss: [0.68093911 0.59375   ], G Loss: 0.7504831552505493\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 14, D Loss: [0.68377277 0.640625  ], G Loss: 0.7317010164260864\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 15, D Loss: [0.70010334 0.46875   ], G Loss: 0.7449571490287781\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 16, D Loss: [0.67938721 0.59375   ], G Loss: 0.7340683341026306\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 17, D Loss: [0.68962255 0.5625    ], G Loss: 0.7326034903526306\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 18, D Loss: [0.68008471 0.53125   ], G Loss: 0.732891321182251\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 19, D Loss: [0.66653877 0.640625  ], G Loss: 0.7290043234825134\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 20, D Loss: [0.69006813 0.5       ], G Loss: 0.7228487133979797\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 21, D Loss: [0.66229957 0.625     ], G Loss: 0.730532705783844\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 22, D Loss: [0.69433919 0.53125   ], G Loss: 0.7067295908927917\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 23, D Loss: [0.67969227 0.515625  ], G Loss: 0.7220008969306946\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 24, D Loss: [0.6863375 0.546875 ], G Loss: 0.7273056507110596\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 25, D Loss: [0.68747368 0.453125  ], G Loss: 0.7085666060447693\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 26, D Loss: [0.68921983 0.609375  ], G Loss: 0.7273722887039185\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 27, D Loss: [0.70205182 0.484375  ], G Loss: 0.7229642868041992\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 28, D Loss: [0.6899924 0.546875 ], G Loss: 0.7225897908210754\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 29, D Loss: [0.67583203 0.640625  ], G Loss: 0.7466895580291748\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 30, D Loss: [0.66283688 0.75      ], G Loss: 0.7082794904708862\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 31, D Loss: [0.66624141 0.625     ], G Loss: 0.72416752576828\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 32, D Loss: [0.70670262 0.53125   ], G Loss: 0.7311476469039917\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 33, D Loss: [0.6937609 0.53125  ], G Loss: 0.7212800979614258\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 34, D Loss: [0.66836554 0.671875  ], G Loss: 0.7450534105300903\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 35, D Loss: [0.67102158 0.71875   ], G Loss: 0.730932891368866\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 36, D Loss: [0.67845148 0.625     ], G Loss: 0.709997832775116\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 37, D Loss: [0.69109613 0.59375   ], G Loss: 0.7093787789344788\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 38, D Loss: [0.68569863 0.578125  ], G Loss: 0.7248759269714355\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 39, D Loss: [0.66494492 0.671875  ], G Loss: 0.730313777923584\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 40, D Loss: [0.69613865 0.53125   ], G Loss: 0.7171669602394104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 41, D Loss: [0.69391102 0.59375   ], G Loss: 0.7167755365371704\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 42, D Loss: [0.68572122 0.578125  ], G Loss: 0.731257438659668\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 43, D Loss: [0.67315 0.5625 ], G Loss: 0.7191959619522095\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 44, D Loss: [0.68956593 0.609375  ], G Loss: 0.730811357498169\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 45, D Loss: [0.68086022 0.578125  ], G Loss: 0.7132728099822998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 46, D Loss: [0.68801033 0.5625    ], G Loss: 0.7306787967681885\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 47, D Loss: [0.67463896 0.546875  ], G Loss: 0.7182128429412842\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 48, D Loss: [0.67389214 0.640625  ], G Loss: 0.7272218465805054\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 49, D Loss: [0.6748853 0.640625 ], G Loss: 0.7253451943397522\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 50, D Loss: [0.67496657 0.625     ], G Loss: 0.7155266404151917\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 51, D Loss: [0.68310422 0.640625  ], G Loss: 0.731322169303894\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 52, D Loss: [0.66570178 0.703125  ], G Loss: 0.7254575490951538\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 53, D Loss: [0.66264307 0.78125   ], G Loss: 0.7221882343292236\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 54, D Loss: [0.69797927 0.421875  ], G Loss: 0.7182990908622742\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 55, D Loss: [0.67280081 0.640625  ], G Loss: 0.7105386257171631\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 56, D Loss: [0.68658394 0.5       ], G Loss: 0.7186771035194397\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 57, D Loss: [0.67152181 0.59375   ], G Loss: 0.7242653965950012\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 58, D Loss: [0.67225862 0.609375  ], G Loss: 0.7248967289924622\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 59, D Loss: [0.68863511 0.484375  ], G Loss: 0.7174384593963623\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 60, D Loss: [0.68626806 0.5625    ], G Loss: 0.7167481184005737\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 61, D Loss: [0.67516828 0.625     ], G Loss: 0.7418501377105713\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 62, D Loss: [0.68207315 0.609375  ], G Loss: 0.7223239541053772\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 63, D Loss: [0.67167765 0.65625   ], G Loss: 0.7255157828330994\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 64, D Loss: [0.68703443 0.671875  ], G Loss: 0.738095760345459\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 65, D Loss: [0.68377909 0.625     ], G Loss: 0.7202025651931763\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 66, D Loss: [0.66921046 0.625     ], G Loss: 0.7282716035842896\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 67, D Loss: [0.66505766 0.609375  ], G Loss: 0.7450406551361084\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 68, D Loss: [0.67145583 0.65625   ], G Loss: 0.7301672697067261\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 69, D Loss: [0.67451921 0.59375   ], G Loss: 0.763089656829834\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 70, D Loss: [0.70427161 0.453125  ], G Loss: 0.7475374937057495\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 71, D Loss: [0.6703372 0.578125 ], G Loss: 0.7423492670059204\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 72, D Loss: [0.67634356 0.59375   ], G Loss: 0.7452061176300049\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 73, D Loss: [0.66427895 0.640625  ], G Loss: 0.7277202606201172\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 74, D Loss: [0.66393393 0.578125  ], G Loss: 0.7433793544769287\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 75, D Loss: [0.69321418 0.484375  ], G Loss: 0.7380383014678955\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 76, D Loss: [0.68440998 0.546875  ], G Loss: 0.745342493057251\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 77, D Loss: [0.67059523 0.59375   ], G Loss: 0.7406494617462158\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 78, D Loss: [0.68104911 0.546875  ], G Loss: 0.7407139539718628\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 79, D Loss: [0.67181751 0.59375   ], G Loss: 0.7167379856109619\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 80, D Loss: [0.65043396 0.734375  ], G Loss: 0.7308472990989685\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 81, D Loss: [0.67554268 0.640625  ], G Loss: 0.7370635867118835\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 82, D Loss: [0.67927158 0.65625   ], G Loss: 0.7193679809570312\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 83, D Loss: [0.68626973 0.53125   ], G Loss: 0.7181733846664429\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 84, D Loss: [0.68026125 0.578125  ], G Loss: 0.7370741367340088\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 85, D Loss: [0.66533393 0.6875    ], G Loss: 0.7336647510528564\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 86, D Loss: [0.68315625 0.53125   ], G Loss: 0.7389870882034302\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 87, D Loss: [0.69720912 0.484375  ], G Loss: 0.7387150526046753\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 88, D Loss: [0.66037208 0.640625  ], G Loss: 0.7303057909011841\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 89, D Loss: [0.68365508 0.578125  ], G Loss: 0.7179431915283203\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 90, D Loss: [0.68262771 0.640625  ], G Loss: 0.7207506895065308\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 91, D Loss: [0.65875351 0.6875    ], G Loss: 0.7486205697059631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 92, D Loss: [0.70289472 0.5       ], G Loss: 0.7443296313285828\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 93, D Loss: [0.69000629 0.5625    ], G Loss: 0.7240306735038757\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 94, D Loss: [0.68891346 0.5       ], G Loss: 0.7382303476333618\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 95, D Loss: [0.69089204 0.609375  ], G Loss: 0.7366548776626587\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 96, D Loss: [0.67250079 0.65625   ], G Loss: 0.7239459753036499\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 97, D Loss: [0.6739203 0.59375  ], G Loss: 0.7347425818443298\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 98, D Loss: [0.69042671 0.53125   ], G Loss: 0.7433919906616211\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 99, D Loss: [0.6718609 0.609375 ], G Loss: 0.732573390007019\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 100, D Loss: [0.68145642 0.515625  ], G Loss: 0.7235694527626038\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 101, D Loss: [0.68182442 0.5625    ], G Loss: 0.7394814491271973\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 102, D Loss: [0.67231396 0.609375  ], G Loss: 0.7314141392707825\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 103, D Loss: [0.65815899 0.671875  ], G Loss: 0.7432202100753784\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 104, D Loss: [0.68629965 0.515625  ], G Loss: 0.7252385020256042\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 105, D Loss: [0.67959151 0.546875  ], G Loss: 0.7403925061225891\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 106, D Loss: [0.68819231 0.515625  ], G Loss: 0.7317696809768677\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 107, D Loss: [0.68716204 0.515625  ], G Loss: 0.7361488342285156\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 108, D Loss: [0.67618477 0.625     ], G Loss: 0.7627713680267334\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 109, D Loss: [0.65027225 0.625     ], G Loss: 0.7558835744857788\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 110, D Loss: [0.68702531 0.5625    ], G Loss: 0.7753687500953674\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 111, D Loss: [0.68171883 0.578125  ], G Loss: 0.7426357865333557\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 112, D Loss: [0.67696822 0.5625    ], G Loss: 0.7469325065612793\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 113, D Loss: [0.66971716 0.59375   ], G Loss: 0.756320059299469\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 114, D Loss: [0.65422085 0.6875    ], G Loss: 0.740129828453064\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 115, D Loss: [0.65079492 0.640625  ], G Loss: 0.745337724685669\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 116, D Loss: [0.67906004 0.53125   ], G Loss: 0.7440248727798462\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 117, D Loss: [0.67035386 0.578125  ], G Loss: 0.7601557970046997\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 118, D Loss: [0.66694358 0.640625  ], G Loss: 0.7584711313247681\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 119, D Loss: [0.66912749 0.59375   ], G Loss: 0.745469868183136\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 120, D Loss: [0.69165856 0.53125   ], G Loss: 0.7371923327445984\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 121, D Loss: [0.69034564 0.5625    ], G Loss: 0.7646651268005371\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 122, D Loss: [0.66946313 0.578125  ], G Loss: 0.7439769506454468\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 123, D Loss: [0.68510094 0.5625    ], G Loss: 0.747366726398468\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 124, D Loss: [0.6625447 0.75     ], G Loss: 0.7554482221603394\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 125, D Loss: [0.68307409 0.546875  ], G Loss: 0.7405602931976318\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 126, D Loss: [0.65865082 0.65625   ], G Loss: 0.7366496324539185\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 127, D Loss: [0.6663205 0.625    ], G Loss: 0.731288731098175\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 128, D Loss: [0.67116573 0.65625   ], G Loss: 0.7420699000358582\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 129, D Loss: [0.66461989 0.609375  ], G Loss: 0.7354315519332886\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 130, D Loss: [0.6683715 0.609375 ], G Loss: 0.7358834743499756\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 131, D Loss: [0.68413588 0.578125  ], G Loss: 0.7490662336349487\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 132, D Loss: [0.67597389 0.546875  ], G Loss: 0.7333971261978149\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 133, D Loss: [0.66124475 0.625     ], G Loss: 0.7456763386726379\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 134, D Loss: [0.66593015 0.5625    ], G Loss: 0.7397327423095703\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 135, D Loss: [0.68782836 0.5625    ], G Loss: 0.7448042035102844\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 136, D Loss: [0.67357153 0.59375   ], G Loss: 0.7404204607009888\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 137, D Loss: [0.6897617 0.53125  ], G Loss: 0.7397699356079102\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 138, D Loss: [0.67181411 0.59375   ], G Loss: 0.7578601837158203\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 139, D Loss: [0.7060093 0.421875 ], G Loss: 0.7459031343460083\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 140, D Loss: [0.70995721 0.390625  ], G Loss: 0.7534949779510498\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 141, D Loss: [0.67024148 0.53125   ], G Loss: 0.758186399936676\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 142, D Loss: [0.67217416 0.59375   ], G Loss: 0.7587060332298279\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 143, D Loss: [0.68610272 0.515625  ], G Loss: 0.7520004510879517\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 144, D Loss: [0.66730535 0.5625    ], G Loss: 0.745304524898529\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 145, D Loss: [0.67175224 0.609375  ], G Loss: 0.7558651566505432\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 146, D Loss: [0.67861927 0.59375   ], G Loss: 0.750636875629425\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 147, D Loss: [0.69148868 0.53125   ], G Loss: 0.7612124681472778\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 148, D Loss: [0.68055207 0.53125   ], G Loss: 0.7480272054672241\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 149, D Loss: [0.67103446 0.625     ], G Loss: 0.7511266469955444\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 150, D Loss: [0.67411977 0.546875  ], G Loss: 0.739504337310791\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 151, D Loss: [0.67610919 0.65625   ], G Loss: 0.7694388628005981\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 152, D Loss: [0.67880517 0.609375  ], G Loss: 0.7388274669647217\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 153, D Loss: [0.68130103 0.65625   ], G Loss: 0.7476479411125183\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 154, D Loss: [0.6624907 0.6875   ], G Loss: 0.7528343200683594\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 155, D Loss: [0.66774526 0.625     ], G Loss: 0.7638152241706848\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 156, D Loss: [0.6620917 0.703125 ], G Loss: 0.7557053565979004\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 157, D Loss: [0.69669744 0.5       ], G Loss: 0.7505407333374023\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 158, D Loss: [0.6899451 0.609375 ], G Loss: 0.7493025064468384\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 159, D Loss: [0.68009523 0.703125  ], G Loss: 0.7484584450721741\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 160, D Loss: [0.66891277 0.65625   ], G Loss: 0.7411439418792725\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 161, D Loss: [0.67849079 0.640625  ], G Loss: 0.7328895330429077\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 162, D Loss: [0.67644632 0.59375   ], G Loss: 0.765062689781189\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 163, D Loss: [0.68054265 0.65625   ], G Loss: 0.7438766956329346\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 164, D Loss: [0.6570226 0.71875  ], G Loss: 0.7509201765060425\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 165, D Loss: [0.66748214 0.65625   ], G Loss: 0.7328018546104431\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 166, D Loss: [0.67320243 0.671875  ], G Loss: 0.7458966970443726\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 167, D Loss: [0.67463407 0.6875    ], G Loss: 0.7506615519523621\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 168, D Loss: [0.68538621 0.65625   ], G Loss: 0.727283239364624\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 169, D Loss: [0.67170456 0.6875    ], G Loss: 0.7341235876083374\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 170, D Loss: [0.67555246 0.640625  ], G Loss: 0.7399518489837646\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 171, D Loss: [0.66371572 0.71875   ], G Loss: 0.7191953063011169\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 172, D Loss: [0.6745322 0.703125 ], G Loss: 0.7403990030288696\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 173, D Loss: [0.67175388 0.734375  ], G Loss: 0.7413414716720581\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 174, D Loss: [0.66334665 0.6875    ], G Loss: 0.7381218671798706\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 175, D Loss: [0.65555081 0.765625  ], G Loss: 0.7234474420547485\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 176, D Loss: [0.67193624 0.6875    ], G Loss: 0.7488287687301636\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 177, D Loss: [0.66394308 0.640625  ], G Loss: 0.7392072677612305\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 178, D Loss: [0.66472054 0.734375  ], G Loss: 0.7366793751716614\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 179, D Loss: [0.67597082 0.75      ], G Loss: 0.7393920421600342\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 180, D Loss: [0.66436115 0.703125  ], G Loss: 0.7333039045333862\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 181, D Loss: [0.67698187 0.625     ], G Loss: 0.7347798347473145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 182, D Loss: [0.67804879 0.578125  ], G Loss: 0.736484169960022\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 183, D Loss: [0.69101095 0.578125  ], G Loss: 0.7258976697921753\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 184, D Loss: [0.67504418 0.59375   ], G Loss: 0.727020263671875\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 185, D Loss: [0.6832529 0.609375 ], G Loss: 0.7273967266082764\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 186, D Loss: [0.68705693 0.578125  ], G Loss: 0.7263017296791077\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 187, D Loss: [0.66251591 0.703125  ], G Loss: 0.7410385012626648\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 188, D Loss: [0.66468924 0.65625   ], G Loss: 0.7273145318031311\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 189, D Loss: [0.66908696 0.703125  ], G Loss: 0.7403308153152466\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 190, D Loss: [0.67671916 0.6875    ], G Loss: 0.7432035803794861\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 191, D Loss: [0.66518596 0.71875   ], G Loss: 0.7324590682983398\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 192, D Loss: [0.66196716 0.671875  ], G Loss: 0.7460353374481201\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 193, D Loss: [0.67004475 0.734375  ], G Loss: 0.728272020816803\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 194, D Loss: [0.6685302 0.671875 ], G Loss: 0.73459792137146\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 195, D Loss: [0.64831561 0.703125  ], G Loss: 0.7255464196205139\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 196, D Loss: [0.66476777 0.75      ], G Loss: 0.734040379524231\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 197, D Loss: [0.67701033 0.65625   ], G Loss: 0.7390154600143433\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 198, D Loss: [0.65403861 0.671875  ], G Loss: 0.7520618438720703\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 199, D Loss: [0.65435839 0.71875   ], G Loss: 0.7368208169937134\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 200, D Loss: [0.67235243 0.625     ], G Loss: 0.7570744752883911\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 201, D Loss: [0.6468789 0.71875  ], G Loss: 0.7531036138534546\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 202, D Loss: [0.67452088 0.609375  ], G Loss: 0.764009416103363\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 203, D Loss: [0.66436356 0.78125   ], G Loss: 0.7451251149177551\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 204, D Loss: [0.67956868 0.5625    ], G Loss: 0.740039050579071\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 205, D Loss: [0.6719518 0.625    ], G Loss: 0.7430317997932434\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 206, D Loss: [0.65699968 0.734375  ], G Loss: 0.7521296739578247\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 207, D Loss: [0.67500451 0.65625   ], G Loss: 0.7398663759231567\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 208, D Loss: [0.66204983 0.609375  ], G Loss: 0.7470828294754028\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 209, D Loss: [0.66170734 0.6875    ], G Loss: 0.7703090906143188\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 210, D Loss: [0.65804946 0.71875   ], G Loss: 0.7738922834396362\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 211, D Loss: [0.67737991 0.640625  ], G Loss: 0.7469792366027832\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 212, D Loss: [0.66356212 0.640625  ], G Loss: 0.7526863813400269\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 213, D Loss: [0.67096964 0.6875    ], G Loss: 0.7399929761886597\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 214, D Loss: [0.67028782 0.671875  ], G Loss: 0.7491604685783386\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 215, D Loss: [0.67960241 0.640625  ], G Loss: 0.7535965442657471\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 216, D Loss: [0.66049689 0.734375  ], G Loss: 0.739037036895752\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 217, D Loss: [0.67380354 0.671875  ], G Loss: 0.7307060360908508\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 218, D Loss: [0.67340732 0.640625  ], G Loss: 0.7408767938613892\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 219, D Loss: [0.6742872 0.71875  ], G Loss: 0.7229908108711243\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 220, D Loss: [0.66683871 0.6875    ], G Loss: 0.747465968132019\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 221, D Loss: [0.65689653 0.75      ], G Loss: 0.7360490560531616\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 222, D Loss: [0.6741254 0.625    ], G Loss: 0.7273629307746887\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 223, D Loss: [0.66735291 0.71875   ], G Loss: 0.7330631613731384\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 224, D Loss: [0.67173025 0.71875   ], G Loss: 0.740801215171814\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 225, D Loss: [0.65022108 0.71875   ], G Loss: 0.7207622528076172\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 226, D Loss: [0.66329947 0.6875    ], G Loss: 0.7433911561965942\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 227, D Loss: [0.66622061 0.6875    ], G Loss: 0.7342401742935181\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 228, D Loss: [0.66616923 0.6875    ], G Loss: 0.7324566841125488\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 229, D Loss: [0.68300632 0.625     ], G Loss: 0.7440924644470215\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 230, D Loss: [0.6645329 0.734375 ], G Loss: 0.7285383939743042\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 231, D Loss: [0.66757506 0.75      ], G Loss: 0.7309514284133911\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 232, D Loss: [0.67796361 0.640625  ], G Loss: 0.7418988943099976\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 233, D Loss: [0.68013313 0.625     ], G Loss: 0.7520454525947571\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 234, D Loss: [0.67946821 0.671875  ], G Loss: 0.7459204196929932\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 235, D Loss: [0.6703501 0.703125 ], G Loss: 0.7475012540817261\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 236, D Loss: [0.6803416 0.671875 ], G Loss: 0.7423194646835327\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 237, D Loss: [0.66162193 0.703125  ], G Loss: 0.7479747533798218\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 238, D Loss: [0.67173326 0.703125  ], G Loss: 0.7460106611251831\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 239, D Loss: [0.65963304 0.75      ], G Loss: 0.7603475451469421\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 240, D Loss: [0.67843217 0.625     ], G Loss: 0.7367075681686401\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 241, D Loss: [0.6794506 0.671875 ], G Loss: 0.7535359859466553\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 242, D Loss: [0.67845672 0.640625  ], G Loss: 0.7436420321464539\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 243, D Loss: [0.66557065 0.78125   ], G Loss: 0.744658350944519\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 244, D Loss: [0.654724 0.625   ], G Loss: 0.7421813607215881\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 245, D Loss: [0.66860184 0.734375  ], G Loss: 0.7559592127799988\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 246, D Loss: [0.68040761 0.59375   ], G Loss: 0.7480512857437134\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 247, D Loss: [0.66411513 0.671875  ], G Loss: 0.7403079271316528\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 248, D Loss: [0.66082206 0.78125   ], G Loss: 0.7413313388824463\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 249, D Loss: [0.66225556 0.71875   ], G Loss: 0.7449226379394531\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 250, D Loss: [0.67198974 0.65625   ], G Loss: 0.7458053231239319\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 251, D Loss: [0.6674099 0.671875 ], G Loss: 0.7550311088562012\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 252, D Loss: [0.66296092 0.765625  ], G Loss: 0.7562136650085449\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 253, D Loss: [0.67858645 0.6875    ], G Loss: 0.7403813600540161\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 254, D Loss: [0.67329904 0.765625  ], G Loss: 0.7401434779167175\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 255, D Loss: [0.66774863 0.78125   ], G Loss: 0.7454437613487244\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 256, D Loss: [0.67267913 0.78125   ], G Loss: 0.749434232711792\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 257, D Loss: [0.66091579 0.71875   ], G Loss: 0.7398275136947632\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 258, D Loss: [0.66644403 0.671875  ], G Loss: 0.7324537634849548\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 259, D Loss: [0.66113794 0.78125   ], G Loss: 0.7487484216690063\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 260, D Loss: [0.65832564 0.734375  ], G Loss: 0.7322497367858887\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 261, D Loss: [0.688393 0.640625], G Loss: 0.7464492321014404\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 262, D Loss: [0.67164227 0.625     ], G Loss: 0.7374924421310425\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 263, D Loss: [0.6606985 0.640625 ], G Loss: 0.7472808957099915\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 264, D Loss: [0.66901562 0.734375  ], G Loss: 0.740556001663208\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 265, D Loss: [0.65746325 0.671875  ], G Loss: 0.7428644895553589\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 266, D Loss: [0.65977004 0.6875    ], G Loss: 0.7439042329788208\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 267, D Loss: [0.66195786 0.6875    ], G Loss: 0.7459830045700073\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 268, D Loss: [0.64677086 0.796875  ], G Loss: 0.7382423877716064\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 269, D Loss: [0.65265527 0.71875   ], G Loss: 0.7420717477798462\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 270, D Loss: [0.65917352 0.75      ], G Loss: 0.7609978318214417\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 271, D Loss: [0.68588451 0.65625   ], G Loss: 0.7417930364608765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 272, D Loss: [0.66314059 0.75      ], G Loss: 0.7451033592224121\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 273, D Loss: [0.65565833 0.78125   ], G Loss: 0.7412155866622925\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 274, D Loss: [0.67183301 0.625     ], G Loss: 0.7698069214820862\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 275, D Loss: [0.68202403 0.59375   ], G Loss: 0.7542513608932495\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 276, D Loss: [0.66979289 0.734375  ], G Loss: 0.7611505389213562\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 277, D Loss: [0.66706592 0.71875   ], G Loss: 0.7623320817947388\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 278, D Loss: [0.69021544 0.609375  ], G Loss: 0.7587249875068665\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 279, D Loss: [0.64512801 0.78125   ], G Loss: 0.7518167495727539\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 280, D Loss: [0.67044243 0.703125  ], G Loss: 0.7524996995925903\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 281, D Loss: [0.66200557 0.78125   ], G Loss: 0.7562563419342041\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 282, D Loss: [0.67111775 0.671875  ], G Loss: 0.7435288429260254\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 283, D Loss: [0.67745328 0.59375   ], G Loss: 0.748826265335083\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 284, D Loss: [0.66796011 0.75      ], G Loss: 0.7585193514823914\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 285, D Loss: [0.67634717 0.609375  ], G Loss: 0.7546669840812683\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 286, D Loss: [0.68372384 0.609375  ], G Loss: 0.7490190863609314\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 287, D Loss: [0.67478395 0.671875  ], G Loss: 0.7302645444869995\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 288, D Loss: [0.65505967 0.796875  ], G Loss: 0.7451740503311157\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 289, D Loss: [0.66852251 0.65625   ], G Loss: 0.7290540337562561\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 290, D Loss: [0.66470221 0.65625   ], G Loss: 0.7254688143730164\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 291, D Loss: [0.65947294 0.75      ], G Loss: 0.7514443397521973\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 292, D Loss: [0.67405915 0.71875   ], G Loss: 0.7270729541778564\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 293, D Loss: [0.65763557 0.796875  ], G Loss: 0.7457535862922668\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 294, D Loss: [0.67262647 0.578125  ], G Loss: 0.7228180170059204\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 295, D Loss: [0.6624293 0.609375 ], G Loss: 0.7431290149688721\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 296, D Loss: [0.66154912 0.65625   ], G Loss: 0.7326587438583374\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 297, D Loss: [0.66246796 0.71875   ], G Loss: 0.719017744064331\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 298, D Loss: [0.66526449 0.71875   ], G Loss: 0.7207555770874023\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 299, D Loss: [0.66263556 0.71875   ], G Loss: 0.7435901165008545\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 300, D Loss: [0.6647225 0.703125 ], G Loss: 0.7199671268463135\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 301, D Loss: [0.67409998 0.640625  ], G Loss: 0.7278096675872803\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 302, D Loss: [0.66569903 0.8125    ], G Loss: 0.7198008298873901\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 303, D Loss: [0.684605 0.5625  ], G Loss: 0.7410855293273926\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 304, D Loss: [0.67083824 0.6875    ], G Loss: 0.7250432372093201\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 305, D Loss: [0.66613972 0.71875   ], G Loss: 0.7155678868293762\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 306, D Loss: [0.6856932 0.5625   ], G Loss: 0.7322947382926941\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 307, D Loss: [0.6655263 0.734375 ], G Loss: 0.7503024339675903\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 308, D Loss: [0.66374683 0.703125  ], G Loss: 0.7104296684265137\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 309, D Loss: [0.67352024 0.640625  ], G Loss: 0.7074095010757446\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 310, D Loss: [0.66993204 0.59375   ], G Loss: 0.7296115159988403\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 311, D Loss: [0.67509308 0.65625   ], G Loss: 0.7235782742500305\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 312, D Loss: [0.68369377 0.546875  ], G Loss: 0.7301702499389648\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 313, D Loss: [0.66888571 0.671875  ], G Loss: 0.7338335514068604\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 314, D Loss: [0.69164616 0.578125  ], G Loss: 0.7106260657310486\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 315, D Loss: [0.67108139 0.75      ], G Loss: 0.7327420711517334\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 316, D Loss: [0.65434831 0.78125   ], G Loss: 0.707047700881958\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 317, D Loss: [0.68119746 0.765625  ], G Loss: 0.7175806760787964\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 318, D Loss: [0.69044736 0.46875   ], G Loss: 0.724584698677063\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 319, D Loss: [0.68810755 0.578125  ], G Loss: 0.7145332098007202\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 320, D Loss: [0.66820991 0.734375  ], G Loss: 0.7151855826377869\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 321, D Loss: [0.70676503 0.515625  ], G Loss: 0.7372744083404541\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 322, D Loss: [0.66689679 0.78125   ], G Loss: 0.7263827323913574\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 323, D Loss: [0.68341044 0.71875   ], G Loss: 0.7569787502288818\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 324, D Loss: [0.68996203 0.578125  ], G Loss: 0.7384630441665649\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 325, D Loss: [0.66803631 0.765625  ], G Loss: 0.7407227158546448\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 326, D Loss: [0.66337481 0.8125    ], G Loss: 0.7420783638954163\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 327, D Loss: [0.69149417 0.5625    ], G Loss: 0.7268109917640686\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 328, D Loss: [0.67520893 0.65625   ], G Loss: 0.7472779750823975\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 329, D Loss: [0.66922188 0.671875  ], G Loss: 0.7271159887313843\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 330, D Loss: [0.6680446 0.640625 ], G Loss: 0.7247368097305298\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 331, D Loss: [0.69559553 0.578125  ], G Loss: 0.7302205562591553\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 332, D Loss: [0.67350975 0.6875    ], G Loss: 0.7325809001922607\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 333, D Loss: [0.68326044 0.609375  ], G Loss: 0.7299482822418213\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 334, D Loss: [0.6802637 0.609375 ], G Loss: 0.737539529800415\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 335, D Loss: [0.67861003 0.65625   ], G Loss: 0.7336146831512451\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 336, D Loss: [0.65733832 0.6875    ], G Loss: 0.7355430126190186\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 337, D Loss: [0.68505776 0.703125  ], G Loss: 0.7281405925750732\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 338, D Loss: [0.67404601 0.625     ], G Loss: 0.7300242781639099\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 339, D Loss: [0.67367208 0.6875    ], G Loss: 0.7208655476570129\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 340, D Loss: [0.66664004 0.75      ], G Loss: 0.7165616154670715\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 341, D Loss: [0.7068074 0.515625 ], G Loss: 0.7219426035881042\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 342, D Loss: [0.69203901 0.640625  ], G Loss: 0.7335172891616821\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 343, D Loss: [0.66600123 0.765625  ], G Loss: 0.7372373938560486\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 344, D Loss: [0.67027044 0.65625   ], G Loss: 0.7389534711837769\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 345, D Loss: [0.68393901 0.609375  ], G Loss: 0.7436710000038147\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 346, D Loss: [0.68644908 0.625     ], G Loss: 0.7259367108345032\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 347, D Loss: [0.6789934 0.71875  ], G Loss: 0.7213786840438843\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 348, D Loss: [0.69673461 0.5       ], G Loss: 0.7260026931762695\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 349, D Loss: [0.66924733 0.703125  ], G Loss: 0.718719482421875\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 350, D Loss: [0.68219686 0.65625   ], G Loss: 0.7356215715408325\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 351, D Loss: [0.70115691 0.578125  ], G Loss: 0.7374700307846069\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 352, D Loss: [0.6756613 0.734375 ], G Loss: 0.7410077452659607\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 353, D Loss: [0.68156204 0.65625   ], G Loss: 0.7242175340652466\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 354, D Loss: [0.68000951 0.640625  ], G Loss: 0.7225161194801331\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 355, D Loss: [0.68160558 0.671875  ], G Loss: 0.7135952115058899\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 356, D Loss: [0.67038101 0.765625  ], G Loss: 0.7281948328018188\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 357, D Loss: [0.68039036 0.71875   ], G Loss: 0.7114627361297607\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 358, D Loss: [0.68562603 0.578125  ], G Loss: 0.7185421586036682\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 359, D Loss: [0.67652208 0.65625   ], G Loss: 0.7188043594360352\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 360, D Loss: [0.68224829 0.640625  ], G Loss: 0.7297077775001526\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 361, D Loss: [0.67550102 0.6875    ], G Loss: 0.722685694694519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 362, D Loss: [0.68903887 0.65625   ], G Loss: 0.7305246591567993\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 363, D Loss: [0.67633265 0.640625  ], G Loss: 0.7267947196960449\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 364, D Loss: [0.67626917 0.6875    ], G Loss: 0.7236220240592957\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 365, D Loss: [0.68025851 0.703125  ], G Loss: 0.7384345531463623\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 366, D Loss: [0.680718 0.59375 ], G Loss: 0.7390083074569702\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 367, D Loss: [0.6764589 0.6875   ], G Loss: 0.7282665967941284\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 368, D Loss: [0.67660353 0.671875  ], G Loss: 0.7292143106460571\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 369, D Loss: [0.66831762 0.65625   ], G Loss: 0.7199240326881409\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 370, D Loss: [0.67586169 0.671875  ], G Loss: 0.7359753847122192\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 371, D Loss: [0.69569123 0.546875  ], G Loss: 0.7324343919754028\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 372, D Loss: [0.6949648 0.5625   ], G Loss: 0.737263560295105\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 373, D Loss: [0.66136035 0.75      ], G Loss: 0.734978437423706\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 374, D Loss: [0.69076011 0.578125  ], G Loss: 0.7327958345413208\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 375, D Loss: [0.68083265 0.6875    ], G Loss: 0.7467973828315735\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 376, D Loss: [0.68125001 0.6875    ], G Loss: 0.7529796361923218\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 377, D Loss: [0.69019377 0.546875  ], G Loss: 0.7406917214393616\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 378, D Loss: [0.679712 0.625   ], G Loss: 0.734485387802124\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 379, D Loss: [0.67042357 0.609375  ], G Loss: 0.7247314453125\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 380, D Loss: [0.67000246 0.734375  ], G Loss: 0.746334433555603\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 381, D Loss: [0.67362624 0.765625  ], G Loss: 0.7224650979042053\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 382, D Loss: [0.67569476 0.609375  ], G Loss: 0.7292945981025696\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 383, D Loss: [0.67419901 0.65625   ], G Loss: 0.7121649980545044\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 384, D Loss: [0.68962529 0.625     ], G Loss: 0.7360072135925293\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 385, D Loss: [0.67767024 0.65625   ], G Loss: 0.7345491647720337\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 386, D Loss: [0.66447952 0.6875    ], G Loss: 0.7390902042388916\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 387, D Loss: [0.66620481 0.703125  ], G Loss: 0.735697865486145\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 388, D Loss: [0.68315384 0.6875    ], G Loss: 0.7286491990089417\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 389, D Loss: [0.6912106 0.609375 ], G Loss: 0.7340278029441833\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 390, D Loss: [0.68370727 0.640625  ], G Loss: 0.7502485513687134\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 391, D Loss: [0.67891192 0.625     ], G Loss: 0.7366542816162109\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 392, D Loss: [0.68943021 0.625     ], G Loss: 0.7245750427246094\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 393, D Loss: [0.68370971 0.609375  ], G Loss: 0.7241969704627991\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 394, D Loss: [0.68169481 0.65625   ], G Loss: 0.7242144346237183\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 395, D Loss: [0.68768373 0.515625  ], G Loss: 0.7299375534057617\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 396, D Loss: [0.67913288 0.625     ], G Loss: 0.740949809551239\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 397, D Loss: [0.67258739 0.703125  ], G Loss: 0.7267898321151733\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 398, D Loss: [0.67569476 0.671875  ], G Loss: 0.7421172261238098\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 399, D Loss: [0.68330473 0.703125  ], G Loss: 0.7417417764663696\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 400, D Loss: [0.69191542 0.609375  ], G Loss: 0.7393589615821838\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 401, D Loss: [0.67470586 0.671875  ], G Loss: 0.7402012348175049\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 402, D Loss: [0.68454352 0.578125  ], G Loss: 0.730193018913269\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 403, D Loss: [0.66563919 0.734375  ], G Loss: 0.7218614220619202\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 404, D Loss: [0.67784604 0.71875   ], G Loss: 0.7454135417938232\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 405, D Loss: [0.68270978 0.609375  ], G Loss: 0.7557079195976257\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 406, D Loss: [0.68434793 0.65625   ], G Loss: 0.7416030168533325\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 407, D Loss: [0.66857573 0.765625  ], G Loss: 0.7415145635604858\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 408, D Loss: [0.67229524 0.65625   ], G Loss: 0.7284319400787354\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 409, D Loss: [0.68944991 0.59375   ], G Loss: 0.7197819948196411\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 410, D Loss: [0.682596 0.625   ], G Loss: 0.7217039465904236\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 411, D Loss: [0.7034339 0.4375   ], G Loss: 0.7242109775543213\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 412, D Loss: [0.68039533 0.609375  ], G Loss: 0.7362974882125854\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 413, D Loss: [0.68544534 0.5625    ], G Loss: 0.7229945659637451\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 414, D Loss: [0.67332232 0.765625  ], G Loss: 0.7301110029220581\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 415, D Loss: [0.67139846 0.6875    ], G Loss: 0.7203863859176636\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 416, D Loss: [0.67824471 0.6875    ], G Loss: 0.7313711643218994\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 417, D Loss: [0.67854702 0.6875    ], G Loss: 0.739364743232727\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 418, D Loss: [0.6832225 0.5      ], G Loss: 0.733735203742981\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 419, D Loss: [0.66266346 0.6875    ], G Loss: 0.7380223274230957\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 420, D Loss: [0.6766375 0.59375  ], G Loss: 0.7451930046081543\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 421, D Loss: [0.6785419 0.625    ], G Loss: 0.7289498448371887\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 422, D Loss: [0.67528504 0.6875    ], G Loss: 0.7269847989082336\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 423, D Loss: [0.67809218 0.6875    ], G Loss: 0.7476691007614136\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 424, D Loss: [0.67328584 0.640625  ], G Loss: 0.7473213076591492\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 425, D Loss: [0.68453309 0.625     ], G Loss: 0.7232182025909424\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 426, D Loss: [0.6627906 0.703125 ], G Loss: 0.7379370927810669\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 427, D Loss: [0.66961122 0.59375   ], G Loss: 0.7237841486930847\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 428, D Loss: [0.66389507 0.75      ], G Loss: 0.7374663352966309\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 429, D Loss: [0.69293141 0.515625  ], G Loss: 0.7421281337738037\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 430, D Loss: [0.6776545 0.65625  ], G Loss: 0.729961097240448\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 431, D Loss: [0.68402556 0.609375  ], G Loss: 0.7241196632385254\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 432, D Loss: [0.69313776 0.609375  ], G Loss: 0.7336326837539673\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 433, D Loss: [0.68153426 0.609375  ], G Loss: 0.7418546676635742\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 434, D Loss: [0.69644567 0.578125  ], G Loss: 0.7324495911598206\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 435, D Loss: [0.68038797 0.546875  ], G Loss: 0.7246814966201782\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 436, D Loss: [0.6912629 0.609375 ], G Loss: 0.7318810820579529\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 437, D Loss: [0.69249523 0.5625    ], G Loss: 0.7260267734527588\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 438, D Loss: [0.70160216 0.515625  ], G Loss: 0.7293375730514526\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 439, D Loss: [0.67586684 0.640625  ], G Loss: 0.7196035981178284\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 440, D Loss: [0.69143456 0.578125  ], G Loss: 0.7314490079879761\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 441, D Loss: [0.69559497 0.609375  ], G Loss: 0.7284835577011108\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 442, D Loss: [0.68176803 0.578125  ], G Loss: 0.7443287968635559\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 443, D Loss: [0.67546919 0.671875  ], G Loss: 0.732204794883728\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 444, D Loss: [0.67762399 0.578125  ], G Loss: 0.7247036695480347\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 445, D Loss: [0.67995948 0.609375  ], G Loss: 0.7374595403671265\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 446, D Loss: [0.69427919 0.609375  ], G Loss: 0.7240300178527832\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 447, D Loss: [0.68314564 0.59375   ], G Loss: 0.7336528301239014\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 448, D Loss: [0.68129864 0.578125  ], G Loss: 0.7261654138565063\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 449, D Loss: [0.67778486 0.734375  ], G Loss: 0.7362575531005859\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 450, D Loss: [0.67912662 0.6875    ], G Loss: 0.7291849255561829\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 451, D Loss: [0.67866677 0.59375   ], G Loss: 0.7295769453048706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 452, D Loss: [0.69312343 0.453125  ], G Loss: 0.7304489612579346\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 453, D Loss: [0.69643641 0.5625    ], G Loss: 0.7487664222717285\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 454, D Loss: [0.69929853 0.484375  ], G Loss: 0.7172519564628601\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 455, D Loss: [0.67670882 0.59375   ], G Loss: 0.7309799194335938\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 456, D Loss: [0.67986953 0.625     ], G Loss: 0.7347608208656311\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 457, D Loss: [0.6667271 0.671875 ], G Loss: 0.7287269830703735\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 458, D Loss: [0.68354017 0.625     ], G Loss: 0.7368832230567932\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 459, D Loss: [0.68618923 0.546875  ], G Loss: 0.7285060286521912\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 460, D Loss: [0.68265536 0.59375   ], G Loss: 0.7432690262794495\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 461, D Loss: [0.6714853 0.703125 ], G Loss: 0.7345684170722961\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 462, D Loss: [0.67845625 0.671875  ], G Loss: 0.7291619777679443\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 463, D Loss: [0.67573816 0.65625   ], G Loss: 0.7311373353004456\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 464, D Loss: [0.67330664 0.6875    ], G Loss: 0.7198828458786011\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 465, D Loss: [0.67421597 0.625     ], G Loss: 0.741675078868866\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 466, D Loss: [0.68224081 0.625     ], G Loss: 0.730518102645874\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 467, D Loss: [0.69526005 0.5625    ], G Loss: 0.713327169418335\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 468, D Loss: [0.68705049 0.484375  ], G Loss: 0.7323649525642395\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 469, D Loss: [0.68965721 0.5625    ], G Loss: 0.7363834381103516\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 470, D Loss: [0.68693718 0.53125   ], G Loss: 0.7218469381332397\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 471, D Loss: [0.68019736 0.625     ], G Loss: 0.721196174621582\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 472, D Loss: [0.68682057 0.546875  ], G Loss: 0.7314530611038208\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 473, D Loss: [0.67680129 0.625     ], G Loss: 0.7265942096710205\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 474, D Loss: [0.68030271 0.609375  ], G Loss: 0.737309455871582\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 475, D Loss: [0.67722771 0.609375  ], G Loss: 0.7414130568504333\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 476, D Loss: [0.67879164 0.59375   ], G Loss: 0.753753125667572\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 477, D Loss: [0.68358174 0.625     ], G Loss: 0.7377893924713135\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 478, D Loss: [0.67553851 0.6875    ], G Loss: 0.7403087615966797\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 479, D Loss: [0.68832609 0.578125  ], G Loss: 0.7534170746803284\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 480, D Loss: [0.68646166 0.515625  ], G Loss: 0.7517099380493164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 481, D Loss: [0.69246733 0.546875  ], G Loss: 0.7348708510398865\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 482, D Loss: [0.6747767 0.640625 ], G Loss: 0.7499359846115112\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 483, D Loss: [0.66848701 0.640625  ], G Loss: 0.727957010269165\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 484, D Loss: [0.68977398 0.59375   ], G Loss: 0.7371921539306641\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 485, D Loss: [0.66507173 0.625     ], G Loss: 0.7570505142211914\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 486, D Loss: [0.68475765 0.515625  ], G Loss: 0.7427787184715271\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 487, D Loss: [0.69251996 0.59375   ], G Loss: 0.747902512550354\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 488, D Loss: [0.67191324 0.671875  ], G Loss: 0.7439937591552734\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 489, D Loss: [0.67490485 0.640625  ], G Loss: 0.7410303950309753\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 490, D Loss: [0.70683676 0.46875   ], G Loss: 0.7522244453430176\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 491, D Loss: [0.67279717 0.59375   ], G Loss: 0.7570329308509827\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 492, D Loss: [0.67127037 0.578125  ], G Loss: 0.7507599592208862\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 493, D Loss: [0.70021212 0.578125  ], G Loss: 0.7405769228935242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 494, D Loss: [0.69409338 0.453125  ], G Loss: 0.7400780320167542\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 495, D Loss: [0.68577996 0.609375  ], G Loss: 0.7441586256027222\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 496, D Loss: [0.67791116 0.609375  ], G Loss: 0.7324769496917725\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 497, D Loss: [0.66545227 0.6875    ], G Loss: 0.7393544316291809\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 498, D Loss: [0.69157457 0.625     ], G Loss: 0.7433338761329651\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 499, D Loss: [0.68041924 0.65625   ], G Loss: 0.7375946044921875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 500, D Loss: [0.67921048 0.59375   ], G Loss: 0.7461144924163818\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 501, D Loss: [0.69893348 0.484375  ], G Loss: 0.7249415516853333\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 502, D Loss: [0.67737377 0.59375   ], G Loss: 0.7338658571243286\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 503, D Loss: [0.68188101 0.546875  ], G Loss: 0.7311368584632874\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 504, D Loss: [0.68337128 0.546875  ], G Loss: 0.7275197505950928\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 505, D Loss: [0.67456424 0.609375  ], G Loss: 0.7304946780204773\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 506, D Loss: [0.6737228 0.6875   ], G Loss: 0.7714196443557739\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 507, D Loss: [0.70902517 0.515625  ], G Loss: 0.7491142749786377\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 508, D Loss: [0.66806278 0.65625   ], G Loss: 0.7472043633460999\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 509, D Loss: [0.67597866 0.703125  ], G Loss: 0.7429631948471069\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 510, D Loss: [0.69310403 0.53125   ], G Loss: 0.7380562424659729\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 511, D Loss: [0.69167578 0.515625  ], G Loss: 0.7414069175720215\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 512, D Loss: [0.66553509 0.640625  ], G Loss: 0.7549002766609192\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 513, D Loss: [0.69200441 0.59375   ], G Loss: 0.7564535737037659\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 514, D Loss: [0.69737858 0.5       ], G Loss: 0.7400867938995361\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 515, D Loss: [0.68110484 0.640625  ], G Loss: 0.7398386597633362\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 516, D Loss: [0.67685124 0.625     ], G Loss: 0.7449265718460083\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 517, D Loss: [0.69274336 0.53125   ], G Loss: 0.7606204748153687\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 518, D Loss: [0.6845457 0.484375 ], G Loss: 0.7649974822998047\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 519, D Loss: [0.68820655 0.484375  ], G Loss: 0.7332929372787476\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 520, D Loss: [0.69346255 0.484375  ], G Loss: 0.7483766078948975\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 521, D Loss: [0.69011149 0.609375  ], G Loss: 0.7607141733169556\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 522, D Loss: [0.69773024 0.515625  ], G Loss: 0.7390835881233215\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 523, D Loss: [0.67542505 0.625     ], G Loss: 0.7576169967651367\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 524, D Loss: [0.68532753 0.546875  ], G Loss: 0.747603178024292\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 525, D Loss: [0.68640107 0.515625  ], G Loss: 0.7570521831512451\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 526, D Loss: [0.67557815 0.671875  ], G Loss: 0.7526350617408752\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 527, D Loss: [0.66641107 0.703125  ], G Loss: 0.7468646764755249\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 528, D Loss: [0.67197478 0.65625   ], G Loss: 0.7456586360931396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 529, D Loss: [0.6796062 0.609375 ], G Loss: 0.755793571472168\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 530, D Loss: [0.67172179 0.640625  ], G Loss: 0.7703662514686584\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 531, D Loss: [0.66548786 0.71875   ], G Loss: 0.7515497207641602\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 532, D Loss: [0.68896216 0.59375   ], G Loss: 0.7487014532089233\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 533, D Loss: [0.66656312 0.640625  ], G Loss: 0.7247519493103027\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 534, D Loss: [0.67423007 0.65625   ], G Loss: 0.746393084526062\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 535, D Loss: [0.67534524 0.6875    ], G Loss: 0.750190019607544\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 536, D Loss: [0.69527033 0.546875  ], G Loss: 0.7607401609420776\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 537, D Loss: [0.66145131 0.703125  ], G Loss: 0.7524930238723755\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 538, D Loss: [0.68702134 0.625     ], G Loss: 0.747435450553894\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 539, D Loss: [0.67247009 0.5625    ], G Loss: 0.7413034439086914\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 540, D Loss: [0.67905885 0.65625   ], G Loss: 0.7360013723373413\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 541, D Loss: [0.6940434 0.53125  ], G Loss: 0.7509105801582336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 542, D Loss: [0.67246613 0.609375  ], G Loss: 0.7561547756195068\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 543, D Loss: [0.70902756 0.453125  ], G Loss: 0.7439119815826416\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 544, D Loss: [0.68329138 0.671875  ], G Loss: 0.7478259801864624\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 545, D Loss: [0.65773398 0.734375  ], G Loss: 0.7574062943458557\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 546, D Loss: [0.68887642 0.578125  ], G Loss: 0.756264328956604\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 547, D Loss: [0.67328212 0.640625  ], G Loss: 0.7495002746582031\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 548, D Loss: [0.67748526 0.671875  ], G Loss: 0.7410441637039185\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 549, D Loss: [0.68913072 0.5625    ], G Loss: 0.7470829486846924\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 550, D Loss: [0.69509542 0.640625  ], G Loss: 0.7646694183349609\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 551, D Loss: [0.68717992 0.5625    ], G Loss: 0.7490627765655518\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 552, D Loss: [0.69112659 0.609375  ], G Loss: 0.753429114818573\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 553, D Loss: [0.67831516 0.640625  ], G Loss: 0.7467780709266663\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 554, D Loss: [0.67841709 0.625     ], G Loss: 0.7477839589118958\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 555, D Loss: [0.69305319 0.4375    ], G Loss: 0.746397852897644\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 556, D Loss: [0.68098041 0.59375   ], G Loss: 0.7424651384353638\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 557, D Loss: [0.70318267 0.578125  ], G Loss: 0.740463137626648\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 558, D Loss: [0.69768211 0.5625    ], G Loss: 0.7493546009063721\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 559, D Loss: [0.67427972 0.578125  ], G Loss: 0.7487016916275024\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 560, D Loss: [0.67658907 0.65625   ], G Loss: 0.7462434768676758\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 561, D Loss: [0.67909771 0.671875  ], G Loss: 0.7412307262420654\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 562, D Loss: [0.68412566 0.609375  ], G Loss: 0.7325044274330139\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 563, D Loss: [0.68707806 0.5       ], G Loss: 0.740877628326416\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 564, D Loss: [0.69455138 0.515625  ], G Loss: 0.7387235164642334\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 565, D Loss: [0.68080655 0.609375  ], G Loss: 0.7425615787506104\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 566, D Loss: [0.67126629 0.671875  ], G Loss: 0.7220163345336914\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 567, D Loss: [0.66993994 0.703125  ], G Loss: 0.7333787679672241\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 568, D Loss: [0.6802817 0.5625   ], G Loss: 0.7364095449447632\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 569, D Loss: [0.67738611 0.640625  ], G Loss: 0.7335175275802612\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 570, D Loss: [0.67176798 0.71875   ], G Loss: 0.7497104406356812\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 571, D Loss: [0.68694881 0.59375   ], G Loss: 0.7339857816696167\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 572, D Loss: [0.67821255 0.53125   ], G Loss: 0.7311192750930786\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 573, D Loss: [0.67036381 0.578125  ], G Loss: 0.7397083044052124\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 574, D Loss: [0.67812452 0.640625  ], G Loss: 0.7355304956436157\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 575, D Loss: [0.69393241 0.53125   ], G Loss: 0.7398437261581421\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 576, D Loss: [0.67035335 0.703125  ], G Loss: 0.7435072064399719\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 577, D Loss: [0.66648781 0.65625   ], G Loss: 0.7450587749481201\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 578, D Loss: [0.67802116 0.625     ], G Loss: 0.7286818027496338\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 579, D Loss: [0.6954987 0.421875 ], G Loss: 0.7326027154922485\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 580, D Loss: [0.67615291 0.703125  ], G Loss: 0.7412057518959045\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 581, D Loss: [0.67975605 0.578125  ], G Loss: 0.7352373600006104\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 582, D Loss: [0.67468482 0.703125  ], G Loss: 0.7384783029556274\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 583, D Loss: [0.68240407 0.640625  ], G Loss: 0.7482075095176697\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 584, D Loss: [0.66111112 0.640625  ], G Loss: 0.7258926033973694\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 585, D Loss: [0.68437001 0.625     ], G Loss: 0.7569801211357117\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 586, D Loss: [0.69239882 0.609375  ], G Loss: 0.7378445863723755\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 587, D Loss: [0.66882765 0.734375  ], G Loss: 0.7353976964950562\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 588, D Loss: [0.67489809 0.703125  ], G Loss: 0.73604416847229\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 589, D Loss: [0.67928976 0.65625   ], G Loss: 0.7334966063499451\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 590, D Loss: [0.67302215 0.609375  ], G Loss: 0.7266610860824585\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 591, D Loss: [0.68258843 0.65625   ], G Loss: 0.7388522028923035\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 592, D Loss: [0.68035659 0.6875    ], G Loss: 0.7316401600837708\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 593, D Loss: [0.6682061 0.6875   ], G Loss: 0.7277028560638428\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 594, D Loss: [0.67071381 0.6875    ], G Loss: 0.7384564876556396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 595, D Loss: [0.67232531 0.734375  ], G Loss: 0.7449226379394531\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 596, D Loss: [0.66584536 0.6875    ], G Loss: 0.7357839941978455\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 597, D Loss: [0.67565432 0.65625   ], G Loss: 0.7370209693908691\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 598, D Loss: [0.70794386 0.625     ], G Loss: 0.7451037168502808\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 599, D Loss: [0.67236602 0.765625  ], G Loss: 0.7348343729972839\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 600, D Loss: [0.66483468 0.6875    ], G Loss: 0.7318689823150635\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 601, D Loss: [0.67327049 0.703125  ], G Loss: 0.7604221105575562\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 602, D Loss: [0.67004931 0.671875  ], G Loss: 0.7410531044006348\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 603, D Loss: [0.68475863 0.53125   ], G Loss: 0.7407273054122925\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 604, D Loss: [0.66469014 0.75      ], G Loss: 0.7491568922996521\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 605, D Loss: [0.67560464 0.625     ], G Loss: 0.7561257481575012\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 606, D Loss: [0.67858106 0.671875  ], G Loss: 0.739183783531189\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 607, D Loss: [0.6739215 0.6875   ], G Loss: 0.7353749871253967\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 608, D Loss: [0.6703718 0.71875  ], G Loss: 0.7373825907707214\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 609, D Loss: [0.6892629 0.59375  ], G Loss: 0.7412446737289429\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 610, D Loss: [0.67081165 0.609375  ], G Loss: 0.7481151223182678\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 611, D Loss: [0.67752981 0.609375  ], G Loss: 0.7484543919563293\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 612, D Loss: [0.68300286 0.59375   ], G Loss: 0.7364200949668884\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 613, D Loss: [0.66849536 0.75      ], G Loss: 0.7401477098464966\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 614, D Loss: [0.67712101 0.703125  ], G Loss: 0.7508057355880737\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 615, D Loss: [0.68051723 0.625     ], G Loss: 0.7505060434341431\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 616, D Loss: [0.68344399 0.65625   ], G Loss: 0.7472641468048096\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 617, D Loss: [0.67939174 0.671875  ], G Loss: 0.7313166260719299\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 618, D Loss: [0.68683341 0.578125  ], G Loss: 0.7491511106491089\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 619, D Loss: [0.68707898 0.59375   ], G Loss: 0.7308920621871948\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 620, D Loss: [0.67613029 0.703125  ], G Loss: 0.7317215204238892\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 621, D Loss: [0.68078732 0.609375  ], G Loss: 0.7374023199081421\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 622, D Loss: [0.67882329 0.609375  ], G Loss: 0.7174144983291626\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 623, D Loss: [0.67489168 0.640625  ], G Loss: 0.723361611366272\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 624, D Loss: [0.67551035 0.640625  ], G Loss: 0.7209482789039612\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 625, D Loss: [0.68763691 0.703125  ], G Loss: 0.7320411205291748\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 626, D Loss: [0.67516375 0.640625  ], G Loss: 0.7337252497673035\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 627, D Loss: [0.67579186 0.640625  ], G Loss: 0.720914363861084\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 628, D Loss: [0.67250866 0.71875   ], G Loss: 0.7272459864616394\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 629, D Loss: [0.67706412 0.609375  ], G Loss: 0.7164220213890076\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 630, D Loss: [0.68792397 0.578125  ], G Loss: 0.7246761322021484\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 631, D Loss: [0.68818107 0.6875    ], G Loss: 0.7256813049316406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 632, D Loss: [0.68551242 0.59375   ], G Loss: 0.7142267227172852\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 633, D Loss: [0.68012115 0.59375   ], G Loss: 0.744497537612915\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 634, D Loss: [0.67557451 0.640625  ], G Loss: 0.7512772679328918\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 635, D Loss: [0.66258457 0.734375  ], G Loss: 0.7346384525299072\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 636, D Loss: [0.67489043 0.65625   ], G Loss: 0.7380517721176147\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 637, D Loss: [0.6702475 0.625    ], G Loss: 0.7369381189346313\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 638, D Loss: [0.66803205 0.75      ], G Loss: 0.7240718007087708\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 639, D Loss: [0.68175647 0.671875  ], G Loss: 0.728778064250946\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 640, D Loss: [0.67572227 0.703125  ], G Loss: 0.7277696132659912\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 641, D Loss: [0.67827535 0.65625   ], G Loss: 0.7248392701148987\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 642, D Loss: [0.66436931 0.75      ], G Loss: 0.7178653478622437\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 643, D Loss: [0.67047125 0.703125  ], G Loss: 0.7325612902641296\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 644, D Loss: [0.67912829 0.6875    ], G Loss: 0.7190544009208679\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 645, D Loss: [0.66776913 0.671875  ], G Loss: 0.7297868728637695\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 646, D Loss: [0.67070568 0.6875    ], G Loss: 0.7079419493675232\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 647, D Loss: [0.66117674 0.796875  ], G Loss: 0.7141964435577393\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 648, D Loss: [0.67627698 0.625     ], G Loss: 0.7144490480422974\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 649, D Loss: [0.68324625 0.640625  ], G Loss: 0.7234702706336975\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 650, D Loss: [0.69290867 0.5625    ], G Loss: 0.7209238409996033\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 651, D Loss: [0.68579835 0.640625  ], G Loss: 0.7250081896781921\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 652, D Loss: [0.69472408 0.484375  ], G Loss: 0.7066435813903809\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 653, D Loss: [0.68298024 0.578125  ], G Loss: 0.708016574382782\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 654, D Loss: [0.68379295 0.640625  ], G Loss: 0.7422536015510559\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 655, D Loss: [0.68171576 0.59375   ], G Loss: 0.7176439166069031\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 656, D Loss: [0.67761752 0.671875  ], G Loss: 0.71345055103302\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 657, D Loss: [0.68185347 0.515625  ], G Loss: 0.7256544828414917\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 658, D Loss: [0.68451232 0.546875  ], G Loss: 0.7210983633995056\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 659, D Loss: [0.69353327 0.5625    ], G Loss: 0.7215126156806946\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 660, D Loss: [0.67745727 0.71875   ], G Loss: 0.7111950516700745\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 661, D Loss: [0.68464184 0.59375   ], G Loss: 0.7125670909881592\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 662, D Loss: [0.66981083 0.71875   ], G Loss: 0.7268780469894409\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 663, D Loss: [0.68219388 0.609375  ], G Loss: 0.7179264426231384\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 664, D Loss: [0.67555392 0.671875  ], G Loss: 0.706838846206665\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 665, D Loss: [0.69430667 0.53125   ], G Loss: 0.7151468992233276\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 666, D Loss: [0.68205675 0.75      ], G Loss: 0.712898313999176\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 667, D Loss: [0.67811155 0.671875  ], G Loss: 0.7369469404220581\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 668, D Loss: [0.67637235 0.65625   ], G Loss: 0.7138665914535522\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 669, D Loss: [0.68577078 0.59375   ], G Loss: 0.7212873697280884\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 670, D Loss: [0.67616552 0.6875    ], G Loss: 0.7297532558441162\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 671, D Loss: [0.70108813 0.5625    ], G Loss: 0.7223776578903198\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 672, D Loss: [0.68822226 0.578125  ], G Loss: 0.7222820520401001\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 673, D Loss: [0.67536885 0.65625   ], G Loss: 0.7523964643478394\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 674, D Loss: [0.68790817 0.609375  ], G Loss: 0.7401118278503418\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 675, D Loss: [0.68634322 0.5625    ], G Loss: 0.732796311378479\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 676, D Loss: [0.68933812 0.5625    ], G Loss: 0.7369169592857361\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 677, D Loss: [0.66848099 0.71875   ], G Loss: 0.7335757613182068\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 678, D Loss: [0.66617078 0.65625   ], G Loss: 0.7382442355155945\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 679, D Loss: [0.6730327 0.671875 ], G Loss: 0.7356131076812744\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 680, D Loss: [0.68883371 0.53125   ], G Loss: 0.739621639251709\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 681, D Loss: [0.67794493 0.53125   ], G Loss: 0.7370150089263916\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 682, D Loss: [0.67382893 0.671875  ], G Loss: 0.7250357866287231\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 683, D Loss: [0.66552234 0.734375  ], G Loss: 0.7182203531265259\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 684, D Loss: [0.66732061 0.703125  ], G Loss: 0.7281990647315979\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 685, D Loss: [0.68078214 0.578125  ], G Loss: 0.7425211668014526\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 686, D Loss: [0.66144466 0.671875  ], G Loss: 0.7382307648658752\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 687, D Loss: [0.6874392 0.546875 ], G Loss: 0.7348512411117554\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 688, D Loss: [0.66162485 0.71875   ], G Loss: 0.7322137355804443\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 689, D Loss: [0.68694577 0.5       ], G Loss: 0.7415896654129028\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 690, D Loss: [0.68782514 0.59375   ], G Loss: 0.7433741092681885\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 691, D Loss: [0.6691131 0.71875  ], G Loss: 0.725823700428009\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 692, D Loss: [0.68086502 0.578125  ], G Loss: 0.7249433994293213\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 693, D Loss: [0.68937907 0.578125  ], G Loss: 0.7284090518951416\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 694, D Loss: [0.6782147 0.5625   ], G Loss: 0.7350993752479553\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 695, D Loss: [0.69044435 0.59375   ], G Loss: 0.7315587401390076\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 696, D Loss: [0.68394685 0.5625    ], G Loss: 0.732520341873169\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 697, D Loss: [0.68144926 0.65625   ], G Loss: 0.7237197160720825\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 698, D Loss: [0.68107036 0.578125  ], G Loss: 0.7296524047851562\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 699, D Loss: [0.69950134 0.53125   ], G Loss: 0.7309800386428833\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 700, D Loss: [0.6833308 0.625    ], G Loss: 0.7314664125442505\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 701, D Loss: [0.67610449 0.59375   ], G Loss: 0.7310278415679932\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 702, D Loss: [0.68320858 0.59375   ], G Loss: 0.734856903553009\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 703, D Loss: [0.67313868 0.6875    ], G Loss: 0.7608828544616699\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 704, D Loss: [0.68156427 0.5625    ], G Loss: 0.7322738170623779\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 705, D Loss: [0.67431954 0.65625   ], G Loss: 0.7379743456840515\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 706, D Loss: [0.67966044 0.609375  ], G Loss: 0.7485653162002563\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 707, D Loss: [0.69750082 0.640625  ], G Loss: 0.7423244714736938\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 708, D Loss: [0.66898596 0.703125  ], G Loss: 0.7305325269699097\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 709, D Loss: [0.6788837 0.71875  ], G Loss: 0.7317066788673401\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 710, D Loss: [0.67069864 0.703125  ], G Loss: 0.7275173664093018\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 711, D Loss: [0.68502471 0.65625   ], G Loss: 0.7364523410797119\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 712, D Loss: [0.67392889 0.734375  ], G Loss: 0.7365369200706482\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 713, D Loss: [0.68304703 0.609375  ], G Loss: 0.7402730584144592\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 714, D Loss: [0.67989916 0.671875  ], G Loss: 0.750708818435669\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 715, D Loss: [0.67737219 0.6875    ], G Loss: 0.7371722459793091\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 716, D Loss: [0.67864162 0.59375   ], G Loss: 0.7386065721511841\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 717, D Loss: [0.67949352 0.6875    ], G Loss: 0.7361106276512146\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 718, D Loss: [0.6822041 0.640625 ], G Loss: 0.7535789608955383\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 719, D Loss: [0.68541443 0.59375   ], G Loss: 0.7495838403701782\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 720, D Loss: [0.68305972 0.59375   ], G Loss: 0.7435652017593384\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 721, D Loss: [0.67000726 0.75      ], G Loss: 0.7535642385482788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 722, D Loss: [0.6864149 0.5625   ], G Loss: 0.7454677224159241\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 723, D Loss: [0.67557979 0.703125  ], G Loss: 0.7516554594039917\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 724, D Loss: [0.66603372 0.796875  ], G Loss: 0.755742073059082\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 725, D Loss: [0.68153718 0.65625   ], G Loss: 0.7384942770004272\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 726, D Loss: [0.6742703 0.6875   ], G Loss: 0.7347590327262878\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 727, D Loss: [0.67209661 0.6875    ], G Loss: 0.7428576946258545\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 728, D Loss: [0.6643911 0.78125  ], G Loss: 0.7392988204956055\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 729, D Loss: [0.7065663 0.578125 ], G Loss: 0.751887321472168\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 730, D Loss: [0.67336416 0.671875  ], G Loss: 0.7544980049133301\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 731, D Loss: [0.66711912 0.640625  ], G Loss: 0.7618334293365479\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 732, D Loss: [0.66178551 0.734375  ], G Loss: 0.7481034994125366\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 733, D Loss: [0.69209093 0.65625   ], G Loss: 0.7698594927787781\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 734, D Loss: [0.67590696 0.640625  ], G Loss: 0.741889238357544\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 735, D Loss: [0.6834949 0.609375 ], G Loss: 0.7549625635147095\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 736, D Loss: [0.6787647 0.609375 ], G Loss: 0.7460386753082275\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 737, D Loss: [0.66503742 0.640625  ], G Loss: 0.7366305589675903\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 738, D Loss: [0.67219946 0.640625  ], G Loss: 0.747691810131073\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 739, D Loss: [0.67754608 0.59375   ], G Loss: 0.738544225692749\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 740, D Loss: [0.69182718 0.5625    ], G Loss: 0.7428879141807556\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 741, D Loss: [0.68647793 0.609375  ], G Loss: 0.7452605962753296\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 742, D Loss: [0.67046669 0.671875  ], G Loss: 0.7363951206207275\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 743, D Loss: [0.68274188 0.640625  ], G Loss: 0.7393220663070679\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 744, D Loss: [0.68512228 0.609375  ], G Loss: 0.7323114275932312\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 745, D Loss: [0.65896627 0.703125  ], G Loss: 0.740761399269104\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 746, D Loss: [0.67066106 0.578125  ], G Loss: 0.7425661087036133\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 747, D Loss: [0.6598632 0.734375 ], G Loss: 0.7529568672180176\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 748, D Loss: [0.65273303 0.75      ], G Loss: 0.7581669092178345\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 749, D Loss: [0.67773718 0.671875  ], G Loss: 0.7493709325790405\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 750, D Loss: [0.67991984 0.609375  ], G Loss: 0.7663896083831787\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 751, D Loss: [0.67420578 0.59375   ], G Loss: 0.7456544041633606\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 752, D Loss: [0.69194832 0.59375   ], G Loss: 0.7529875040054321\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 753, D Loss: [0.67700034 0.640625  ], G Loss: 0.7579288482666016\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 754, D Loss: [0.67543224 0.6875    ], G Loss: 0.7437116503715515\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 755, D Loss: [0.67393368 0.609375  ], G Loss: 0.7384395599365234\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 756, D Loss: [0.6753546 0.59375  ], G Loss: 0.73191237449646\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 757, D Loss: [0.68026203 0.640625  ], G Loss: 0.7238544225692749\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 758, D Loss: [0.67437395 0.609375  ], G Loss: 0.7368926405906677\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 759, D Loss: [0.69024274 0.578125  ], G Loss: 0.7496466636657715\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 760, D Loss: [0.67441779 0.65625   ], G Loss: 0.735197126865387\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 761, D Loss: [0.6721909 0.65625  ], G Loss: 0.7397659420967102\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 762, D Loss: [0.66703886 0.625     ], G Loss: 0.7507872581481934\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 763, D Loss: [0.67910147 0.640625  ], G Loss: 0.7483407855033875\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 764, D Loss: [0.68479699 0.546875  ], G Loss: 0.7455940246582031\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 765, D Loss: [0.6694901 0.6875   ], G Loss: 0.7530026435852051\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 766, D Loss: [0.69363606 0.46875   ], G Loss: 0.729256808757782\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 767, D Loss: [0.6778824 0.59375  ], G Loss: 0.7496747970581055\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 768, D Loss: [0.67834479 0.640625  ], G Loss: 0.7473716139793396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 769, D Loss: [0.68913272 0.578125  ], G Loss: 0.7564445734024048\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 770, D Loss: [0.68463427 0.609375  ], G Loss: 0.7485947608947754\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 771, D Loss: [0.68822297 0.53125   ], G Loss: 0.7561743259429932\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 772, D Loss: [0.67564154 0.640625  ], G Loss: 0.7549343109130859\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 773, D Loss: [0.6716027 0.546875 ], G Loss: 0.7429705858230591\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 774, D Loss: [0.67896312 0.578125  ], G Loss: 0.7415130734443665\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 775, D Loss: [0.68754533 0.65625   ], G Loss: 0.7590459585189819\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 776, D Loss: [0.69092417 0.609375  ], G Loss: 0.7425529360771179\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 777, D Loss: [0.66199669 0.734375  ], G Loss: 0.7368593811988831\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 778, D Loss: [0.68372965 0.609375  ], G Loss: 0.7364466786384583\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 779, D Loss: [0.68674728 0.578125  ], G Loss: 0.73902428150177\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 780, D Loss: [0.66971737 0.625     ], G Loss: 0.7452998161315918\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 781, D Loss: [0.68769342 0.5625    ], G Loss: 0.7395855188369751\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 782, D Loss: [0.6685915 0.703125 ], G Loss: 0.7493265271186829\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 783, D Loss: [0.68196225 0.625     ], G Loss: 0.7530402541160583\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 784, D Loss: [0.68462431 0.578125  ], G Loss: 0.7476575374603271\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 785, D Loss: [0.68220121 0.65625   ], G Loss: 0.7311009764671326\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 786, D Loss: [0.6739226 0.671875 ], G Loss: 0.7447961568832397\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 787, D Loss: [0.67917174 0.671875  ], G Loss: 0.7361655235290527\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 788, D Loss: [0.68525204 0.546875  ], G Loss: 0.7378945350646973\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 789, D Loss: [0.68144378 0.546875  ], G Loss: 0.7455097436904907\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 790, D Loss: [0.67502758 0.609375  ], G Loss: 0.7375005483627319\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 791, D Loss: [0.68521643 0.578125  ], G Loss: 0.7458087205886841\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 792, D Loss: [0.67386195 0.734375  ], G Loss: 0.7478753328323364\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 793, D Loss: [0.68365505 0.625     ], G Loss: 0.7195433378219604\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 794, D Loss: [0.67410284 0.6875    ], G Loss: 0.7500636577606201\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 795, D Loss: [0.67350832 0.671875  ], G Loss: 0.7340570092201233\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 796, D Loss: [0.67442828 0.640625  ], G Loss: 0.7438674569129944\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 797, D Loss: [0.65516919 0.78125   ], G Loss: 0.7278163433074951\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 798, D Loss: [0.6779108 0.671875 ], G Loss: 0.7381688952445984\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 799, D Loss: [0.68922186 0.625     ], G Loss: 0.7401697039604187\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 800, D Loss: [0.68502429 0.59375   ], G Loss: 0.7369397282600403\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 801, D Loss: [0.67820755 0.578125  ], G Loss: 0.7390286922454834\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 802, D Loss: [0.68102884 0.5625    ], G Loss: 0.7441368103027344\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 803, D Loss: [0.67522866 0.640625  ], G Loss: 0.7339212894439697\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 804, D Loss: [0.69101602 0.5       ], G Loss: 0.7325657606124878\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 805, D Loss: [0.66376862 0.75      ], G Loss: 0.7366652488708496\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 806, D Loss: [0.67118204 0.703125  ], G Loss: 0.743084728717804\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 807, D Loss: [0.66394827 0.71875   ], G Loss: 0.7268521785736084\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 808, D Loss: [0.66820851 0.625     ], G Loss: 0.7310599088668823\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 809, D Loss: [0.68239021 0.578125  ], G Loss: 0.7214227914810181\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 810, D Loss: [0.71423274 0.625     ], G Loss: 0.7314128875732422\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 811, D Loss: [0.68750361 0.515625  ], G Loss: 0.7296286225318909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 812, D Loss: [0.6832673 0.625    ], G Loss: 0.7426823377609253\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 813, D Loss: [0.6816808 0.578125 ], G Loss: 0.7300578355789185\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 814, D Loss: [0.67507109 0.609375  ], G Loss: 0.7304495573043823\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 815, D Loss: [0.68142217 0.59375   ], G Loss: 0.7248820066452026\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 816, D Loss: [0.68145338 0.625     ], G Loss: 0.7426666021347046\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 817, D Loss: [0.67841998 0.609375  ], G Loss: 0.7362905740737915\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 818, D Loss: [0.66260049 0.703125  ], G Loss: 0.7417827844619751\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 819, D Loss: [0.67800876 0.609375  ], G Loss: 0.7262371182441711\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 820, D Loss: [0.67706019 0.53125   ], G Loss: 0.7339272499084473\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 821, D Loss: [0.68389606 0.5625    ], G Loss: 0.729998767375946\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 822, D Loss: [0.67747292 0.671875  ], G Loss: 0.7385896444320679\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 823, D Loss: [0.6677295 0.703125 ], G Loss: 0.7340152263641357\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 824, D Loss: [0.68544683 0.578125  ], G Loss: 0.7379418611526489\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 825, D Loss: [0.67758608 0.640625  ], G Loss: 0.7445113658905029\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 826, D Loss: [0.68822885 0.546875  ], G Loss: 0.7313071489334106\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 827, D Loss: [0.67811668 0.640625  ], G Loss: 0.7507548332214355\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 828, D Loss: [0.68591747 0.546875  ], G Loss: 0.7367091178894043\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 829, D Loss: [0.67760459 0.6875    ], G Loss: 0.7352509498596191\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 830, D Loss: [0.66740978 0.671875  ], G Loss: 0.7414121031761169\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 831, D Loss: [0.68810835 0.59375   ], G Loss: 0.7507991790771484\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 832, D Loss: [0.67724252 0.59375   ], G Loss: 0.740802526473999\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 833, D Loss: [0.68345577 0.609375  ], G Loss: 0.7320233583450317\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 834, D Loss: [0.68099207 0.625     ], G Loss: 0.7392055988311768\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 835, D Loss: [0.6787304 0.625    ], G Loss: 0.7383866310119629\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 836, D Loss: [0.67632806 0.59375   ], G Loss: 0.7435684204101562\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 837, D Loss: [0.67156348 0.625     ], G Loss: 0.7306229472160339\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 838, D Loss: [0.67496756 0.671875  ], G Loss: 0.7296603918075562\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 839, D Loss: [0.67899764 0.6875    ], G Loss: 0.7204534411430359\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 840, D Loss: [0.67494261 0.671875  ], G Loss: 0.7395521402359009\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 841, D Loss: [0.68529844 0.609375  ], G Loss: 0.7121427059173584\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 842, D Loss: [0.67942271 0.65625   ], G Loss: 0.7328643202781677\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 843, D Loss: [0.68880045 0.578125  ], G Loss: 0.7316925525665283\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 844, D Loss: [0.67983097 0.59375   ], G Loss: 0.7487956285476685\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 845, D Loss: [0.67193824 0.625     ], G Loss: 0.7111737728118896\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 846, D Loss: [0.67539546 0.65625   ], G Loss: 0.7161500453948975\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 847, D Loss: [0.6796892 0.59375  ], G Loss: 0.7183626294136047\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 848, D Loss: [0.67622578 0.75      ], G Loss: 0.7177497744560242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 849, D Loss: [0.67740422 0.6875    ], G Loss: 0.7336397767066956\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 850, D Loss: [0.67454642 0.671875  ], G Loss: 0.728291392326355\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 851, D Loss: [0.67563477 0.609375  ], G Loss: 0.7112240791320801\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 852, D Loss: [0.68727928 0.625     ], G Loss: 0.7068689465522766\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 853, D Loss: [0.69004184 0.515625  ], G Loss: 0.7145419716835022\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 854, D Loss: [0.69002533 0.671875  ], G Loss: 0.7108720541000366\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 855, D Loss: [0.67486024 0.71875   ], G Loss: 0.7212209701538086\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 856, D Loss: [0.68354815 0.546875  ], G Loss: 0.7138445973396301\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 857, D Loss: [0.67665115 0.703125  ], G Loss: 0.7289813756942749\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 858, D Loss: [0.67232028 0.6875    ], G Loss: 0.731399655342102\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 859, D Loss: [0.67161155 0.71875   ], G Loss: 0.7175822854042053\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 860, D Loss: [0.67697388 0.65625   ], G Loss: 0.7300676107406616\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 861, D Loss: [0.67968068 0.6875    ], G Loss: 0.7380582094192505\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 862, D Loss: [0.68266723 0.65625   ], G Loss: 0.7284910678863525\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 863, D Loss: [0.68393153 0.625     ], G Loss: 0.7444102168083191\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 864, D Loss: [0.69644189 0.5625    ], G Loss: 0.7346488237380981\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 865, D Loss: [0.67159066 0.6875    ], G Loss: 0.7471640110015869\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 866, D Loss: [0.67840767 0.59375   ], G Loss: 0.741445779800415\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 867, D Loss: [0.66624486 0.796875  ], G Loss: 0.7414973974227905\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 868, D Loss: [0.6796577 0.640625 ], G Loss: 0.734801173210144\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 869, D Loss: [0.68016818 0.578125  ], G Loss: 0.737808346748352\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 870, D Loss: [0.68456173 0.578125  ], G Loss: 0.7428503632545471\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 871, D Loss: [0.67633119 0.734375  ], G Loss: 0.750942587852478\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 872, D Loss: [0.67655495 0.671875  ], G Loss: 0.7290425300598145\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 873, D Loss: [0.6916222 0.53125  ], G Loss: 0.7346773147583008\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 874, D Loss: [0.673168 0.6875  ], G Loss: 0.7262149453163147\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 875, D Loss: [0.68245444 0.65625   ], G Loss: 0.7332675457000732\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 876, D Loss: [0.67425519 0.78125   ], G Loss: 0.7180938720703125\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 877, D Loss: [0.67499316 0.625     ], G Loss: 0.7193037867546082\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 878, D Loss: [0.68939924 0.65625   ], G Loss: 0.7318172454833984\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 879, D Loss: [0.68686718 0.53125   ], G Loss: 0.7279707193374634\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 880, D Loss: [0.6779325 0.671875 ], G Loss: 0.7461038827896118\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 881, D Loss: [0.69061095 0.609375  ], G Loss: 0.7348091006278992\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 882, D Loss: [0.6724458 0.65625  ], G Loss: 0.7259604930877686\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 883, D Loss: [0.67055637 0.6875    ], G Loss: 0.7153995037078857\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 884, D Loss: [0.6569666 0.71875  ], G Loss: 0.7401629090309143\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 885, D Loss: [0.66874838 0.71875   ], G Loss: 0.7240676283836365\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 886, D Loss: [0.66757679 0.671875  ], G Loss: 0.7421801090240479\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 887, D Loss: [0.69065645 0.578125  ], G Loss: 0.7233484983444214\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 888, D Loss: [0.66424248 0.765625  ], G Loss: 0.7419668436050415\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 889, D Loss: [0.66983986 0.640625  ], G Loss: 0.7318001985549927\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 890, D Loss: [0.68198901 0.65625   ], G Loss: 0.7387165427207947\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 891, D Loss: [0.66222754 0.671875  ], G Loss: 0.7441703081130981\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 892, D Loss: [0.67998189 0.640625  ], G Loss: 0.7347437143325806\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 893, D Loss: [0.66667801 0.734375  ], G Loss: 0.7425906658172607\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 894, D Loss: [0.68518615 0.6875    ], G Loss: 0.7387332320213318\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 895, D Loss: [0.66899991 0.671875  ], G Loss: 0.7207373976707458\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 896, D Loss: [0.68194973 0.609375  ], G Loss: 0.7442303895950317\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 897, D Loss: [0.68372545 0.5625    ], G Loss: 0.7409719228744507\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 898, D Loss: [0.68793124 0.625     ], G Loss: 0.7252768874168396\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 899, D Loss: [0.68342328 0.6875    ], G Loss: 0.7373803853988647\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 900, D Loss: [0.68565524 0.65625   ], G Loss: 0.719224214553833\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 901, D Loss: [0.67263925 0.6875    ], G Loss: 0.7287715673446655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 902, D Loss: [0.68364334 0.59375   ], G Loss: 0.7126010656356812\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 903, D Loss: [0.66539627 0.765625  ], G Loss: 0.7179173231124878\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 904, D Loss: [0.68064541 0.59375   ], G Loss: 0.7348113059997559\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 905, D Loss: [0.66567239 0.65625   ], G Loss: 0.703927755355835\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 906, D Loss: [0.68609142 0.625     ], G Loss: 0.7298486232757568\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 907, D Loss: [0.67572469 0.65625   ], G Loss: 0.7105147838592529\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 908, D Loss: [0.68237549 0.59375   ], G Loss: 0.7201803922653198\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 909, D Loss: [0.67250159 0.65625   ], G Loss: 0.7001444697380066\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 910, D Loss: [0.67991227 0.59375   ], G Loss: 0.7160263061523438\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 911, D Loss: [0.68636811 0.5625    ], G Loss: 0.6999122500419617\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 912, D Loss: [0.68427989 0.625     ], G Loss: 0.6806888580322266\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 913, D Loss: [0.68312377 0.625     ], G Loss: 0.7135092616081238\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 914, D Loss: [0.67106241 0.671875  ], G Loss: 0.7220691442489624\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 915, D Loss: [0.68262559 0.625     ], G Loss: 0.7115446329116821\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 916, D Loss: [0.68375638 0.578125  ], G Loss: 0.7237551212310791\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 917, D Loss: [0.67227882 0.734375  ], G Loss: 0.7196576595306396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 918, D Loss: [0.67883337 0.640625  ], G Loss: 0.7258588075637817\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 919, D Loss: [0.67847323 0.671875  ], G Loss: 0.7263540029525757\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 920, D Loss: [0.68613133 0.609375  ], G Loss: 0.7252089977264404\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 921, D Loss: [0.69209382 0.578125  ], G Loss: 0.727484405040741\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 922, D Loss: [0.67705613 0.703125  ], G Loss: 0.7446375489234924\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 923, D Loss: [0.6828329 0.625    ], G Loss: 0.739093542098999\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 924, D Loss: [0.67559603 0.640625  ], G Loss: 0.725523054599762\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 925, D Loss: [0.68353266 0.578125  ], G Loss: 0.7440570592880249\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 926, D Loss: [0.67760676 0.65625   ], G Loss: 0.7296700477600098\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 927, D Loss: [0.67886725 0.640625  ], G Loss: 0.7163612842559814\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 928, D Loss: [0.67427194 0.65625   ], G Loss: 0.7400256395339966\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 929, D Loss: [0.67599434 0.640625  ], G Loss: 0.7231483459472656\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 930, D Loss: [0.66491985 0.71875   ], G Loss: 0.7227625846862793\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 931, D Loss: [0.67524481 0.71875   ], G Loss: 0.7294951677322388\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 932, D Loss: [0.6726526 0.65625  ], G Loss: 0.7300944328308105\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 933, D Loss: [0.68047142 0.65625   ], G Loss: 0.7154518365859985\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 934, D Loss: [0.67444915 0.59375   ], G Loss: 0.7322414517402649\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 935, D Loss: [0.66885585 0.65625   ], G Loss: 0.7140460014343262\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 936, D Loss: [0.68502408 0.671875  ], G Loss: 0.7166736125946045\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 937, D Loss: [0.68118623 0.640625  ], G Loss: 0.7287746071815491\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 938, D Loss: [0.67947745 0.609375  ], G Loss: 0.7349794507026672\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 939, D Loss: [0.6754722 0.671875 ], G Loss: 0.7118717432022095\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 940, D Loss: [0.68100157 0.59375   ], G Loss: 0.727229118347168\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 941, D Loss: [0.67524868 0.6875    ], G Loss: 0.7268354892730713\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 942, D Loss: [0.67221388 0.75      ], G Loss: 0.7274644374847412\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 943, D Loss: [0.69039005 0.515625  ], G Loss: 0.7167171239852905\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 944, D Loss: [0.68144748 0.671875  ], G Loss: 0.7307234406471252\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 945, D Loss: [0.67274874 0.609375  ], G Loss: 0.7057715058326721\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 946, D Loss: [0.68805036 0.625     ], G Loss: 0.7064860463142395\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 947, D Loss: [0.66802999 0.703125  ], G Loss: 0.7273091673851013\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 948, D Loss: [0.67161095 0.65625   ], G Loss: 0.7181572914123535\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 949, D Loss: [0.65916422 0.671875  ], G Loss: 0.7240402102470398\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 950, D Loss: [0.66627771 0.734375  ], G Loss: 0.7264907360076904\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 951, D Loss: [0.67120108 0.71875   ], G Loss: 0.7330889701843262\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 952, D Loss: [0.69139186 0.609375  ], G Loss: 0.7288460731506348\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 953, D Loss: [0.67035243 0.640625  ], G Loss: 0.7195665836334229\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 954, D Loss: [0.69137701 0.546875  ], G Loss: 0.7314717173576355\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 955, D Loss: [0.66438109 0.640625  ], G Loss: 0.7228085994720459\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 956, D Loss: [0.67374659 0.65625   ], G Loss: 0.7131587266921997\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 957, D Loss: [0.67332643 0.671875  ], G Loss: 0.7158322930335999\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 958, D Loss: [0.67753559 0.703125  ], G Loss: 0.7136021852493286\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 959, D Loss: [0.66474235 0.71875   ], G Loss: 0.7191009521484375\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 960, D Loss: [0.67431545 0.640625  ], G Loss: 0.7044854164123535\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 961, D Loss: [0.66476685 0.71875   ], G Loss: 0.7085825204849243\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 962, D Loss: [0.69278634 0.546875  ], G Loss: 0.717695951461792\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 963, D Loss: [0.66697785 0.6875    ], G Loss: 0.7109733819961548\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 964, D Loss: [0.65762195 0.6875    ], G Loss: 0.713969349861145\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 965, D Loss: [0.6879136 0.546875 ], G Loss: 0.7232561111450195\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 966, D Loss: [0.67380652 0.671875  ], G Loss: 0.7295759916305542\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 967, D Loss: [0.67832491 0.625     ], G Loss: 0.7272182703018188\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 968, D Loss: [0.67917639 0.65625   ], G Loss: 0.7261146306991577\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 969, D Loss: [0.68063346 0.65625   ], G Loss: 0.730829119682312\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 970, D Loss: [0.67569464 0.703125  ], G Loss: 0.7259539365768433\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 971, D Loss: [0.69157889 0.5625    ], G Loss: 0.7177224159240723\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 972, D Loss: [0.66650313 0.765625  ], G Loss: 0.7355585694313049\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 973, D Loss: [0.67626688 0.6875    ], G Loss: 0.7265341877937317\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 974, D Loss: [0.6846087 0.671875 ], G Loss: 0.7346214056015015\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 975, D Loss: [0.68541893 0.640625  ], G Loss: 0.7240003347396851\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 976, D Loss: [0.67669791 0.609375  ], G Loss: 0.7466479539871216\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 977, D Loss: [0.68999779 0.578125  ], G Loss: 0.7155120372772217\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 978, D Loss: [0.66239381 0.734375  ], G Loss: 0.7342058420181274\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 979, D Loss: [0.67264879 0.6875    ], G Loss: 0.7168272137641907\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 980, D Loss: [0.65963608 0.671875  ], G Loss: 0.7136077880859375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 981, D Loss: [0.67548591 0.6875    ], G Loss: 0.7234933376312256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 982, D Loss: [0.67725962 0.703125  ], G Loss: 0.7234320640563965\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 983, D Loss: [0.68203026 0.546875  ], G Loss: 0.7263648509979248\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 984, D Loss: [0.67733267 0.65625   ], G Loss: 0.7359126806259155\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 985, D Loss: [0.68710876 0.59375   ], G Loss: 0.7255344390869141\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 986, D Loss: [0.6866127 0.625    ], G Loss: 0.7342314720153809\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 987, D Loss: [0.66879755 0.625     ], G Loss: 0.741691529750824\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 988, D Loss: [0.66636342 0.75      ], G Loss: 0.7324163317680359\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 989, D Loss: [0.68206152 0.59375   ], G Loss: 0.7220492362976074\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 990, D Loss: [0.6815677 0.609375 ], G Loss: 0.7434309720993042\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 991, D Loss: [0.69245911 0.625     ], G Loss: 0.7255349159240723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 992, D Loss: [0.66692993 0.671875  ], G Loss: 0.7324541211128235\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 993, D Loss: [0.67396757 0.734375  ], G Loss: 0.7294291257858276\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 994, D Loss: [0.68127176 0.65625   ], G Loss: 0.7380973100662231\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 995, D Loss: [0.66013315 0.71875   ], G Loss: 0.7393398284912109\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 996, D Loss: [0.66865444 0.8125    ], G Loss: 0.7298504114151001\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 997, D Loss: [0.67635611 0.65625   ], G Loss: 0.7263672351837158\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 998, D Loss: [0.68401623 0.578125  ], G Loss: 0.7483819723129272\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 999, D Loss: [0.679207 0.625   ], G Loss: 0.7345700263977051\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1000, D Loss: [0.68305936 0.65625   ], G Loss: 0.7413690090179443\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1001, D Loss: [0.65621001 0.796875  ], G Loss: 0.7459215521812439\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1002, D Loss: [0.6836262 0.5625   ], G Loss: 0.7324254512786865\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1003, D Loss: [0.68396837 0.671875  ], G Loss: 0.7373855113983154\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1004, D Loss: [0.66849691 0.71875   ], G Loss: 0.7287822961807251\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1005, D Loss: [0.67922735 0.65625   ], G Loss: 0.7234753370285034\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1006, D Loss: [0.68034896 0.578125  ], G Loss: 0.7380329966545105\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1007, D Loss: [0.67519519 0.609375  ], G Loss: 0.7398344278335571\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1008, D Loss: [0.66928351 0.734375  ], G Loss: 0.7314209938049316\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1009, D Loss: [0.68431804 0.609375  ], G Loss: 0.743739128112793\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1010, D Loss: [0.68085641 0.6875    ], G Loss: 0.7329368591308594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1011, D Loss: [0.66806027 0.671875  ], G Loss: 0.7477273941040039\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1012, D Loss: [0.67893305 0.65625   ], G Loss: 0.7433959245681763\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1013, D Loss: [0.68733165 0.59375   ], G Loss: 0.7432031631469727\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1014, D Loss: [0.67649066 0.65625   ], G Loss: 0.7344657182693481\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1015, D Loss: [0.66349739 0.671875  ], G Loss: 0.7525367736816406\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1016, D Loss: [0.67176777 0.625     ], G Loss: 0.7485092282295227\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1017, D Loss: [0.6815199 0.640625 ], G Loss: 0.7313948273658752\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1018, D Loss: [0.68028423 0.640625  ], G Loss: 0.7279796600341797\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1019, D Loss: [0.67022225 0.6875    ], G Loss: 0.7435817718505859\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1020, D Loss: [0.67022955 0.640625  ], G Loss: 0.7562305331230164\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1021, D Loss: [0.67560324 0.640625  ], G Loss: 0.7328917384147644\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1022, D Loss: [0.67948198 0.6875    ], G Loss: 0.7461619973182678\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1023, D Loss: [0.65979892 0.671875  ], G Loss: 0.7398081421852112\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1024, D Loss: [0.6824916 0.578125 ], G Loss: 0.7380009293556213\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1025, D Loss: [0.68048614 0.640625  ], G Loss: 0.7366746068000793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1026, D Loss: [0.68219137 0.609375  ], G Loss: 0.737519383430481\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1027, D Loss: [0.66672212 0.6875    ], G Loss: 0.7309215068817139\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1028, D Loss: [0.6785877 0.53125  ], G Loss: 0.7362977266311646\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1029, D Loss: [0.68788415 0.5625    ], G Loss: 0.752948522567749\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1030, D Loss: [0.67231008 0.640625  ], G Loss: 0.7428764700889587\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1031, D Loss: [0.66624281 0.734375  ], G Loss: 0.740416407585144\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1032, D Loss: [0.68138725 0.65625   ], G Loss: 0.7403973340988159\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1033, D Loss: [0.67369258 0.765625  ], G Loss: 0.7271542549133301\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1034, D Loss: [0.68559736 0.625     ], G Loss: 0.7377216219902039\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1035, D Loss: [0.67278659 0.6875    ], G Loss: 0.730589747428894\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1036, D Loss: [0.68052769 0.703125  ], G Loss: 0.7357019186019897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1037, D Loss: [0.67609909 0.703125  ], G Loss: 0.7198002338409424\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1038, D Loss: [0.67946175 0.6875    ], G Loss: 0.7179055213928223\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1039, D Loss: [0.67384207 0.671875  ], G Loss: 0.7256350517272949\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1040, D Loss: [0.67279953 0.734375  ], G Loss: 0.7201340198516846\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1041, D Loss: [0.66333747 0.75      ], G Loss: 0.7244174480438232\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1042, D Loss: [0.67189634 0.6875    ], G Loss: 0.7063812017440796\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1043, D Loss: [0.66840395 0.609375  ], G Loss: 0.7204834818840027\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1044, D Loss: [0.67032614 0.640625  ], G Loss: 0.7073765993118286\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1045, D Loss: [0.67323011 0.703125  ], G Loss: 0.7220779657363892\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1046, D Loss: [0.68187147 0.640625  ], G Loss: 0.7228258848190308\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1047, D Loss: [0.66007683 0.734375  ], G Loss: 0.7195789813995361\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1048, D Loss: [0.67058197 0.703125  ], G Loss: 0.7099236845970154\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1049, D Loss: [0.67197934 0.703125  ], G Loss: 0.7262226939201355\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1050, D Loss: [0.67697808 0.640625  ], G Loss: 0.727781355381012\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1051, D Loss: [0.66229302 0.6875    ], G Loss: 0.7335019111633301\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1052, D Loss: [0.66449234 0.71875   ], G Loss: 0.7238608002662659\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1053, D Loss: [0.67328548 0.703125  ], G Loss: 0.7305284738540649\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1054, D Loss: [0.66315022 0.703125  ], G Loss: 0.7219483852386475\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1055, D Loss: [0.68626598 0.578125  ], G Loss: 0.7220311164855957\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1056, D Loss: [0.68092564 0.640625  ], G Loss: 0.7039939165115356\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1057, D Loss: [0.65730533 0.6875    ], G Loss: 0.7037625908851624\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1058, D Loss: [0.67163879 0.703125  ], G Loss: 0.7270130515098572\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1059, D Loss: [0.6659582 0.671875 ], G Loss: 0.7230484485626221\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1060, D Loss: [0.67792138 0.6875    ], G Loss: 0.7156577706336975\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1061, D Loss: [0.66163987 0.6875    ], G Loss: 0.7237924337387085\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1062, D Loss: [0.68599513 0.578125  ], G Loss: 0.7187552452087402\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1063, D Loss: [0.66969514 0.71875   ], G Loss: 0.709896445274353\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1064, D Loss: [0.6850245 0.609375 ], G Loss: 0.7167765498161316\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1065, D Loss: [0.67341125 0.703125  ], G Loss: 0.7131941318511963\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1066, D Loss: [0.6849575 0.640625 ], G Loss: 0.7164359092712402\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1067, D Loss: [0.66721466 0.6875    ], G Loss: 0.7231779098510742\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1068, D Loss: [0.67245597 0.734375  ], G Loss: 0.7165741920471191\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1069, D Loss: [0.68552122 0.609375  ], G Loss: 0.7287145256996155\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1070, D Loss: [0.67973158 0.734375  ], G Loss: 0.7184122204780579\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1071, D Loss: [0.68803087 0.671875  ], G Loss: 0.7170868515968323\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1072, D Loss: [0.67134076 0.703125  ], G Loss: 0.7151105999946594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1073, D Loss: [0.67204541 0.671875  ], G Loss: 0.7118314504623413\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1074, D Loss: [0.67684898 0.609375  ], G Loss: 0.7150301933288574\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1075, D Loss: [0.67767432 0.65625   ], G Loss: 0.7250869274139404\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1076, D Loss: [0.6667549 0.8125   ], G Loss: 0.7165571451187134\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1077, D Loss: [0.66391128 0.734375  ], G Loss: 0.7255880832672119\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1078, D Loss: [0.67202577 0.75      ], G Loss: 0.7277990579605103\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1079, D Loss: [0.68123624 0.609375  ], G Loss: 0.7243055701255798\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1080, D Loss: [0.68678358 0.640625  ], G Loss: 0.7268980741500854\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1081, D Loss: [0.67517814 0.640625  ], G Loss: 0.7556725740432739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1082, D Loss: [0.66378182 0.734375  ], G Loss: 0.7307251691818237\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1083, D Loss: [0.68778247 0.609375  ], G Loss: 0.7398451566696167\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1084, D Loss: [0.67994386 0.578125  ], G Loss: 0.7274630069732666\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1085, D Loss: [0.69319338 0.578125  ], G Loss: 0.7327605485916138\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1086, D Loss: [0.67416182 0.609375  ], G Loss: 0.7418868541717529\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1087, D Loss: [0.67265439 0.65625   ], G Loss: 0.7391229867935181\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1088, D Loss: [0.69277355 0.578125  ], G Loss: 0.7169508934020996\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1089, D Loss: [0.67773113 0.578125  ], G Loss: 0.7501426935195923\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1090, D Loss: [0.66299915 0.640625  ], G Loss: 0.7319550514221191\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1091, D Loss: [0.66127682 0.625     ], G Loss: 0.7529687285423279\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1092, D Loss: [0.67045468 0.640625  ], G Loss: 0.7431106567382812\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1093, D Loss: [0.65568984 0.75      ], G Loss: 0.7441236972808838\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1094, D Loss: [0.68913174 0.515625  ], G Loss: 0.7367135882377625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1095, D Loss: [0.66779816 0.671875  ], G Loss: 0.7501643896102905\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1096, D Loss: [0.68925908 0.484375  ], G Loss: 0.7399562001228333\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1097, D Loss: [0.68038452 0.546875  ], G Loss: 0.7450442314147949\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1098, D Loss: [0.69072628 0.5       ], G Loss: 0.748989999294281\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1099, D Loss: [0.6643362 0.6875   ], G Loss: 0.7374364137649536\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1100, D Loss: [0.66062319 0.65625   ], G Loss: 0.750910758972168\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1101, D Loss: [0.66474843 0.59375   ], G Loss: 0.7352957725524902\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1102, D Loss: [0.69249219 0.53125   ], G Loss: 0.7412080764770508\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1103, D Loss: [0.68025488 0.5625    ], G Loss: 0.7432554960250854\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1104, D Loss: [0.66896418 0.640625  ], G Loss: 0.7375004291534424\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1105, D Loss: [0.69312197 0.40625   ], G Loss: 0.7386252880096436\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1106, D Loss: [0.66186565 0.5625    ], G Loss: 0.75038081407547\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1107, D Loss: [0.6747528 0.5625   ], G Loss: 0.7464598417282104\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1108, D Loss: [0.69106579 0.46875   ], G Loss: 0.7406816482543945\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1109, D Loss: [0.66133237 0.640625  ], G Loss: 0.7335498332977295\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1110, D Loss: [0.65251112 0.734375  ], G Loss: 0.7292662858963013\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1111, D Loss: [0.67984912 0.515625  ], G Loss: 0.7236668467521667\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1112, D Loss: [0.68044063 0.53125   ], G Loss: 0.7382082939147949\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1113, D Loss: [0.66977453 0.625     ], G Loss: 0.7468650341033936\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1114, D Loss: [0.66082376 0.65625   ], G Loss: 0.717054009437561\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1115, D Loss: [0.68852723 0.484375  ], G Loss: 0.7385818958282471\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1116, D Loss: [0.6886363 0.59375  ], G Loss: 0.735896646976471\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1117, D Loss: [0.66400802 0.703125  ], G Loss: 0.7219582200050354\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1118, D Loss: [0.68456015 0.546875  ], G Loss: 0.7203901410102844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1119, D Loss: [0.6870147 0.484375 ], G Loss: 0.7442973852157593\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1120, D Loss: [0.68266776 0.5625    ], G Loss: 0.7035698890686035\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1121, D Loss: [0.66124237 0.609375  ], G Loss: 0.7282817363739014\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1122, D Loss: [0.6761426 0.578125 ], G Loss: 0.7166562676429749\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1123, D Loss: [0.67210305 0.640625  ], G Loss: 0.7139955163002014\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1124, D Loss: [0.67608503 0.703125  ], G Loss: 0.7275142669677734\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1125, D Loss: [0.68082082 0.609375  ], G Loss: 0.7150021195411682\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1126, D Loss: [0.69291341 0.5       ], G Loss: 0.7323791980743408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1127, D Loss: [0.66738361 0.6875    ], G Loss: 0.7121244072914124\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1128, D Loss: [0.681512 0.5625  ], G Loss: 0.7247675657272339\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1129, D Loss: [0.67722562 0.640625  ], G Loss: 0.7128602862358093\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1130, D Loss: [0.6748946 0.640625 ], G Loss: 0.7200930118560791\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1131, D Loss: [0.68370998 0.53125   ], G Loss: 0.6986410617828369\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1132, D Loss: [0.68508601 0.5       ], G Loss: 0.7418344020843506\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1133, D Loss: [0.68409485 0.5625    ], G Loss: 0.7108839154243469\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1134, D Loss: [0.66851157 0.625     ], G Loss: 0.7190316915512085\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1135, D Loss: [0.68166393 0.578125  ], G Loss: 0.7176001071929932\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1136, D Loss: [0.67376319 0.6875    ], G Loss: 0.7227573990821838\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1137, D Loss: [0.68381861 0.609375  ], G Loss: 0.7105726003646851\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1138, D Loss: [0.67597729 0.65625   ], G Loss: 0.7014083862304688\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1139, D Loss: [0.68352607 0.546875  ], G Loss: 0.7174943089485168\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1140, D Loss: [0.66759801 0.53125   ], G Loss: 0.7235479354858398\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1141, D Loss: [0.69015032 0.546875  ], G Loss: 0.7244923114776611\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1142, D Loss: [0.68467689 0.53125   ], G Loss: 0.7293657064437866\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1143, D Loss: [0.68667772 0.53125   ], G Loss: 0.7222713232040405\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1144, D Loss: [0.68627888 0.59375   ], G Loss: 0.7192591428756714\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1145, D Loss: [0.67092249 0.6875    ], G Loss: 0.7259448170661926\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1146, D Loss: [0.68228292 0.53125   ], G Loss: 0.7246004343032837\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1147, D Loss: [0.67156127 0.515625  ], G Loss: 0.710989236831665\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1148, D Loss: [0.6851505 0.546875 ], G Loss: 0.7194737195968628\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1149, D Loss: [0.6833913 0.609375 ], G Loss: 0.7108750343322754\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1150, D Loss: [0.67712244 0.484375  ], G Loss: 0.7201921939849854\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1151, D Loss: [0.68648323 0.578125  ], G Loss: 0.7159212231636047\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1152, D Loss: [0.67849675 0.703125  ], G Loss: 0.727633535861969\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1153, D Loss: [0.65776497 0.71875   ], G Loss: 0.7023025751113892\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1154, D Loss: [0.68513173 0.625     ], G Loss: 0.717445433139801\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1155, D Loss: [0.67559284 0.578125  ], G Loss: 0.7154362201690674\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1156, D Loss: [0.66968724 0.609375  ], G Loss: 0.7074937224388123\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1157, D Loss: [0.68428981 0.578125  ], G Loss: 0.7115707397460938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1158, D Loss: [0.67977905 0.640625  ], G Loss: 0.7271503210067749\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1159, D Loss: [0.68182364 0.65625   ], G Loss: 0.7266631126403809\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1160, D Loss: [0.6846475 0.546875 ], G Loss: 0.711397647857666\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1161, D Loss: [0.67456973 0.671875  ], G Loss: 0.7305154800415039\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1162, D Loss: [0.66892046 0.671875  ], G Loss: 0.7270445823669434\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1163, D Loss: [0.67051283 0.671875  ], G Loss: 0.7211912870407104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1164, D Loss: [0.66176558 0.71875   ], G Loss: 0.7138742208480835\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1165, D Loss: [0.66203517 0.65625   ], G Loss: 0.7077370882034302\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1166, D Loss: [0.67661387 0.65625   ], G Loss: 0.7213976383209229\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1167, D Loss: [0.67748398 0.671875  ], G Loss: 0.7363790273666382\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1168, D Loss: [0.67466444 0.59375   ], G Loss: 0.713525652885437\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1169, D Loss: [0.68366352 0.5625    ], G Loss: 0.7112176418304443\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1170, D Loss: [0.67965078 0.609375  ], G Loss: 0.720741868019104\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1171, D Loss: [0.68006921 0.5625    ], G Loss: 0.7171123623847961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1172, D Loss: [0.66998619 0.578125  ], G Loss: 0.724077582359314\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1173, D Loss: [0.67868418 0.625     ], G Loss: 0.7200597524642944\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1174, D Loss: [0.67075786 0.515625  ], G Loss: 0.7287551164627075\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1175, D Loss: [0.67219603 0.671875  ], G Loss: 0.7035391926765442\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1176, D Loss: [0.67815399 0.609375  ], G Loss: 0.7157970666885376\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1177, D Loss: [0.6767891 0.578125 ], G Loss: 0.7242710590362549\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1178, D Loss: [0.67530367 0.546875  ], G Loss: 0.7047950029373169\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1179, D Loss: [0.67717552 0.609375  ], G Loss: 0.7371480464935303\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1180, D Loss: [0.68576944 0.546875  ], G Loss: 0.7217807769775391\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1181, D Loss: [0.67043138 0.609375  ], G Loss: 0.7188302278518677\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1182, D Loss: [0.66782153 0.8125    ], G Loss: 0.719201922416687\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1183, D Loss: [0.67280728 0.640625  ], G Loss: 0.7274780869483948\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1184, D Loss: [0.67761162 0.546875  ], G Loss: 0.7202488780021667\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1185, D Loss: [0.6728819 0.59375  ], G Loss: 0.7241570949554443\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1186, D Loss: [0.67744613 0.625     ], G Loss: 0.7356853485107422\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1187, D Loss: [0.67144367 0.65625   ], G Loss: 0.7148367166519165\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1188, D Loss: [0.67150664 0.671875  ], G Loss: 0.743765115737915\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1189, D Loss: [0.67658174 0.65625   ], G Loss: 0.7451372146606445\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1190, D Loss: [0.68077961 0.609375  ], G Loss: 0.7319604754447937\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1191, D Loss: [0.67238131 0.625     ], G Loss: 0.7250469923019409\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1192, D Loss: [0.67858002 0.578125  ], G Loss: 0.7214696407318115\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1193, D Loss: [0.67984098 0.671875  ], G Loss: 0.7322595119476318\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1194, D Loss: [0.67512  0.640625], G Loss: 0.7277441024780273\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1195, D Loss: [0.67078203 0.65625   ], G Loss: 0.7183383703231812\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1196, D Loss: [0.68095103 0.5625    ], G Loss: 0.7256848812103271\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1197, D Loss: [0.6837694 0.546875 ], G Loss: 0.73509681224823\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1198, D Loss: [0.68376574 0.59375   ], G Loss: 0.7358582019805908\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1199, D Loss: [0.65607724 0.640625  ], G Loss: 0.7178651094436646\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1200, D Loss: [0.67581278 0.609375  ], G Loss: 0.7065713405609131\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1201, D Loss: [0.68791211 0.5       ], G Loss: 0.733433723449707\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1202, D Loss: [0.66946584 0.625     ], G Loss: 0.730046808719635\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1203, D Loss: [0.68067384 0.53125   ], G Loss: 0.7108997702598572\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1204, D Loss: [0.66794506 0.640625  ], G Loss: 0.7334678173065186\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1205, D Loss: [0.67199764 0.671875  ], G Loss: 0.7078559994697571\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1206, D Loss: [0.6854066 0.53125  ], G Loss: 0.7110077142715454\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1207, D Loss: [0.67161381 0.65625   ], G Loss: 0.7295383214950562\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1208, D Loss: [0.67792958 0.578125  ], G Loss: 0.7191286087036133\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1209, D Loss: [0.66864312 0.640625  ], G Loss: 0.7048723697662354\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1210, D Loss: [0.67596751 0.671875  ], G Loss: 0.7216797471046448\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1211, D Loss: [0.68971419 0.453125  ], G Loss: 0.7194619178771973\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1212, D Loss: [0.6863997 0.515625 ], G Loss: 0.715333104133606\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1213, D Loss: [0.68003961 0.546875  ], G Loss: 0.7376242876052856\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1214, D Loss: [0.67928395 0.578125  ], G Loss: 0.7254801988601685\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1215, D Loss: [0.67909425 0.546875  ], G Loss: 0.7382237315177917\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1216, D Loss: [0.67626128 0.5625    ], G Loss: 0.7189764976501465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1217, D Loss: [0.6690118 0.578125 ], G Loss: 0.7316303849220276\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1218, D Loss: [0.66915652 0.65625   ], G Loss: 0.7164061665534973\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1219, D Loss: [0.67085046 0.625     ], G Loss: 0.718866229057312\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1220, D Loss: [0.67787668 0.59375   ], G Loss: 0.7255749702453613\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1221, D Loss: [0.69121936 0.484375  ], G Loss: 0.7303063869476318\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1222, D Loss: [0.67949623 0.578125  ], G Loss: 0.7366883158683777\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1223, D Loss: [0.6864143 0.546875 ], G Loss: 0.7559396028518677\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1224, D Loss: [1.02499282 0.4375    ], G Loss: 0.7244656085968018\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1225, D Loss: [0.68681121 0.5       ], G Loss: 0.7291361093521118\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1226, D Loss: [0.66863909 0.65625   ], G Loss: 0.7101025581359863\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1227, D Loss: [0.66531599 0.640625  ], G Loss: 0.7112038135528564\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1228, D Loss: [0.67537835 0.59375   ], G Loss: 0.7214547395706177\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1229, D Loss: [0.6710304 0.59375  ], G Loss: 0.7337647676467896\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1230, D Loss: [0.68547797 0.671875  ], G Loss: 0.713456928730011\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1231, D Loss: [0.668199 0.640625], G Loss: 0.7229872941970825\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1232, D Loss: [0.67692557 0.609375  ], G Loss: 0.7267822027206421\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1233, D Loss: [0.67291546 0.625     ], G Loss: 0.7342097759246826\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1234, D Loss: [0.66349208 0.6875    ], G Loss: 0.7301858067512512\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1235, D Loss: [0.68662992 0.625     ], G Loss: 0.7404136657714844\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1236, D Loss: [0.69453841 0.5       ], G Loss: 0.7355618476867676\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1237, D Loss: [0.67813963 0.59375   ], G Loss: 0.7413834929466248\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1238, D Loss: [0.67460158 0.546875  ], G Loss: 0.7274307012557983\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1239, D Loss: [0.67795914 0.640625  ], G Loss: 0.720532238483429\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1240, D Loss: [0.6764358 0.609375 ], G Loss: 0.7449561357498169\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1241, D Loss: [0.6892944 0.53125  ], G Loss: 0.7324725389480591\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1242, D Loss: [0.65114433 0.703125  ], G Loss: 0.7366580963134766\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1243, D Loss: [0.66980627 0.65625   ], G Loss: 0.729637622833252\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1244, D Loss: [0.67968336 0.59375   ], G Loss: 0.7272759675979614\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1245, D Loss: [0.68033198 0.609375  ], G Loss: 0.7469772696495056\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1246, D Loss: [0.67923912 0.703125  ], G Loss: 0.7291796207427979\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1247, D Loss: [0.67271438 0.609375  ], G Loss: 0.7392306923866272\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1248, D Loss: [0.68351561 0.546875  ], G Loss: 0.7421378493309021\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1249, D Loss: [0.67228502 0.578125  ], G Loss: 0.7328069806098938\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1250, D Loss: [0.66510367 0.640625  ], G Loss: 0.7400424480438232\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1251, D Loss: [0.66637552 0.578125  ], G Loss: 0.7423397302627563\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1252, D Loss: [0.66324157 0.640625  ], G Loss: 0.7464196681976318\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1253, D Loss: [0.66591963 0.625     ], G Loss: 0.7448073625564575\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1254, D Loss: [0.67005938 0.703125  ], G Loss: 0.7455332279205322\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1255, D Loss: [0.6683706 0.71875  ], G Loss: 0.7474271059036255\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1256, D Loss: [0.67678845 0.640625  ], G Loss: 0.7433713674545288\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1257, D Loss: [0.66447604 0.671875  ], G Loss: 0.7668545246124268\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1258, D Loss: [0.67507848 0.65625   ], G Loss: 0.7647818326950073\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1259, D Loss: [0.66869754 0.703125  ], G Loss: 0.7404937744140625\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1260, D Loss: [0.65877327 0.6875    ], G Loss: 0.7506723403930664\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1261, D Loss: [0.65046266 0.609375  ], G Loss: 0.7507389783859253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1262, D Loss: [0.66733947 0.640625  ], G Loss: 0.7431200742721558\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1263, D Loss: [0.66340467 0.671875  ], G Loss: 0.7401937246322632\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1264, D Loss: [0.66659921 0.6875    ], G Loss: 0.7405267953872681\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1265, D Loss: [0.67382798 0.640625  ], G Loss: 0.7420626282691956\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1266, D Loss: [0.68533459 0.578125  ], G Loss: 0.7404128313064575\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1267, D Loss: [0.68131167 0.578125  ], G Loss: 0.7482641339302063\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1268, D Loss: [0.66533318 0.59375   ], G Loss: 0.7449778318405151\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1269, D Loss: [0.67584303 0.703125  ], G Loss: 0.7437809705734253\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1270, D Loss: [0.65609521 0.71875   ], G Loss: 0.753488302230835\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1271, D Loss: [0.68368882 0.59375   ], G Loss: 0.7439680695533752\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1272, D Loss: [0.66621017 0.671875  ], G Loss: 0.7308555841445923\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1273, D Loss: [0.67426822 0.65625   ], G Loss: 0.7373602390289307\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1274, D Loss: [0.68137589 0.578125  ], G Loss: 0.743117094039917\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1275, D Loss: [0.67187554 0.640625  ], G Loss: 0.7418146133422852\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1276, D Loss: [0.67380381 0.59375   ], G Loss: 0.7259023785591125\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1277, D Loss: [0.68775919 0.5625    ], G Loss: 0.7698890566825867\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1278, D Loss: [0.67269853 0.578125  ], G Loss: 0.7519843578338623\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1279, D Loss: [0.67057523 0.734375  ], G Loss: 0.7345001697540283\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1280, D Loss: [0.66613835 0.609375  ], G Loss: 0.7276325821876526\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1281, D Loss: [0.6661624 0.65625  ], G Loss: 0.7442135214805603\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1282, D Loss: [0.67313498 0.65625   ], G Loss: 0.7449250221252441\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1283, D Loss: [0.67516631 0.6875    ], G Loss: 0.7438616752624512\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1284, D Loss: [0.91294146 0.65625   ], G Loss: 0.7279579043388367\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1285, D Loss: [0.67292294 0.71875   ], G Loss: 0.7278310060501099\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1286, D Loss: [0.67316741 0.65625   ], G Loss: 0.72857666015625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1287, D Loss: [0.66129982 0.796875  ], G Loss: 0.7268465757369995\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1288, D Loss: [0.67803955 0.625     ], G Loss: 0.7214236259460449\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1289, D Loss: [0.67241114 0.6875    ], G Loss: 0.7429313659667969\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1290, D Loss: [0.67351744 0.546875  ], G Loss: 0.7381812930107117\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1291, D Loss: [0.66476458 0.765625  ], G Loss: 0.7260593175888062\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1292, D Loss: [0.6837205 0.578125 ], G Loss: 0.7546049356460571\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1293, D Loss: [0.68592829 0.59375   ], G Loss: 0.7208198308944702\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1294, D Loss: [0.66569129 0.640625  ], G Loss: 0.7164658904075623\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1295, D Loss: [0.68117872 0.65625   ], G Loss: 0.7279205322265625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1296, D Loss: [0.65441403 0.640625  ], G Loss: 0.732160210609436\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1297, D Loss: [0.6815697 0.59375  ], G Loss: 0.7262158393859863\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1298, D Loss: [0.66955101 0.734375  ], G Loss: 0.7192783355712891\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1299, D Loss: [0.67773041 0.703125  ], G Loss: 0.7350635528564453\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1300, D Loss: [0.67021316 0.65625   ], G Loss: 0.7124125957489014\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1301, D Loss: [0.67067015 0.6875    ], G Loss: 0.7302381992340088\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1302, D Loss: [0.6722728 0.6875   ], G Loss: 0.7246239185333252\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1303, D Loss: [0.68254164 0.546875  ], G Loss: 0.7337678670883179\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1304, D Loss: [0.68820167 0.5       ], G Loss: 0.7116014957427979\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1305, D Loss: [0.6669029 0.6875   ], G Loss: 0.7080495357513428\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1306, D Loss: [0.68832523 0.59375   ], G Loss: 0.7189043164253235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1307, D Loss: [0.68167183 0.65625   ], G Loss: 0.7291244268417358\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1308, D Loss: [0.67329681 0.703125  ], G Loss: 0.7287746071815491\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1309, D Loss: [0.67897338 0.6875    ], G Loss: 0.7183799743652344\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1310, D Loss: [0.67368713 0.59375   ], G Loss: 0.7276092767715454\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1311, D Loss: [0.67147362 0.6875    ], G Loss: 0.7261689901351929\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1312, D Loss: [0.65934867 0.671875  ], G Loss: 0.728845477104187\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1313, D Loss: [0.66355532 0.734375  ], G Loss: 0.7326124906539917\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1314, D Loss: [0.64830962 0.75      ], G Loss: 0.7039896249771118\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1315, D Loss: [0.65909743 0.734375  ], G Loss: 0.7181767225265503\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1316, D Loss: [0.65640938 0.734375  ], G Loss: 0.7342132329940796\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1317, D Loss: [0.67323679 0.65625   ], G Loss: 0.7273557186126709\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1318, D Loss: [0.66316295 0.765625  ], G Loss: 0.7131156325340271\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1319, D Loss: [0.6724059 0.6875   ], G Loss: 0.718919575214386\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1320, D Loss: [0.66291851 0.734375  ], G Loss: 0.720916748046875\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1321, D Loss: [0.66310778 0.6875    ], G Loss: 0.7179694175720215\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1322, D Loss: [0.66410142 0.6875    ], G Loss: 0.729812741279602\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1323, D Loss: [0.66763115 0.703125  ], G Loss: 0.7282689809799194\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1324, D Loss: [0.65727237 0.734375  ], G Loss: 0.7420328259468079\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1325, D Loss: [0.66358417 0.71875   ], G Loss: 0.7269587516784668\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1326, D Loss: [0.65503722 0.671875  ], G Loss: 0.7324844598770142\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1327, D Loss: [0.67390105 0.671875  ], G Loss: 0.7243719100952148\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1328, D Loss: [0.66384524 0.640625  ], G Loss: 0.7262904644012451\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1329, D Loss: [0.66740757 0.65625   ], G Loss: 0.7545050978660583\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1330, D Loss: [0.67471498 0.671875  ], G Loss: 0.7419814467430115\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1331, D Loss: [0.67642242 0.6875    ], G Loss: 0.7216283679008484\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1332, D Loss: [0.67132482 0.65625   ], G Loss: 0.7371616959571838\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1333, D Loss: [0.67330256 0.625     ], G Loss: 0.738702118396759\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1334, D Loss: [0.67458418 0.6875    ], G Loss: 0.7518496513366699\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1335, D Loss: [0.6864875 0.59375  ], G Loss: 0.7400505542755127\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1336, D Loss: [0.6655736 0.671875 ], G Loss: 0.7246425151824951\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1337, D Loss: [0.6599406 0.671875 ], G Loss: 0.7278925180435181\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1338, D Loss: [0.68072712 0.640625  ], G Loss: 0.724885106086731\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1339, D Loss: [0.67191815 0.71875   ], G Loss: 0.7492582201957703\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1340, D Loss: [0.68693748 0.5625    ], G Loss: 0.7298085689544678\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1341, D Loss: [0.68804803 0.625     ], G Loss: 0.7396230697631836\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1342, D Loss: [0.67205286 0.671875  ], G Loss: 0.7323318123817444\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1343, D Loss: [0.69075468 0.625     ], G Loss: 0.7287313342094421\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1344, D Loss: [0.67381498 0.71875   ], G Loss: 0.7324953079223633\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1345, D Loss: [0.67730802 0.671875  ], G Loss: 0.7572498917579651\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1346, D Loss: [0.66992369 0.671875  ], G Loss: 0.7335147857666016\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1347, D Loss: [0.66830671 0.71875   ], G Loss: 0.7412945628166199\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1348, D Loss: [0.66215622 0.703125  ], G Loss: 0.7416379451751709\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1349, D Loss: [0.66956794 0.65625   ], G Loss: 0.7441741228103638\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1350, D Loss: [0.68568131 0.578125  ], G Loss: 0.7386573553085327\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1351, D Loss: [0.66760761 0.671875  ], G Loss: 0.7487061619758606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1352, D Loss: [0.65174198 0.734375  ], G Loss: 0.7365188002586365\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1353, D Loss: [0.66659692 0.640625  ], G Loss: 0.7286320924758911\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1354, D Loss: [0.65351626 0.765625  ], G Loss: 0.7489825487136841\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1355, D Loss: [0.66393265 0.625     ], G Loss: 0.7428017854690552\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1356, D Loss: [0.66534758 0.765625  ], G Loss: 0.7301232814788818\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1357, D Loss: [0.6803934 0.65625  ], G Loss: 0.7454515695571899\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1358, D Loss: [0.66047707 0.71875   ], G Loss: 0.7603286504745483\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1359, D Loss: [0.67382318 0.71875   ], G Loss: 0.7382163405418396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1360, D Loss: [0.68379721 0.609375  ], G Loss: 0.737610936164856\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1361, D Loss: [0.65531039 0.71875   ], G Loss: 0.7598865032196045\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1362, D Loss: [0.67535076 0.640625  ], G Loss: 0.7462453842163086\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1363, D Loss: [0.66083619 0.765625  ], G Loss: 0.737037181854248\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1364, D Loss: [0.66692063 0.71875   ], G Loss: 0.7327077388763428\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1365, D Loss: [0.65126699 0.765625  ], G Loss: 0.735797643661499\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1366, D Loss: [0.67143279 0.640625  ], G Loss: 0.7219064831733704\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1367, D Loss: [0.67031443 0.671875  ], G Loss: 0.7488929629325867\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1368, D Loss: [0.67330009 0.609375  ], G Loss: 0.7357552647590637\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1369, D Loss: [0.66961142 0.625     ], G Loss: 0.7301166653633118\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1370, D Loss: [0.66740239 0.671875  ], G Loss: 0.7357704639434814\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1371, D Loss: [0.66866079 0.671875  ], G Loss: 0.7519809603691101\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1372, D Loss: [0.66993791 0.65625   ], G Loss: 0.7185301184654236\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1373, D Loss: [0.67768785 0.609375  ], G Loss: 0.7290172576904297\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1374, D Loss: [0.65792495 0.71875   ], G Loss: 0.7388912439346313\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1375, D Loss: [0.67388541 0.6875    ], G Loss: 0.7253275513648987\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1376, D Loss: [0.67605981 0.65625   ], G Loss: 0.7320014834403992\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1377, D Loss: [0.68280262 0.625     ], G Loss: 0.7163326740264893\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1378, D Loss: [0.66463906 0.734375  ], G Loss: 0.7232052087783813\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1379, D Loss: [0.67512721 0.640625  ], G Loss: 0.7265313267707825\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1380, D Loss: [0.69809291 0.5625    ], G Loss: 0.7149626016616821\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1381, D Loss: [0.658981 0.65625 ], G Loss: 0.71820068359375\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1382, D Loss: [0.65881348 0.671875  ], G Loss: 0.7280051708221436\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1383, D Loss: [0.65750587 0.78125   ], G Loss: 0.7316526770591736\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1384, D Loss: [0.66460729 0.671875  ], G Loss: 0.7258325815200806\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1385, D Loss: [0.66135418 0.65625   ], G Loss: 0.7303890585899353\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1386, D Loss: [0.66358715 0.703125  ], G Loss: 0.7193424105644226\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1387, D Loss: [0.66664946 0.671875  ], G Loss: 0.7369153499603271\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1388, D Loss: [0.67130604 0.65625   ], G Loss: 0.7208887338638306\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1389, D Loss: [0.6824868 0.578125 ], G Loss: 0.7408342361450195\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1390, D Loss: [0.67833126 0.609375  ], G Loss: 0.7367441654205322\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1391, D Loss: [0.65148994 0.734375  ], G Loss: 0.7362502813339233\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1392, D Loss: [0.66905117 0.6875    ], G Loss: 0.7333818674087524\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1393, D Loss: [0.6641638 0.703125 ], G Loss: 0.7273391485214233\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1394, D Loss: [0.66107106 0.75      ], G Loss: 0.7260862588882446\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1395, D Loss: [0.66449159 0.75      ], G Loss: 0.7443541288375854\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1396, D Loss: [0.67721111 0.734375  ], G Loss: 0.7127265930175781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1397, D Loss: [0.65842116 0.703125  ], G Loss: 0.7270967960357666\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1398, D Loss: [0.6763607 0.65625  ], G Loss: 0.7275550961494446\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1399, D Loss: [0.67205477 0.71875   ], G Loss: 0.7256041765213013\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1400, D Loss: [0.67488021 0.640625  ], G Loss: 0.7404466867446899\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1401, D Loss: [0.66004953 0.75      ], G Loss: 0.7364375591278076\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1402, D Loss: [0.67638344 0.65625   ], G Loss: 0.7293039560317993\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1403, D Loss: [0.6662755 0.703125 ], G Loss: 0.7441672682762146\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1404, D Loss: [0.67365128 0.703125  ], G Loss: 0.7162027955055237\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1405, D Loss: [0.67457622 0.703125  ], G Loss: 0.7423117160797119\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1406, D Loss: [0.67469323 0.625     ], G Loss: 0.7359497547149658\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1407, D Loss: [0.65054736 0.734375  ], G Loss: 0.7205502986907959\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1408, D Loss: [0.64897853 0.703125  ], G Loss: 0.7280631065368652\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1409, D Loss: [0.67827597 0.640625  ], G Loss: 0.7331297397613525\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1410, D Loss: [0.66109267 0.65625   ], G Loss: 0.733475923538208\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1411, D Loss: [0.67391074 0.609375  ], G Loss: 0.7502740621566772\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1412, D Loss: [0.66398144 0.75      ], G Loss: 0.7395039796829224\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1413, D Loss: [0.66701362 0.71875   ], G Loss: 0.7241348028182983\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1414, D Loss: [0.66537547 0.6875    ], G Loss: 0.7344381809234619\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1415, D Loss: [0.65802982 0.703125  ], G Loss: 0.7199651002883911\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1416, D Loss: [0.67171118 0.671875  ], G Loss: 0.7196187973022461\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1417, D Loss: [0.66784897 0.75      ], G Loss: 0.7235779762268066\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1418, D Loss: [0.66817266 0.6875    ], G Loss: 0.7379250526428223\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1419, D Loss: [0.65598407 0.71875   ], G Loss: 0.7373555898666382\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1420, D Loss: [0.66978052 0.78125   ], G Loss: 0.7184818387031555\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1421, D Loss: [0.66158286 0.703125  ], G Loss: 0.7374526262283325\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1422, D Loss: [0.67198306 0.703125  ], G Loss: 0.7137422561645508\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1423, D Loss: [0.67900592 0.625     ], G Loss: 0.7318373918533325\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1424, D Loss: [0.66941819 0.703125  ], G Loss: 0.7427183389663696\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1425, D Loss: [0.6505881 0.765625 ], G Loss: 0.716865062713623\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1426, D Loss: [0.67378929 0.6875    ], G Loss: 0.7488001585006714\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1427, D Loss: [0.66112122 0.65625   ], G Loss: 0.7269824147224426\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1428, D Loss: [0.69080165 0.703125  ], G Loss: 0.7367649078369141\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1429, D Loss: [0.67915332 0.671875  ], G Loss: 0.7440696358680725\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1430, D Loss: [0.6597563 0.65625  ], G Loss: 0.7335501909255981\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1431, D Loss: [0.63629657 0.78125   ], G Loss: 0.749468207359314\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1432, D Loss: [0.66642544 0.625     ], G Loss: 0.7484289407730103\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1433, D Loss: [0.67250317 0.640625  ], G Loss: 0.740949273109436\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1434, D Loss: [0.65914762 0.703125  ], G Loss: 0.7102261781692505\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1435, D Loss: [0.65747842 0.703125  ], G Loss: 0.7359262704849243\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1436, D Loss: [0.6683251 0.671875 ], G Loss: 0.7413405179977417\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1437, D Loss: [0.68143862 0.625     ], G Loss: 0.7362327575683594\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1438, D Loss: [0.64842689 0.734375  ], G Loss: 0.7386181354522705\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1439, D Loss: [0.66182238 0.78125   ], G Loss: 0.7325706481933594\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1440, D Loss: [0.66792756 0.71875   ], G Loss: 0.7329681515693665\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1441, D Loss: [0.64805013 0.6875    ], G Loss: 0.7378568649291992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1442, D Loss: [0.66592023 0.703125  ], G Loss: 0.7357648611068726\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1443, D Loss: [0.67142209 0.734375  ], G Loss: 0.746946394443512\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1444, D Loss: [0.67979032 0.640625  ], G Loss: 0.7236995100975037\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1445, D Loss: [0.68564099 0.71875   ], G Loss: 0.7410156726837158\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1446, D Loss: [0.67784107 0.625     ], G Loss: 0.755381166934967\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1447, D Loss: [0.68168625 0.640625  ], G Loss: 0.719614565372467\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1448, D Loss: [0.66773021 0.71875   ], G Loss: 0.7217167615890503\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1449, D Loss: [0.67066658 0.734375  ], G Loss: 0.7317062616348267\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1450, D Loss: [0.67603377 0.75      ], G Loss: 0.7381913661956787\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1451, D Loss: [0.6727986 0.6875   ], G Loss: 0.7459737062454224\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1452, D Loss: [0.66052976 0.640625  ], G Loss: 0.7306972742080688\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1453, D Loss: [0.67038354 0.640625  ], G Loss: 0.7423840761184692\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1454, D Loss: [0.67556781 0.65625   ], G Loss: 0.7467651963233948\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1455, D Loss: [0.67604721 0.703125  ], G Loss: 0.7278765439987183\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1456, D Loss: [0.64610368 0.78125   ], G Loss: 0.7321289777755737\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1457, D Loss: [0.68886012 0.578125  ], G Loss: 0.726443886756897\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1458, D Loss: [0.64529169 0.75      ], G Loss: 0.7320284843444824\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1459, D Loss: [0.66268528 0.6875    ], G Loss: 0.7434094548225403\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1460, D Loss: [0.68263167 0.78125   ], G Loss: 0.7449378371238708\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1461, D Loss: [0.65323508 0.671875  ], G Loss: 0.7531262040138245\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1462, D Loss: [0.69136971 0.625     ], G Loss: 0.7508193254470825\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1463, D Loss: [0.67099923 0.640625  ], G Loss: 0.767082691192627\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1464, D Loss: [0.67496952 0.640625  ], G Loss: 0.7438932657241821\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1465, D Loss: [0.66680294 0.78125   ], G Loss: 0.7339170575141907\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1466, D Loss: [0.64518988 0.703125  ], G Loss: 0.7237756252288818\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1467, D Loss: [0.66691762 0.71875   ], G Loss: 0.7473257780075073\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1468, D Loss: [0.65067247 0.765625  ], G Loss: 0.7409446835517883\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1469, D Loss: [0.66543382 0.6875    ], G Loss: 0.7597548365592957\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1470, D Loss: [0.67648503 0.65625   ], G Loss: 0.7446730732917786\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1471, D Loss: [0.67227536 0.6875    ], G Loss: 0.7436095476150513\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1472, D Loss: [0.67783421 0.75      ], G Loss: 0.7386000752449036\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1473, D Loss: [0.66400462 0.734375  ], G Loss: 0.7404651641845703\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1474, D Loss: [0.67767179 0.625     ], G Loss: 0.7534750699996948\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1475, D Loss: [0.66375127 0.734375  ], G Loss: 0.7514950633049011\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1476, D Loss: [0.657437 0.734375], G Loss: 0.7285212278366089\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1477, D Loss: [0.65084928 0.765625  ], G Loss: 0.7317099571228027\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1478, D Loss: [0.66981491 0.671875  ], G Loss: 0.7511159181594849\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1479, D Loss: [0.67468667 0.640625  ], G Loss: 0.7421050667762756\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1480, D Loss: [0.66908813 0.65625   ], G Loss: 0.7571394443511963\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1481, D Loss: [0.65807709 0.671875  ], G Loss: 0.7350325584411621\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1482, D Loss: [0.64502132 0.75      ], G Loss: 0.763019859790802\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1483, D Loss: [0.65897426 0.671875  ], G Loss: 0.7447210550308228\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1484, D Loss: [0.65738899 0.625     ], G Loss: 0.7579876184463501\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1485, D Loss: [0.68250641 0.65625   ], G Loss: 0.751131534576416\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1486, D Loss: [0.64827281 0.8125    ], G Loss: 0.744398832321167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1487, D Loss: [0.66064703 0.65625   ], G Loss: 0.7457314133644104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1488, D Loss: [0.69102892 0.609375  ], G Loss: 0.7328945398330688\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1489, D Loss: [0.67683315 0.5625    ], G Loss: 0.7340874671936035\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1490, D Loss: [0.6802828 0.546875 ], G Loss: 0.7672877907752991\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1491, D Loss: [0.65829018 0.671875  ], G Loss: 0.7417032718658447\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1492, D Loss: [0.67367119 0.59375   ], G Loss: 0.7245000004768372\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1493, D Loss: [0.66960746 0.71875   ], G Loss: 0.736240029335022\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1494, D Loss: [0.68323463 0.578125  ], G Loss: 0.7675466537475586\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1495, D Loss: [0.67884207 0.578125  ], G Loss: 0.7360796928405762\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1496, D Loss: [0.66754144 0.671875  ], G Loss: 0.7361685037612915\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1497, D Loss: [0.65408489 0.765625  ], G Loss: 0.7275376915931702\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1498, D Loss: [0.66357496 0.703125  ], G Loss: 0.7477896213531494\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1499, D Loss: [0.65554661 0.734375  ], G Loss: 0.7518643736839294\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1500, D Loss: [0.66566887 0.65625   ], G Loss: 0.7334346175193787\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1501, D Loss: [0.66373739 0.671875  ], G Loss: 0.7305070161819458\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1502, D Loss: [0.64689779 0.703125  ], G Loss: 0.7626453638076782\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1503, D Loss: [0.67798361 0.609375  ], G Loss: 0.7271569967269897\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1504, D Loss: [0.65646714 0.703125  ], G Loss: 0.7402166724205017\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1505, D Loss: [0.67331019 0.640625  ], G Loss: 0.7456885576248169\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1506, D Loss: [0.65179539 0.8125    ], G Loss: 0.7475647926330566\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1507, D Loss: [0.68284488 0.640625  ], G Loss: 0.7405756711959839\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1508, D Loss: [0.67250165 0.65625   ], G Loss: 0.7388747930526733\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1509, D Loss: [0.64830083 0.796875  ], G Loss: 0.7435863018035889\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1510, D Loss: [0.68048972 0.734375  ], G Loss: 0.7468312978744507\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1511, D Loss: [0.66553402 0.6875    ], G Loss: 0.7378137111663818\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1512, D Loss: [0.66489276 0.703125  ], G Loss: 0.7303892970085144\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1513, D Loss: [0.67135864 0.765625  ], G Loss: 0.7367422580718994\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1514, D Loss: [0.66067982 0.765625  ], G Loss: 0.7480530738830566\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1515, D Loss: [0.64504579 0.765625  ], G Loss: 0.7543677091598511\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1516, D Loss: [0.67086792 0.6875    ], G Loss: 0.7604308128356934\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1517, D Loss: [0.6518054 0.734375 ], G Loss: 0.7622228264808655\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1518, D Loss: [0.68261027 0.640625  ], G Loss: 0.7591202259063721\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1519, D Loss: [0.64529258 0.75      ], G Loss: 0.7472106218338013\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1520, D Loss: [0.66250893 0.71875   ], G Loss: 0.7606388330459595\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1521, D Loss: [0.65960234 0.703125  ], G Loss: 0.7595552206039429\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1522, D Loss: [0.65745485 0.71875   ], G Loss: 0.7384765148162842\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1523, D Loss: [0.66085249 0.75      ], G Loss: 0.7544116973876953\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1524, D Loss: [0.68719748 0.578125  ], G Loss: 0.7491700053215027\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1525, D Loss: [0.66406187 0.6875    ], G Loss: 0.728995680809021\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1526, D Loss: [0.66281191 0.6875    ], G Loss: 0.7399333715438843\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1527, D Loss: [0.64841375 0.703125  ], G Loss: 0.7575864791870117\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1528, D Loss: [0.65663758 0.78125   ], G Loss: 0.7251114249229431\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1529, D Loss: [0.66490337 0.734375  ], G Loss: 0.7311116456985474\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1530, D Loss: [0.67072606 0.609375  ], G Loss: 0.7594337463378906\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1531, D Loss: [0.67113954 0.703125  ], G Loss: 0.7440063953399658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1532, D Loss: [0.66309631 0.671875  ], G Loss: 0.7340943813323975\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1533, D Loss: [0.66617072 0.765625  ], G Loss: 0.7641342878341675\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1534, D Loss: [0.66317016 0.71875   ], G Loss: 0.7773795127868652\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1535, D Loss: [0.64681199 0.828125  ], G Loss: 0.7386850118637085\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1536, D Loss: [0.67732644 0.65625   ], G Loss: 0.7534421682357788\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1537, D Loss: [0.66437858 0.671875  ], G Loss: 0.7390068769454956\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1538, D Loss: [0.65360534 0.75      ], G Loss: 0.7341373562812805\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1539, D Loss: [0.66967428 0.609375  ], G Loss: 0.7261425256729126\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1540, D Loss: [0.66523251 0.640625  ], G Loss: 0.741591215133667\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1541, D Loss: [0.65675473 0.703125  ], G Loss: 0.7317633628845215\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1542, D Loss: [0.66909471 0.6875    ], G Loss: 0.7424479722976685\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1543, D Loss: [0.67110008 0.65625   ], G Loss: 0.7243119478225708\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1544, D Loss: [0.65088233 0.734375  ], G Loss: 0.7419612407684326\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1545, D Loss: [0.66515443 0.71875   ], G Loss: 0.7330195903778076\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1546, D Loss: [0.64973941 0.78125   ], G Loss: 0.7268004417419434\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1547, D Loss: [0.66091731 0.765625  ], G Loss: 0.7196566462516785\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1548, D Loss: [0.65185145 0.71875   ], G Loss: 0.7298439741134644\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1549, D Loss: [0.68973958 0.5625    ], G Loss: 0.7369441986083984\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1550, D Loss: [0.66901511 0.671875  ], G Loss: 0.7421026229858398\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1551, D Loss: [0.65544254 0.671875  ], G Loss: 0.7317451238632202\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1552, D Loss: [0.65290612 0.75      ], G Loss: 0.7314574718475342\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1553, D Loss: [0.66192171 0.671875  ], G Loss: 0.7340564727783203\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1554, D Loss: [0.65672946 0.734375  ], G Loss: 0.764761209487915\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1555, D Loss: [0.64309356 0.765625  ], G Loss: 0.7298669815063477\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1556, D Loss: [0.64973697 0.796875  ], G Loss: 0.7395147085189819\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1557, D Loss: [0.67200664 0.609375  ], G Loss: 0.7435517311096191\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1558, D Loss: [0.66430014 0.71875   ], G Loss: 0.7291259169578552\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1559, D Loss: [0.66012877 0.71875   ], G Loss: 0.7416574954986572\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1560, D Loss: [0.64856926 0.734375  ], G Loss: 0.7297846078872681\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1561, D Loss: [0.67246473 0.625     ], G Loss: 0.7351452708244324\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1562, D Loss: [0.6445474 0.859375 ], G Loss: 0.7246885299682617\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1563, D Loss: [0.67001784 0.703125  ], G Loss: 0.7338876724243164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1564, D Loss: [0.66706747 0.640625  ], G Loss: 0.7284835577011108\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1565, D Loss: [0.65936321 0.75      ], G Loss: 0.7362200617790222\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1566, D Loss: [0.67224425 0.625     ], G Loss: 0.7388037443161011\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1567, D Loss: [0.63277811 0.84375   ], G Loss: 0.7414258122444153\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1568, D Loss: [0.6638757 0.640625 ], G Loss: 0.7330501675605774\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1569, D Loss: [0.66716447 0.703125  ], G Loss: 0.7268609404563904\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1570, D Loss: [0.67443073 0.71875   ], G Loss: 0.7365878820419312\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1571, D Loss: [0.66918963 0.71875   ], G Loss: 0.7423559427261353\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1572, D Loss: [0.64932865 0.734375  ], G Loss: 0.7273334860801697\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1573, D Loss: [0.68211022 0.640625  ], G Loss: 0.7286977767944336\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1574, D Loss: [0.64301062 0.734375  ], G Loss: 0.7442959547042847\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1575, D Loss: [0.67022961 0.671875  ], G Loss: 0.7386699914932251\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1576, D Loss: [0.67774397 0.640625  ], G Loss: 0.7342666387557983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1577, D Loss: [0.6543498 0.703125 ], G Loss: 0.7327451705932617\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1578, D Loss: [0.68225941 0.609375  ], G Loss: 0.7464129328727722\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1579, D Loss: [0.67903239 0.671875  ], G Loss: 0.7463006973266602\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1580, D Loss: [0.66492569 0.6875    ], G Loss: 0.737557590007782\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1581, D Loss: [0.6471906 0.75     ], G Loss: 0.7427453994750977\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1582, D Loss: [0.69144386 0.640625  ], G Loss: 0.7479472756385803\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1583, D Loss: [0.65814582 0.640625  ], G Loss: 0.748997688293457\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1584, D Loss: [0.88150722 0.640625  ], G Loss: 0.7244345545768738\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1585, D Loss: [0.65534693 0.765625  ], G Loss: 0.7334883213043213\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1586, D Loss: [0.64831123 0.578125  ], G Loss: 0.7193002700805664\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1587, D Loss: [0.67047864 0.703125  ], G Loss: 0.7207221984863281\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1588, D Loss: [0.65606806 0.6875    ], G Loss: 0.7277714610099792\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1589, D Loss: [0.65931085 0.6875    ], G Loss: 0.7380840182304382\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1590, D Loss: [0.65785462 0.71875   ], G Loss: 0.7465333938598633\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1591, D Loss: [0.66374305 0.75      ], G Loss: 0.7253187894821167\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1592, D Loss: [0.63636196 0.734375  ], G Loss: 0.7374309301376343\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1593, D Loss: [0.6563122 0.734375 ], G Loss: 0.7302834987640381\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1594, D Loss: [0.65666774 0.734375  ], G Loss: 0.7315841913223267\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1595, D Loss: [0.64659339 0.8125    ], G Loss: 0.7370088696479797\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1596, D Loss: [0.64843127 0.75      ], G Loss: 0.7235191464424133\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1597, D Loss: [0.65310615 0.765625  ], G Loss: 0.7218290567398071\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1598, D Loss: [0.66290382 0.703125  ], G Loss: 0.7354235649108887\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1599, D Loss: [0.65850452 0.765625  ], G Loss: 0.7191439867019653\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1600, D Loss: [0.65171641 0.6875    ], G Loss: 0.7169939875602722\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1601, D Loss: [0.67496097 0.65625   ], G Loss: 0.7370719313621521\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1602, D Loss: [0.65081719 0.765625  ], G Loss: 0.7181106805801392\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1603, D Loss: [0.63711706 0.84375   ], G Loss: 0.7226322293281555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1604, D Loss: [0.63220084 0.828125  ], G Loss: 0.7435330152511597\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1605, D Loss: [0.68304032 0.703125  ], G Loss: 0.7267172336578369\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1606, D Loss: [0.65953711 0.765625  ], G Loss: 0.7287971377372742\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1607, D Loss: [0.65908507 0.765625  ], G Loss: 0.7614477872848511\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1608, D Loss: [0.65855151 0.671875  ], G Loss: 0.7426918745040894\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1609, D Loss: [0.66006234 0.640625  ], G Loss: 0.7306408286094666\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1610, D Loss: [0.65170807 0.671875  ], G Loss: 0.7382233142852783\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1611, D Loss: [0.6469475 0.75     ], G Loss: 0.7611045241355896\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1612, D Loss: [0.64922565 0.71875   ], G Loss: 0.7385596036911011\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1613, D Loss: [0.63424543 0.78125   ], G Loss: 0.7360755205154419\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1614, D Loss: [0.65519381 0.71875   ], G Loss: 0.7348294258117676\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1615, D Loss: [0.65815857 0.703125  ], G Loss: 0.7432198524475098\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1616, D Loss: [0.66447487 0.671875  ], G Loss: 0.7381588220596313\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1617, D Loss: [0.79210263 0.640625  ], G Loss: 0.7414084672927856\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1618, D Loss: [0.66209438 0.609375  ], G Loss: 0.7373989224433899\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1619, D Loss: [0.63706148 0.71875   ], G Loss: 0.7240493297576904\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1620, D Loss: [0.66862816 0.671875  ], G Loss: 0.7282577753067017\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1621, D Loss: [0.64855891 0.765625  ], G Loss: 0.7291567921638489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1622, D Loss: [0.65048164 0.65625   ], G Loss: 0.7349668741226196\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1623, D Loss: [0.68164143 0.640625  ], G Loss: 0.7212420105934143\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1624, D Loss: [0.64540011 0.796875  ], G Loss: 0.7210407257080078\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1625, D Loss: [0.63799509 0.65625   ], G Loss: 0.7433544397354126\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1626, D Loss: [0.65070182 0.625     ], G Loss: 0.7407057285308838\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1627, D Loss: [0.65394866 0.734375  ], G Loss: 0.7372702956199646\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1628, D Loss: [0.65809932 0.6875    ], G Loss: 0.744964063167572\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1629, D Loss: [0.6586042 0.578125 ], G Loss: 0.7413812875747681\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1630, D Loss: [0.64858234 0.6875    ], G Loss: 0.7281085848808289\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1631, D Loss: [0.66011024 0.734375  ], G Loss: 0.7335320115089417\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1632, D Loss: [0.66358545 0.734375  ], G Loss: 0.7334115505218506\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1633, D Loss: [0.64724895 0.640625  ], G Loss: 0.7572437524795532\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1634, D Loss: [0.6350874 0.765625 ], G Loss: 0.723731517791748\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1635, D Loss: [0.65544671 0.609375  ], G Loss: 0.7474333047866821\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1636, D Loss: [0.65886974 0.71875   ], G Loss: 0.7273727655410767\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1637, D Loss: [0.66718358 0.65625   ], G Loss: 0.7236855626106262\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1638, D Loss: [0.65430087 0.71875   ], G Loss: 0.7232909202575684\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1639, D Loss: [0.67571256 0.609375  ], G Loss: 0.7471812963485718\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1640, D Loss: [0.65319723 0.671875  ], G Loss: 0.7338312268257141\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1641, D Loss: [0.65316582 0.78125   ], G Loss: 0.7311922311782837\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1642, D Loss: [0.6710541 0.671875 ], G Loss: 0.7409937381744385\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1643, D Loss: [0.65610155 0.734375  ], G Loss: 0.7282613515853882\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1644, D Loss: [0.64477682 0.71875   ], G Loss: 0.7444315552711487\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1645, D Loss: [0.65618116 0.625     ], G Loss: 0.7234700918197632\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1646, D Loss: [0.65281108 0.71875   ], G Loss: 0.7471426129341125\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1647, D Loss: [0.65924266 0.6875    ], G Loss: 0.7326339483261108\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1648, D Loss: [0.64924774 0.6875    ], G Loss: 0.7193707227706909\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1649, D Loss: [0.65773523 0.734375  ], G Loss: 0.7243233323097229\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1650, D Loss: [0.65854752 0.71875   ], G Loss: 0.7224463224411011\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1651, D Loss: [0.67815816 0.65625   ], G Loss: 0.739290714263916\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1652, D Loss: [0.65906987 0.625     ], G Loss: 0.7318642139434814\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1653, D Loss: [0.66679543 0.6875    ], G Loss: 0.7376993298530579\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1654, D Loss: [0.6684342 0.640625 ], G Loss: 0.716500997543335\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1655, D Loss: [0.66496748 0.703125  ], G Loss: 0.7363778948783875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1656, D Loss: [0.65580276 0.625     ], G Loss: 0.7178342938423157\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1657, D Loss: [0.64597249 0.671875  ], G Loss: 0.7391424775123596\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1658, D Loss: [0.67375684 0.65625   ], G Loss: 0.7301832437515259\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1659, D Loss: [0.65771401 0.75      ], G Loss: 0.7232334613800049\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1660, D Loss: [0.65745711 0.75      ], G Loss: 0.7354789972305298\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1661, D Loss: [0.65478018 0.6875    ], G Loss: 0.7503076791763306\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1662, D Loss: [0.66888773 0.609375  ], G Loss: 0.7344956398010254\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1663, D Loss: [0.64718235 0.703125  ], G Loss: 0.7492799162864685\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1664, D Loss: [0.67508519 0.640625  ], G Loss: 0.7105401754379272\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1665, D Loss: [0.67787108 0.6875    ], G Loss: 0.7178722023963928\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1666, D Loss: [0.66264275 0.6875    ], G Loss: 0.7201516628265381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1667, D Loss: [0.67969778 0.609375  ], G Loss: 0.7224844098091125\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1668, D Loss: [0.68493867 0.578125  ], G Loss: 0.7384341955184937\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1669, D Loss: [0.66871989 0.59375   ], G Loss: 0.7294594049453735\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1670, D Loss: [0.66732284 0.640625  ], G Loss: 0.7432713508605957\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1671, D Loss: [0.66372174 0.765625  ], G Loss: 0.7418745160102844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1672, D Loss: [0.66701406 0.6875    ], G Loss: 0.7294857501983643\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1673, D Loss: [0.65040493 0.71875   ], G Loss: 0.724402904510498\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1674, D Loss: [0.66403967 0.6875    ], G Loss: 0.7259782552719116\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1675, D Loss: [0.66647065 0.609375  ], G Loss: 0.7290860414505005\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1676, D Loss: [0.6579847 0.6875   ], G Loss: 0.7356265783309937\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1677, D Loss: [0.66627204 0.671875  ], G Loss: 0.7436338663101196\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1678, D Loss: [0.65134448 0.703125  ], G Loss: 0.7590116262435913\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1679, D Loss: [0.62600905 0.78125   ], G Loss: 0.7289849519729614\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1680, D Loss: [0.64242914 0.765625  ], G Loss: 0.7409389019012451\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1681, D Loss: [0.64268503 0.78125   ], G Loss: 0.7235398292541504\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1682, D Loss: [0.63869864 0.78125   ], G Loss: 0.7140496373176575\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1683, D Loss: [0.64613533 0.671875  ], G Loss: 0.7478587031364441\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1684, D Loss: [0.66458902 0.59375   ], G Loss: 0.7366040349006653\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1685, D Loss: [0.66429788 0.65625   ], G Loss: 0.7277737259864807\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1686, D Loss: [0.64625311 0.71875   ], G Loss: 0.7324177026748657\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1687, D Loss: [0.64596218 0.765625  ], G Loss: 0.7351374626159668\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1688, D Loss: [0.64138228 0.640625  ], G Loss: 0.7012337446212769\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1689, D Loss: [0.65419635 0.640625  ], G Loss: 0.7139725685119629\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1690, D Loss: [0.67921445 0.53125   ], G Loss: 0.7229121923446655\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1691, D Loss: [0.66794932 0.671875  ], G Loss: 0.7167940735816956\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1692, D Loss: [0.68245983 0.578125  ], G Loss: 0.7518932819366455\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1693, D Loss: [0.66222024 0.640625  ], G Loss: 0.7375750541687012\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1694, D Loss: [0.66096565 0.671875  ], G Loss: 0.7175314426422119\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1695, D Loss: [0.66396445 0.609375  ], G Loss: 0.7354527711868286\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1696, D Loss: [0.65900889 0.6875    ], G Loss: 0.735211193561554\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1697, D Loss: [0.69343489 0.515625  ], G Loss: 0.7404357194900513\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1698, D Loss: [0.66723663 0.71875   ], G Loss: 0.7410814166069031\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1699, D Loss: [0.65726128 0.65625   ], G Loss: 0.7474288940429688\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1700, D Loss: [0.65764764 0.65625   ], G Loss: 0.7452508211135864\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1701, D Loss: [0.68175185 0.609375  ], G Loss: 0.7640227675437927\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1702, D Loss: [0.67185193 0.609375  ], G Loss: 0.7389009594917297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1703, D Loss: [0.64051932 0.6875    ], G Loss: 0.7483144998550415\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1704, D Loss: [0.66747698 0.703125  ], G Loss: 0.7503042221069336\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1705, D Loss: [0.68256864 0.5625    ], G Loss: 0.7483479976654053\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1706, D Loss: [0.66090235 0.6875    ], G Loss: 0.7559443712234497\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1707, D Loss: [0.64782473 0.671875  ], G Loss: 0.7278586626052856\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1708, D Loss: [0.69729546 0.4375    ], G Loss: 0.74261474609375\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1709, D Loss: [0.64085308 0.640625  ], G Loss: 0.749268114566803\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1710, D Loss: [0.68899709 0.609375  ], G Loss: 0.7485470771789551\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1711, D Loss: [0.67044607 0.6875    ], G Loss: 0.7167521119117737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1712, D Loss: [0.66900027 0.625     ], G Loss: 0.753663182258606\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1713, D Loss: [0.6810244 0.65625  ], G Loss: 0.7462422847747803\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1714, D Loss: [0.65793037 0.5625    ], G Loss: 0.7364280819892883\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1715, D Loss: [0.68686315 0.578125  ], G Loss: 0.7508543729782104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1716, D Loss: [0.68128499 0.65625   ], G Loss: 0.7506228685379028\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1717, D Loss: [0.66841173 0.734375  ], G Loss: 0.7478669881820679\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1718, D Loss: [0.65589058 0.703125  ], G Loss: 0.7717206478118896\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1719, D Loss: [0.66728365 0.671875  ], G Loss: 0.7621480226516724\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1720, D Loss: [0.67845219 0.6875    ], G Loss: 0.7527637481689453\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1721, D Loss: [0.65908188 0.6875    ], G Loss: 0.7779281139373779\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1722, D Loss: [0.67652869 0.609375  ], G Loss: 0.7534997463226318\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1723, D Loss: [0.67208281 0.609375  ], G Loss: 0.7525607347488403\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1724, D Loss: [0.67328048 0.640625  ], G Loss: 0.7580170631408691\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1725, D Loss: [0.65768355 0.703125  ], G Loss: 0.7560213804244995\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1726, D Loss: [0.66183743 0.671875  ], G Loss: 0.7410159707069397\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1727, D Loss: [0.66023925 0.609375  ], G Loss: 0.7273663282394409\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1728, D Loss: [0.668933 0.703125], G Loss: 0.7456002235412598\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1729, D Loss: [0.67256746 0.6875    ], G Loss: 0.7351387143135071\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1730, D Loss: [0.6563023 0.625    ], G Loss: 0.7322099208831787\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1731, D Loss: [0.6668267 0.671875 ], G Loss: 0.7263218760490417\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1732, D Loss: [0.67160994 0.515625  ], G Loss: 0.7375996708869934\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1733, D Loss: [0.66108191 0.625     ], G Loss: 0.728036642074585\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1734, D Loss: [0.64729467 0.734375  ], G Loss: 0.7286058068275452\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1735, D Loss: [0.6621412 0.625    ], G Loss: 0.7356960773468018\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1736, D Loss: [0.63258547 0.671875  ], G Loss: 0.7321615219116211\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1737, D Loss: [0.6842894 0.609375 ], G Loss: 0.7311044931411743\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1738, D Loss: [0.6505022 0.59375  ], G Loss: 0.7309293746948242\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1739, D Loss: [0.67369801 0.640625  ], G Loss: 0.7344623804092407\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1740, D Loss: [0.66751012 0.65625   ], G Loss: 0.7298099398612976\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1741, D Loss: [0.66713315 0.65625   ], G Loss: 0.719793438911438\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1742, D Loss: [0.65889657 0.734375  ], G Loss: 0.7388300895690918\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1743, D Loss: [0.68681526 0.5       ], G Loss: 0.7172728776931763\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1744, D Loss: [0.66606876 0.75      ], G Loss: 0.7407373785972595\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1745, D Loss: [0.65774858 0.6875    ], G Loss: 0.7328131198883057\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1746, D Loss: [0.65280795 0.671875  ], G Loss: 0.7265786528587341\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1747, D Loss: [0.64608747 0.71875   ], G Loss: 0.7451138496398926\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1748, D Loss: [0.63491854 0.703125  ], G Loss: 0.7380309104919434\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1749, D Loss: [0.67590812 0.65625   ], G Loss: 0.740882396697998\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1750, D Loss: [0.65332264 0.640625  ], G Loss: 0.7479029297828674\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1751, D Loss: [0.65633827 0.71875   ], G Loss: 0.7343589067459106\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1752, D Loss: [0.65895265 0.65625   ], G Loss: 0.7496659159660339\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1753, D Loss: [0.65422219 0.734375  ], G Loss: 0.7350625991821289\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1754, D Loss: [0.66070899 0.671875  ], G Loss: 0.7450525760650635\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1755, D Loss: [0.6551967 0.734375 ], G Loss: 0.7297182083129883\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1756, D Loss: [0.65780017 0.671875  ], G Loss: 0.7526117563247681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1757, D Loss: [0.69999194 0.546875  ], G Loss: 0.7474337220191956\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1758, D Loss: [0.65767211 0.65625   ], G Loss: 0.7531254291534424\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1759, D Loss: [0.65590242 0.6875    ], G Loss: 0.7371035814285278\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1760, D Loss: [0.6403541 0.765625 ], G Loss: 0.7610052824020386\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1761, D Loss: [0.65910584 0.6875    ], G Loss: 0.7490066289901733\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1762, D Loss: [0.63759735 0.75      ], G Loss: 0.7506657242774963\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1763, D Loss: [0.63276407 0.75      ], G Loss: 0.737613320350647\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1764, D Loss: [0.65376735 0.59375   ], G Loss: 0.7372342348098755\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1765, D Loss: [0.64836067 0.71875   ], G Loss: 0.7434602379798889\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1766, D Loss: [0.66127035 0.75      ], G Loss: 0.7387813329696655\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1767, D Loss: [0.65570492 0.640625  ], G Loss: 0.7498131990432739\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1768, D Loss: [0.63152659 0.71875   ], G Loss: 0.7519278526306152\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1769, D Loss: [0.6684483 0.703125 ], G Loss: 0.761716365814209\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1770, D Loss: [0.64709824 0.75      ], G Loss: 0.7533268332481384\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1771, D Loss: [0.66001913 0.703125  ], G Loss: 0.7648462057113647\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1772, D Loss: [0.65301013 0.703125  ], G Loss: 0.743675172328949\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1773, D Loss: [0.6724295 0.671875 ], G Loss: 0.7732263803482056\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1774, D Loss: [0.66927329 0.65625   ], G Loss: 0.7569712996482849\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1775, D Loss: [0.66277602 0.671875  ], G Loss: 0.7462366819381714\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1776, D Loss: [0.65025645 0.71875   ], G Loss: 0.7428390383720398\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1777, D Loss: [0.65832627 0.625     ], G Loss: 0.7618668675422668\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1778, D Loss: [0.6426954 0.71875  ], G Loss: 0.7529050707817078\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1779, D Loss: [0.65795377 0.703125  ], G Loss: 0.7447405457496643\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1780, D Loss: [0.67502812 0.59375   ], G Loss: 0.7432582378387451\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1781, D Loss: [0.67586982 0.671875  ], G Loss: 0.7595415115356445\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1782, D Loss: [0.65660802 0.640625  ], G Loss: 0.7574231624603271\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1783, D Loss: [0.67557293 0.625     ], G Loss: 0.806454062461853\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1784, D Loss: [0.66325662 0.65625   ], G Loss: 0.7748572826385498\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1785, D Loss: [0.64451206 0.65625   ], G Loss: 0.7777488231658936\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1786, D Loss: [0.66364408 0.65625   ], G Loss: 0.7518348097801208\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1787, D Loss: [0.63405651 0.734375  ], G Loss: 0.7233140468597412\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1788, D Loss: [0.63163808 0.703125  ], G Loss: 0.7430004477500916\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1789, D Loss: [0.65547782 0.703125  ], G Loss: 0.7527859210968018\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1790, D Loss: [0.64136124 0.828125  ], G Loss: 0.7570469379425049\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1791, D Loss: [0.65652126 0.6875    ], G Loss: 0.7513515949249268\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1792, D Loss: [0.66341901 0.71875   ], G Loss: 0.7328027486801147\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1793, D Loss: [0.66277403 0.65625   ], G Loss: 0.7572178840637207\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1794, D Loss: [0.66083741 0.625     ], G Loss: 0.7517071962356567\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1795, D Loss: [0.65503943 0.703125  ], G Loss: 0.7610970139503479\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1796, D Loss: [0.65893242 0.6875    ], G Loss: 0.7474965453147888\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1797, D Loss: [0.65672848 0.671875  ], G Loss: 0.7515973448753357\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1798, D Loss: [0.65777898 0.640625  ], G Loss: 0.7665715217590332\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Shape of real data: (32, 11)\n",
      "Shape of fake data: (32, 11)\n",
      "Epoch: 1799, D Loss: [0.6623356 0.609375 ], G Loss: 0.7409132719039917\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Retrain the GAN\n",
    "# Assuming generator, discriminator, and GAN have been defined as per previous steps\n",
    "\n",
    "# Train GAN\n",
    "train_gan(gan, generator, discriminator, scaled_features, epochs=1800, batch_size=32)  # Adjust epochs and batch_size as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bdb20d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 [==============================] - 2s 887us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate Synthetic Data\n",
    "# Generate synthetic data\n",
    "noise = np.random.normal(0, 1, (number_of_samples, latent_dim))\n",
    "synthetic_data = generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0476c5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Quality Assessment of Synthetic Data\n",
    "# Statistical comparison using histograms\n",
    "for i in range(scaled_features.shape[1]):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(scaled_features[:, i], bins=20, alpha=0.5, label='Real')\n",
    "    plt.hist(synthetic_data[:, i], bins=20, alpha=0.5, label='Synthetic')\n",
    "    plt.title(f'Feature {i} Distribution Comparison')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "396dca2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation Matrix Analysis\n",
    "# Correlation matrix comparison\n",
    "real_corr = np.corrcoef(scaled_features, rowvar=False)\n",
    "synthetic_corr = np.corrcoef(synthetic_data, rowvar=False)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(real_corr, cmap='coolwarm')\n",
    "plt.title('Real Data Correlation Matrix')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(synthetic_corr, cmap='coolwarm')\n",
    "plt.title('Synthetic Data Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6800e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d4a0ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 128)               384       \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,123\n",
      "Trainable params: 9,739\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 128)               1536      \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,857\n",
      "Trainable params: 9,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A. Generator\n",
    "# The generator takes a point from the latent space and outputs synthetic data.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, LeakyReLU\n",
    "\n",
    "\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation=\"relu\", input_dim=latent_dim))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(11, activation='tanh'))  # Output size to match the 11 features\n",
    "    return model\n",
    "\n",
    "# latent_dim = 2  # or choose an appropriate size for the latent dimension\n",
    "generator = build_generator(latent_dim)\n",
    "generator.summary()\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "# The discriminator should accept input data of the same shape as your dataset's features.\n",
    "# The discriminator takes real or synthetic data and tries to classify it as real or fake.\n",
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=input_shape, activation='relu'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification output\n",
    "    return model\n",
    "\n",
    "# Assuming build_discriminator is already defined\n",
    "input_shape = (11,)  # Shape of the features in your dataset\n",
    "discriminator = build_discriminator(input_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3646801b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 [==============================] - 2s 720us/step\n"
     ]
    }
   ],
   "source": [
    "# Generate new synthetic data with corrected generator\n",
    "noise = np.random.normal(0, 1, (number_of_samples, latent_dim))\n",
    "synthetic_data = generator.predict(noise)\n",
    "\n",
    "# Split synthetic data\n",
    "X_train_synthetic = synthetic_data[:, :-1]\n",
    "y_train_synthetic = synthetic_data[:, -1]\n",
    "y_train_synthetic_binary = (y_train_synthetic > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "023898be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of synthetic training data: (70000, 10)\n",
      "Shape of real test data: (21000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 11 features, but RandomForestClassifier is expecting 10 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_synthetic, y_train_synthetic_binary)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Evaluate on real test data\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test_real, y_pred))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 11 features, but RandomForestClassifier is expecting 10 features as input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "# Check and print the shapes\n",
    "print(\"Shape of synthetic training data:\", X_train_synthetic.shape)\n",
    "print(\"Shape of real test data:\", X_test_real.shape)\n",
    "\n",
    "# Train RandomForestClassifier on corrected synthetic data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_synthetic, y_train_synthetic_binary)\n",
    "\n",
    "# Evaluate on real test data\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2f0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af2bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7ee881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of synthetic training data: (70000, 10)\n",
      "Shape of real test data: (21000, 11)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature count mismatch between training and test data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Ensure the number of features is the same\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_train_synthetic\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m X_test_real\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature count mismatch between training and test data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train RandomForestClassifier on correct synthetic data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n",
      "\u001b[1;31mValueError\u001b[0m: Feature count mismatch between training and test data."
     ]
    }
   ],
   "source": [
    "# Check and print the shapes\n",
    "print(\"Shape of synthetic training data:\", X_train_synthetic.shape)\n",
    "print(\"Shape of real test data:\", X_test_real.shape)\n",
    "\n",
    "# Ensure the number of features is the same\n",
    "if X_train_synthetic.shape[1] != X_test_real.shape[1]:\n",
    "    raise ValueError(\"Feature count mismatch between training and test data.\")\n",
    "\n",
    "# Train RandomForestClassifier on correct synthetic data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_synthetic, y_train_synthetic_binary)\n",
    "\n",
    "# Evaluate on real test data\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a0b9347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data shape: (70000, 11)\n",
      "Real data shape: (70000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ede\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 11 features, but RandomForestClassifier is expecting 10 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_synthetic, y_train_synthetic_binary)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluate the model on real test data\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test_real, y_pred))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 11 features, but RandomForestClassifier is expecting 10 features as input."
     ]
    }
   ],
   "source": [
    "# Check the number of features in synthetic and real data\n",
    "print(\"Synthetic data shape:\", synthetic_data.shape)\n",
    "print(\"Real data shape:\", features.shape)\n",
    "\n",
    "# If the shapes are not consistent, investigate the cause before proceeding\n",
    "\n",
    "# Assuming synthetic_data now has the correct number of features\n",
    "X_train_synthetic = synthetic_data[:, :-1]\n",
    "y_train_synthetic_binary = (synthetic_data[:, -1] > 0.5).astype(int)\n",
    "\n",
    "# Train RandomForestClassifier on synthetic data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_synthetic, y_train_synthetic_binary)\n",
    "\n",
    "# Evaluate the model on real test data\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11b9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f61d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3766e751",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_synthetic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m X_train_real, X_test_real, y_train_real, y_test_real \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     10\u001b[0m     features, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Before training the model, you can add a check to ensure the feature count is consistent:\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of features in synthetic training data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mX_train_synthetic\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of features in real test data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_test_real\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_train_synthetic\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m X_test_real\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_synthetic' is not defined"
     ]
    }
   ],
   "source": [
    "# Extracting the target variable 'cardio' from the original dataset\n",
    "labels = cardio_df['cardio'].values\n",
    "\n",
    "# 1. Split Original Data for Training and Testing:\n",
    "\n",
    "# Split the original dataset into training and testing sets to evaluate the utility of synthetic data.\n",
    "# The testing set should only include real data to assess the model's performance on unseen, real instances.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "    features, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Before training the model, you can add a check to ensure the feature count is consistent:\n",
    "print(\"Number of features in synthetic training data:\", X_train_synthetic.shape[1])\n",
    "print(\"Number of features in real test data:\", X_test_real.shape[1])\n",
    "\n",
    "if X_train_synthetic.shape[1] != X_test_real.shape[1]:\n",
    "    raise ValueError(\"Mismatch in the number of features between synthetic training data and real test data.\")\n",
    "\n",
    "# 2. Train Models on Synthetic Data:\n",
    "\n",
    "# Use the synthetic data to train various machine learning models.\n",
    "# You can choose models like Decision Trees, Random Forests, MLP, Logistic Regression, etc.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming the last column of synthetic data is the label\n",
    "X_train_synthetic = synthetic_data[:, :-1]  # All columns except the last one\n",
    "y_train_synthetic = synthetic_data[:, -1]\n",
    "\n",
    "# Convert continuous synthetic labels to binary format\n",
    "y_train_synthetic_binary = (y_train_synthetic > 0.5).astype(int)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_synthetic, y_train_synthetic_binary)\n",
    "\n",
    "# 3. Evaluate Models on Real Test Data:\n",
    "\n",
    "# Evaluate these models on the real test set.\n",
    "# Use metrics like Accuracy, Precision, Recall, F1-Score, and AUC-ROC.\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83f1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e38d15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in synthetic training data: 10\n",
      "Number of features in real test data: 11\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mismatch in the number of features between synthetic training data and real test data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of features in real test data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_test_real\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_train_synthetic\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m X_test_real\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch in the number of features between synthetic training data and real test data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train Models on Synthetic Data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n",
      "\u001b[1;31mValueError\u001b[0m: Mismatch in the number of features between synthetic training data and real test data."
     ]
    }
   ],
   "source": [
    "# Assuming 'synthetic_data' is already generated and available\n",
    "\n",
    "# Split synthetic data into features and labels\n",
    "X_train_synthetic = synthetic_data[:, :-1]  # All columns except the last one\n",
    "y_train_synthetic = synthetic_data[:, -1]\n",
    "y_train_synthetic_binary = (y_train_synthetic > 0.5).astype(int)  # Convert continuous labels to binary\n",
    "\n",
    "# Split Original Data for Training and Testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'features' and 'labels' are your original dataset's features and labels\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "    features, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Check Feature Consistency\n",
    "print(\"Number of features in synthetic training data:\", X_train_synthetic.shape[1])\n",
    "print(\"Number of features in real test data:\", X_test_real.shape[1])\n",
    "\n",
    "if X_train_synthetic.shape[1] != X_test_real.shape[1]:\n",
    "    raise ValueError(\"Mismatch in the number of features between synthetic training data and real test data.\")\n",
    "\n",
    "# Train Models on Synthetic Data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_synthetic, y_train_synthetic_binary)\n",
    "\n",
    "# Evaluate Models on Real Test Data\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad36ff0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7a7b9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          70000 non-null  int64  \n",
      " 1   gender       70000 non-null  int64  \n",
      " 2   height       70000 non-null  int64  \n",
      " 3   weight       70000 non-null  float64\n",
      " 4   ap_hi        70000 non-null  int64  \n",
      " 5   ap_lo        70000 non-null  int64  \n",
      " 6   cholesterol  70000 non-null  int64  \n",
      " 7   gluc         70000 non-null  int64  \n",
      " 8   smoke        70000 non-null  int64  \n",
      " 9   alco         70000 non-null  int64  \n",
      " 10  active       70000 non-null  int64  \n",
      " 11  cardio       70000 non-null  int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 6.4 MB\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 116>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    114\u001b[0m scaled_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m \u001b[38;5;66;03m# Your scaled feature data\u001b[39;00m\n\u001b[0;32m    115\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m \u001b[38;5;66;03m# Your target labels\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[43mscaled_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m],)\n\u001b[0;32m    117\u001b[0m latent_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    118\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Activation, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Cardiovascular disease dataset\n",
    "cardio_data_path = 'C:\\\\Users\\\\Ede\\\\Desktop\\\\Synthetic_Data_Using_AE_VAE_Techniques\\\\cardio.csv'\n",
    "cardio_df = pd.read_csv(cardio_data_path)\n",
    "\n",
    "# Process dataset: Feature extraction and scaling\n",
    "features = cardio_df.drop('cardio', axis=1)  # Assuming 'cardio' is the target column\n",
    "labels = cardio_df['cardio'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "    scaled_features, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Displaying the first few rows of the dataset and summary information\n",
    "cardio_df_info = cardio_df.info()\n",
    "cardio_df_head = cardio_df.head()\n",
    "\n",
    "\n",
    "# Define the VAE's sampling mechanism\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Define VAE architecture\n",
    "def build_vae(input_shape, intermediate_dim=64, latent_dim=2):\n",
    "    # Encoder\n",
    "    inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "    # Decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(input_shape[0], activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # VAE Model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Define GAN's Generator and Discriminator\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation=\"relu\", input_dim=latent_dim))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(11, activation='linear'))  # Output size to match the 11 features\n",
    "    return model\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=input_shape, activation='relu'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification output\n",
    "    return model\n",
    "\n",
    "# Combine Generator and Discriminator to create GAN\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential([generator, discriminator])\n",
    "    return model\n",
    "\n",
    "# Train the GAN\n",
    "def train_gan(gan, generator, discriminator, features, epochs, batch_size, latent_dim):\n",
    "    for epoch in range(epochs):\n",
    "        # Real data\n",
    "        idx = np.random.randint(0, features.shape[0], batch_size)\n",
    "        real_data = features[idx]\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "\n",
    "        # Fake data\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_data = generator.predict(noise)\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Train Discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(real_data, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_data, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train Generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(noise, real_labels)\n",
    "\n",
    "# Main Execution\n",
    "scaled_features = ... # Your scaled feature data\n",
    "labels = ... # Your target labels\n",
    "input_shape = (scaled_features.shape[1],)\n",
    "latent_dim = 2\n",
    "epochs = 50\n",
    "\n",
    "# VAE and GAN setup\n",
    "vae, encoder, decoder = build_vae(input_shape)\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator(input_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "# Train GAN\n",
    "train_gan(gan, generator, discriminator, scaled_features, epochs=1513, batch_size=32, latent_dim=latent_dim)\n",
    "\n",
    "# Generate Synthetic Data\n",
    "number_of_samples = scaled_features.shape[0]\n",
    "noise = np.random.normal(0, 1, (number_of_samples, latent_dim))\n",
    "synthetic_data = generator.predict(noise)\n",
    "\n",
    "# Split synthetic data into features and labels\n",
    "X_train_synthetic = synthetic_data\n",
    "y_train_synthetic = (np.random.rand(number_of_samples) > 0.5).astype(int)  # Random binary labels\n",
    "\n",
    "# Split real data for evaluation\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "    scaled_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Check feature count match\n",
    "if X_train_synthetic.shape[1] != X_test_real.shape[1]:\n",
    "    raise ValueError(\"Feature count mismatch between synthetic training and real test data.\")\n",
    "\n",
    "# Train and evaluate model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_synthetic, y_train_synthetic)\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred))\n",
    "\n",
    "# Print the info and head of the dataframe to check the data\n",
    "print(cardio_df_info)\n",
    "print(cardio_df_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed27227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0f59207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          70000 non-null  int64  \n",
      " 1   gender       70000 non-null  int64  \n",
      " 2   height       70000 non-null  int64  \n",
      " 3   weight       70000 non-null  float64\n",
      " 4   ap_hi        70000 non-null  int64  \n",
      " 5   ap_lo        70000 non-null  int64  \n",
      " 6   cholesterol  70000 non-null  int64  \n",
      " 7   gluc         70000 non-null  int64  \n",
      " 8   smoke        70000 non-null  int64  \n",
      " 9   alco         70000 non-null  int64  \n",
      " 10  active       70000 non-null  int64  \n",
      " 11  cardio       70000 non-null  int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 6.4 MB\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "2188/2188 [==============================] - 2s 840us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.44      0.46     10461\n",
      "           1       0.49      0.52      0.50     10539\n",
      "\n",
      "    accuracy                           0.48     21000\n",
      "   macro avg       0.48      0.48      0.48     21000\n",
      "weighted avg       0.48      0.48      0.48     21000\n",
      "\n",
      "None\n",
      "     age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
      "0  18393       2     168    62.0    110     80            1     1      0   \n",
      "1  20228       1     156    85.0    140     90            3     1      0   \n",
      "2  18857       1     165    64.0    130     70            3     1      0   \n",
      "3  17623       2     169    82.0    150    100            1     1      0   \n",
      "4  17474       1     156    56.0    100     60            1     1      0   \n",
      "\n",
      "   alco  active  cardio  \n",
      "0     0       1       0  \n",
      "1     0       1       1  \n",
      "2     0       0       1  \n",
      "3     0       1       1  \n",
      "4     0       0       0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Activation, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Cardiovascular disease dataset\n",
    "cardio_data_path = 'C:\\\\Users\\\\Ede\\\\Desktop\\\\Synthetic_Data_Using_AE_VAE_Techniques\\\\cardio.csv'\n",
    "cardio_df = pd.read_csv(cardio_data_path)\n",
    "\n",
    "# Process dataset: Feature extraction and scaling\n",
    "features = cardio_df.drop('cardio', axis=1)  # Assuming 'cardio' is the target column\n",
    "labels = cardio_df['cardio'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "    scaled_features, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Displaying the first few rows of the dataset and summary information\n",
    "cardio_df_info = cardio_df.info()\n",
    "cardio_df_head = cardio_df.head()\n",
    "\n",
    "# Define the VAE's sampling mechanism\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Define VAE architecture\n",
    "def build_vae(input_shape, intermediate_dim=64, latent_dim=2):\n",
    "    # Encoder\n",
    "    inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "    # Decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(input_shape[0], activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # VAE Model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Define GAN's Generator and Discriminator\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation=\"relu\", input_dim=latent_dim))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(11, activation='linear'))  # Output size to match the 11 features\n",
    "    return model\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=input_shape, activation='relu'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification output\n",
    "    return model\n",
    "\n",
    "# Combine Generator and Discriminator to create GAN\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential([generator, discriminator])\n",
    "    return model\n",
    "\n",
    "# Train the GAN\n",
    "def train_gan(gan, generator, discriminator, features, epochs, batch_size, latent_dim):\n",
    "    for epoch in range(epochs):\n",
    "        # Real data\n",
    "        idx = np.random.randint(0, features.shape[0], batch_size)\n",
    "        real_data = features[idx]\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "\n",
    "        # Fake data\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_data = generator.predict(noise)\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Train Discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(real_data, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_data, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train Generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(noise, real_labels)\n",
    "\n",
    "# Main Execution\n",
    "input_shape = (scaled_features.shape[1],)\n",
    "latent_dim = 2\n",
    "epochs = 50\n",
    "\n",
    "# VAE and GAN setup\n",
    "vae, encoder, decoder = build_vae(input_shape)\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator(input_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "# Train GAN\n",
    "train_gan(gan, generator, discriminator, scaled_features, epochs=1513, batch_size=32, latent_dim=latent_dim)\n",
    "\n",
    "# Generate Synthetic Data\n",
    "number_of_samples = scaled_features.shape[0]\n",
    "noise = np.random.normal(0, 1, (number_of_samples, latent_dim))\n",
    "synthetic_data = generator.predict(noise)\n",
    "\n",
    "# Split synthetic data into features and labels\n",
    "X_train_synthetic = synthetic_data\n",
    "y_train_synthetic = (np.random.rand(number_of_samples) > 0.5).astype(int)  # Random binary labels\n",
    "\n",
    "# Split real data for evaluation\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "    scaled_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Check feature count match\n",
    "if X_train_synthetic.shape[1] != X_test_real.shape[1]:\n",
    "    raise ValueError(\"Feature count mismatch between synthetic training and real test data.\")\n",
    "\n",
    "# Train and evaluate model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_synthetic, y_train_synthetic)\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred))\n",
    "\n",
    "# Print the info and head of the dataframe to check the data\n",
    "print(cardio_df_info)\n",
    "print(cardio_df_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee60efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38279c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edb91dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          70000 non-null  int64  \n",
      " 1   gender       70000 non-null  int64  \n",
      " 2   height       70000 non-null  int64  \n",
      " 3   weight       70000 non-null  float64\n",
      " 4   ap_hi        70000 non-null  int64  \n",
      " 5   ap_lo        70000 non-null  int64  \n",
      " 6   cholesterol  70000 non-null  int64  \n",
      " 7   gluc         70000 non-null  int64  \n",
      " 8   smoke        70000 non-null  int64  \n",
      " 9   alco         70000 non-null  int64  \n",
      " 10  active       70000 non-null  int64  \n",
      " 11  cardio       70000 non-null  int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 6.4 MB\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "2188/2188 [==============================] - 3s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.58      0.53     10461\n",
      "           1       0.50      0.41      0.45     10539\n",
      "\n",
      "    accuracy                           0.50     21000\n",
      "   macro avg       0.50      0.50      0.49     21000\n",
      "weighted avg       0.50      0.50      0.49     21000\n",
      "\n",
      "None\n",
      "     age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
      "0  18393       2     168    62.0    110     80            1     1      0   \n",
      "1  20228       1     156    85.0    140     90            3     1      0   \n",
      "2  18857       1     165    64.0    130     70            3     1      0   \n",
      "3  17623       2     169    82.0    150    100            1     1      0   \n",
      "4  17474       1     156    56.0    100     60            1     1      0   \n",
      "\n",
      "   alco  active  cardio  \n",
      "0     0       1       0  \n",
      "1     0       1       1  \n",
      "2     0       0       1  \n",
      "3     0       1       1  \n",
      "4     0       0       0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Activation, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Cardiovascular disease dataset\n",
    "cardio_data_path = 'C:\\\\Users\\\\Ede\\\\Desktop\\\\Synthetic_Data_Using_AE_VAE_Techniques\\\\cardio.csv'\n",
    "cardio_df = pd.read_csv(cardio_data_path)\n",
    "\n",
    "# Process dataset: Feature extraction and scaling\n",
    "features = cardio_df.drop('cardio', axis=1)  # Assuming 'cardio' is the target column\n",
    "labels = cardio_df['cardio'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "    scaled_features, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Displaying the first few rows of the dataset and summary information\n",
    "cardio_df_info = cardio_df.info()\n",
    "cardio_df_head = cardio_df.head()\n",
    "\n",
    "# Define the VAE's sampling mechanism\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Define VAE architecture\n",
    "def build_vae(input_shape, intermediate_dim=64, latent_dim=2):\n",
    "    # Encoder\n",
    "    inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "    # Decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(input_shape[0], activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # VAE Model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Define GAN's Generator and Discriminator\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation=\"relu\", input_dim=latent_dim))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(11, activation='tanh'))  # Output size to match the 11 features\n",
    "    return model\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=input_shape, activation='relu'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification output\n",
    "    return model\n",
    "\n",
    "# Combine Generator and Discriminator to create GAN\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential([generator, discriminator])\n",
    "    return model\n",
    "\n",
    "# Train the GAN\n",
    "def train_gan(gan, generator, discriminator, features, epochs, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        # Real data\n",
    "        idx = np.random.randint(0, features.shape[0], batch_size)\n",
    "        real_data = features[idx]\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "\n",
    "        # Fake data\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_data = generator.predict(noise)\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Train Discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(real_data, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_data, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train Generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(noise, real_labels)\n",
    "\n",
    "# Main Execution\n",
    "input_shape = (scaled_features.shape[1],)\n",
    "intermediate_dim = 64\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "epochs = 50\n",
    "\n",
    "# VAE and GAN setup\n",
    "vae, encoder, decoder = build_vae(input_shape)\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator(input_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "# Train GAN\n",
    "train_gan(gan, generator, discriminator, scaled_features, epochs=3500, batch_size=32)\n",
    "\n",
    "# Generate Synthetic Data\n",
    "number_of_samples = scaled_features.shape[0]\n",
    "noise = np.random.normal(0, 1, (number_of_samples, latent_dim))\n",
    "synthetic_data = generator.predict(noise)\n",
    "\n",
    "# Split synthetic data into features and labels\n",
    "X_train_synthetic = synthetic_data\n",
    "y_train_synthetic = (np.random.rand(number_of_samples) > 0.5).astype(int)  # Random binary labels\n",
    "\n",
    "# Split real data for evaluation\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "    scaled_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Check feature count match\n",
    "if X_train_synthetic.shape[1] != X_test_real.shape[1]:\n",
    "    raise ValueError(\"Feature count mismatch between synthetic training and real test data.\")\n",
    "\n",
    "# Train and evaluate model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_synthetic, y_train_synthetic)\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(classification_report(y_test_real, y_pred))\n",
    "\n",
    "# Print the info and head of the dataframe to check the data\n",
    "print(cardio_df_info)\n",
    "print(cardio_df_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd5389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
